{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAgxLUj7wCCM"
   },
   "source": [
    "# Welcome!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWcQ7faUm8At"
   },
   "source": [
    "**This notebook lists the libraries we require for scientific modeling and/or computation tasks.**\n",
    "\n",
    "**Included some examples and code snippets for future use**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tkEibAMKHnWb"
   },
   "source": [
    "# [*/ Python /*]\n",
    "\n",
    "* Standard Libraries https://docs.python.org/3.7/library/\n",
    "\n",
    "* Language Reference https://docs.python.org/3.7/reference/index.html#reference-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1223,
     "status": "ok",
     "timestamp": 1620680992709,
     "user": {
      "displayName": "Nelson Sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPBID9lAjTfc37OKpgQrK84DxazL0gYxBwMLjs=s64",
      "userId": "05205859662695765719"
     },
     "user_tz": -330
    },
    "id": "0ZTpHw7JHHPX",
    "outputId": "c90a81eb-64d9-4ad1-c1cc-92a49cd34c18"
   },
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZwbcfsWnZBA"
   },
   "source": [
    "# [*] Libraries [*]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9d_PO-q8dSFD"
   },
   "source": [
    "## Basic Imports\n",
    "\n",
    "> Core python3.x libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "49ti5OLOdVOw"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import random\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#hide warnings on outputs\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.simplefilter('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cIR5nGhxd9bL"
   },
   "source": [
    "## SciPy\n",
    "\n",
    "> SciPy provides most of the core libraries needed for scientific computations and visualization\n",
    "\n",
    "* Documentation https://docs.scipy.org/doc/\n",
    "\n",
    "* NumPy API https://numpy.org/doc/stable/reference/index.html\n",
    "\n",
    "* SciPy API http://scipy.github.io/devdocs/reference/index.html\n",
    "\n",
    "* Matplotlib API https://matplotlib.org/stable/api/index.html\n",
    "\n",
    "* Pandas API https://pandas.pydata.org/docs/reference/index.html#api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GIugMMPseKzV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import *  # or use import scipy.xyz as scipy_xyz import scipy.signal as scsig\n",
    "from scipy.sparse.csgraph import floyd_warshall\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqku_G46dq0_"
   },
   "source": [
    "## scikit libraries\n",
    "\n",
    "> scikit-learn is a great library for machine-learning\n",
    "\n",
    "* Documentation https://scikit-learn.org/stable/\n",
    "\n",
    "* sklearn API Reference https://scikit-learn.org/stable/modules/classes.html\n",
    "\n",
    "* User guide https://scikit-learn.org/stable/user_guide.html#user-guide\n",
    "\n",
    "\n",
    "> scikit-image provides API for image processing\n",
    "\n",
    "* scikit-image API https://scikit-image.org/docs/dev/api/api.html\n",
    "\n",
    "* scikit-image Guide https://scikit-image.org/docs/dev/user_guide.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CDXaVO6KiABh"
   },
   "outputs": [],
   "source": [
    "# recomended way of importing sklearn and skimage modules\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from skimage import transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIU3aj2-dxMz"
   },
   "source": [
    "## Seaborn\n",
    "\n",
    "> based on matplotlib, provides high level API\n",
    "\n",
    "* Seaborn API https://seaborn.pydata.org/api.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ohRfUIAXd3Ch"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChB9OYZ6zF4F"
   },
   "source": [
    "## Keras and TensorFlow\n",
    "> TensorFlow for Deep Learning\n",
    "\n",
    "* TensorFlow API https://www.tensorflow.org/api_docs/python/tf\n",
    "\n",
    "> Keras is a high-level API for TensorFlow.\n",
    "\n",
    "* Keras Reference https://www.tensorflow.org/guide/keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 1184,
     "status": "ok",
     "timestamp": 1620669665770,
     "user": {
      "displayName": "Nelson Sharma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPBID9lAjTfc37OKpgQrK84DxazL0gYxBwMLjs=s64",
      "userId": "05205859662695765719"
     },
     "user_tz": -330
    },
    "id": "yPwIGRm7b5o4",
    "outputId": "f02112fc-f3b2-4287-a77b-38b66ab80659"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as tfk\n",
    "from tensorflow.keras import Model  # always use this approach instead of Sequential\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.models import clone_model\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3GhoDje_cc9o"
   },
   "source": [
    "## statsmodels \n",
    "\n",
    "> For Time Series Analysis\n",
    "\n",
    "* statsmodels API https://www.statsmodels.org/stable/api.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install statsmodels==0.12.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DMoZWtLidfGS"
   },
   "outputs": [],
   "source": [
    "# pip install statsmodels==0.12.2\n",
    "import statsmodels.tsa as tsa\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "warnings.simplefilter('ignore', ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dsypLRZm3qN_"
   },
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f54h_uHv3sEo"
   },
   "outputs": [],
   "source": [
    "# for jupyter notebook on a desktop\n",
    "pip install notebook\n",
    "\n",
    "# consider using cython\n",
    "pip install cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3he-Ghrj7VL"
   },
   "source": [
    "# [*] Snippets [*]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUaHGnjgolxO"
   },
   "source": [
    "## Execute external .py scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ftpnxt60ooQd"
   },
   "outputs": [],
   "source": [
    "execpath = '/content/drive/MyDrive/xyz.py' # define execution path\n",
    "execfile(execpath)  # call execfile()\n",
    "\n",
    "#or use\n",
    "%run '/content/drive/MyDrive/xyz.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hAkAihFej89l"
   },
   "source": [
    "## Display Execution Time Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fejRnMofj_zk"
   },
   "outputs": [],
   "source": [
    "timestamp_start = datetime.datetime.now()\n",
    "#*********************************************************\n",
    "# ... code goes here ....\n",
    "print(os.listdir('/home'))\n",
    "\n",
    "#*********************************************************\n",
    "timestamp_dur = datetime.datetime.now() - timestamp_start\n",
    "print('Elapsed time = ' + str(timestamp_dur))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UID using TimeStamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.datetime.now().strftime('%Y%M%d%H%m%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(path, mode = 0o777, exist_ok = False)\n",
    "\n",
    "os.makedirs(path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-~-~-~-~-~~-~-~-~-~-~\n",
    "# directories\n",
    "#-~-~-~-~-~~-~-~-~-~-~\n",
    "temp_dir = \"_temp\" # directory for temporary fiiles\n",
    "report_dir = \"_logs\" # define logger and its directory \n",
    "os.makedirs(temp_dir,exist_ok=True)\n",
    "os.makedirs(report_dir,exist_ok=True)\n",
    "#-~-~-~-~-~~-~-~-~-~-~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumsum(divA):\n",
    "    l = len(divA)\n",
    "    res = np.zeros(l+1, dtype=divA.dtype)\n",
    "    for i in range(1, l+1):\n",
    "        res[i] = np.sum(divA[0:i])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.array([0, 3,3,4])\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = cumsum(n)\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(n)\n",
    "for i in range(1, l):\n",
    "    n[i] = n[i-1]+n[i]\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = copy.deepcopy(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas-datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas.datareader'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6428/3050883115.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatareader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas.datareader'"
     ]
    }
   ],
   "source": [
    "import pandas.datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  High         Low        Open       Close     Volume  \\\n",
      "Date                                                                    \n",
      "2010-08-02  131.199997  129.250000  129.250000  130.759995  6437500.0   \n",
      "2010-08-03  131.039993  129.330002  130.029999  130.369995  5091800.0   \n",
      "2010-08-04  131.500000  129.850006  130.460007  131.270004  4567500.0   \n",
      "2010-08-05  131.979996  130.529999  130.729996  131.830002  4520600.0   \n",
      "2010-08-06  130.479996  128.759995  130.410004  130.139999  6136200.0   \n",
      "\n",
      "            Adj Close  \n",
      "Date                   \n",
      "2010-08-02  90.169785  \n",
      "2010-08-03  89.900833  \n",
      "2010-08-04  90.521461  \n",
      "2010-08-05  90.907639  \n",
      "2010-08-06  90.186905  \n",
      "                High       Low      Open     Close       Volume  Adj Close\n",
      "Date                                                                      \n",
      "2010-08-02  9.378214  9.272143  9.301429  9.351786  428055600.0   8.029596\n",
      "2010-08-03  9.402143  9.265000  9.321786  9.354643  417653600.0   8.032053\n",
      "2010-08-04  9.438571  9.296786  9.387143  9.392143  420375200.0   8.064249\n",
      "2010-08-05  9.399286  9.305357  9.347500  9.346429  289097200.0   8.024997\n",
      "2010-08-06  9.338929  9.201071  9.277857  9.288929  444897600.0   7.975628\n",
      "                 High        Low       Open      Close     Volume  Adj Close\n",
      "Date                                                                        \n",
      "2012-05-18  45.000000  38.000000  42.049999  38.230000  573576400  38.230000\n",
      "2012-05-21  36.660000  33.000000  36.529999  34.029999  168192700  34.029999\n",
      "2012-05-22  33.590000  30.940001  32.610001  31.000000  101786600  31.000000\n",
      "2012-05-23  32.500000  31.360001  31.370001  32.000000   73600000  32.000000\n",
      "2012-05-24  33.209999  31.770000  32.950001  33.029999   50237200  33.029999\n",
      "                  High         Low        Open       Close     Volume  \\\n",
      "Date                                                                    \n",
      "2010-08-02  246.886887  243.713715  244.739746  245.450455  3713683.0   \n",
      "2010-08-03  246.476471  243.623627  245.495499  245.160156  3600995.0   \n",
      "2010-08-04  253.753754  245.770767  246.336334  253.413406  7617375.0   \n",
      "2010-08-05  254.554550  252.032028  253.198196  254.304306  4835959.0   \n",
      "2010-08-06  253.123123  248.273270  252.952957  250.360367  6632361.0   \n",
      "\n",
      "             Adj Close  \n",
      "Date                    \n",
      "2010-08-02  245.450455  \n",
      "2010-08-03  245.160156  \n",
      "2010-08-04  253.413406  \n",
      "2010-08-05  254.304306  \n",
      "2010-08-06  250.360367  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pandas_datareader import data as pdr \n",
    "from datetime import datetime \n",
    "#download data \n",
    "ibm = pdr.DataReader('IBM', 'yahoo', start=datetime(2010, 8, 1), end=datetime(2016, 11, 30))  \n",
    "aapl = pdr.DataReader('AAPL', 'yahoo', start=datetime(2010, 8, 1), end=datetime(2016, 11, 30))  \n",
    "fb = pdr.DataReader('FB', 'yahoo', start=datetime(2010, 8, 1), end=datetime(2016, 11, 30))  \n",
    "googl = pdr.DataReader('GOOGL', 'yahoo', start=datetime(2010, 8, 1), end=datetime(2016, 11, 30)) \n",
    " \n",
    "#print first few lines of data \n",
    "print(ibm.head()) \n",
    "print(aapl.head()) \n",
    "print(fb.head()) \n",
    "print(googl.head()) \n",
    " \n",
    "#export and save as csv files \n",
    "ibm.to_csv('IBM_stock.csv', sep=',') \n",
    "aapl.to_csv('Apple_stock.csv', sep=',') \n",
    "fb.to_csv('Facebook_stock.csv', sep=',') \n",
    "googl.to_csv('Google_stock.csv', sep=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pybase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package _pybase:\n",
      "\n",
      "NAME\n",
      "    _pybase\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "\n",
      "\n",
      "FILE\n",
      "    (built-in)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(_pybase)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Welcome.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
