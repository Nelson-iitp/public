{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Q.6]\n",
    "\n",
    "![Alt text](image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution [6]\n",
    "\n",
    "![Alt text](image-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAIs for App A : AAI_A_X=27.4, AAI_A_Y=30.4, AAI_A_Z=24.4\n",
      "App A should be placed on Server Z since AAI_A_Z=24.4 is minimum\n",
      "\n",
      "AAIs for App B : AAI_B_X=21.2, AAI_B_Y=24.2, AAI_B_Z=18.2\n",
      "App B should be placed on Server Z since AAI_B_Z=18.2 is minimum\n",
      "\n",
      "AAIs for App C : AAI_C_X=33.6, AAI_C_Y=36.6, AAI_C_Z=30.6\n",
      "App C should be placed on Server Z since AAI_C_Z=30.6 is minimum\n",
      "\n",
      "\n",
      "Note that server Z does not actually have enough cpu-cores and memory to support all the apps\n",
      "but that should not be considered in AAI index calculation and application placement decision.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# latency is given\n",
    "latency_X, latency_Y, latency_Z = 30, 40, 20\n",
    "\n",
    "# response time is given\n",
    "response_time_A, response_time_B, response_time_C = 60, 40, 80\n",
    "\n",
    "# calculate AAI for app A on all servers\n",
    "\n",
    "# App A requires 2-cpu, 8-memory\n",
    "# resource_utilization = required_resource / available_resource   #<---- sum over all types of resources (memory and cpu)\n",
    "resource_util_A_X = 2/4 + 4/8 \n",
    "resource_util_A_Y = 2/4 + 4/8 \n",
    "resource_util_A_Z = 2/4 + 4/8 \n",
    "AAI_A_X = 0.4*resource_util_A_X + 0.3*latency_X + 0.3*response_time_A\n",
    "AAI_A_Y = 0.4*resource_util_A_Y + 0.3*latency_Y + 0.3*response_time_A\n",
    "AAI_A_Z = 0.4*resource_util_A_Z + 0.3*latency_Z + 0.3*response_time_A\n",
    "\n",
    "# calculate AAI for app B on all servers\n",
    "# App B requires 1-cpu, 2-memory\n",
    "# resource_utilization = required_resource / available_resource   #<---- sum over all types of resources (memory and cpu)\n",
    "resource_util_B_X = 1/4 + 2/8 \n",
    "resource_util_B_Y = 1/4 + 2/8 \n",
    "resource_util_B_Z = 1/4 + 2/8 \n",
    "AAI_B_X = 0.4*resource_util_B_X + 0.3*latency_X + 0.3*response_time_B\n",
    "AAI_B_Y = 0.4*resource_util_B_Y + 0.3*latency_Y + 0.3*response_time_B\n",
    "AAI_B_Z = 0.4*resource_util_B_Z + 0.3*latency_Z + 0.3*response_time_B\n",
    "\n",
    "# calculate AAI for app C on all servers\n",
    "# App C requires 3-cpu, 6-memory\n",
    "# resource_utilization = required_resource / available_resource   #<---- sum over all types of resources (memory and cpu)\n",
    "resource_util_C_X = 3/4 + 6/8 \n",
    "resource_util_C_Y = 3/4 + 6/8 \n",
    "resource_util_C_Z = 3/4 + 6/8 \n",
    "AAI_C_X = 0.4*resource_util_C_X + 0.3*latency_X + 0.3*response_time_C\n",
    "AAI_C_Y = 0.4*resource_util_C_Y + 0.3*latency_Y + 0.3*response_time_C\n",
    "AAI_C_Z = 0.4*resource_util_C_Z + 0.3*latency_Z + 0.3*response_time_C\n",
    "\n",
    "print(f'AAIs for App A : {AAI_A_X=}, {AAI_A_Y=}, {AAI_A_Z=}') #<---- which one is minimum? = AAI_A_Z\n",
    "print(f'App A should be placed on Server Z since {AAI_A_Z=} is minimum\\n')\n",
    "\n",
    "print(f'AAIs for App B : {AAI_B_X=}, {AAI_B_Y=}, {AAI_B_Z=}') #<---- which one is minimum? = AAI_A_Z\n",
    "print(f'App B should be placed on Server Z since {AAI_B_Z=} is minimum\\n')\n",
    "\n",
    "print(f'AAIs for App C : {AAI_C_X=}, {AAI_C_Y=}, {AAI_C_Z=}') #<---- which one is minimum? = AAI_A_Z\n",
    "print(f'App C should be placed on Server Z since {AAI_C_Z=} is minimum\\n')\n",
    "\n",
    "print(\n",
    "\"\"\"\n",
    "Note that server Z does not actually have enough cpu-cores and memory to support all the apps\n",
    "but that should not be considered in AAI index calculation and application placement decision.\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Q.7]\n",
    "\n",
    "![Alt text](image-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution [7]\n",
    "\n",
    "\n",
    "![Alt text](image-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Q.8] :: for full solution refer to lecture slides LEC_12_PDQN_DDPG.pptx on slide 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Q.9] [a] Attention calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4]) torch.Size([2, 4]) torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch as tt\n",
    "\n",
    "\n",
    "# define keys\n",
    "K = tt.tensor([\n",
    "     [ -0.1458, -0.9395, -0.0372,  0.3079 ], # k1\n",
    "     [  0.4547, -0.6297, -0.3239, -0.5402 ], # k2\n",
    "     [  0.0615, -0.1083, -0.1887,  0.9741 ], # k3\n",
    "]) # size = 3 x 4\n",
    "\n",
    "# define values\n",
    "V = tt.tensor([\n",
    "    [  0.1466, -1.0041 ],  # v1\n",
    "    [ -0.7882, -0.8074 ],  # v2\n",
    "    [ -0.2957, -0.1462 ],  # v3\n",
    "]) # size = 3 x 2\n",
    "\n",
    "# define queries\n",
    "Q = tt.tensor([\n",
    "     [  0.2429,  0.2889,  0.3933, -0.8384 ], # q1\n",
    "     [  0.1826,  0.3651,  0.5477,  0.7303 ], # q2\n",
    "]) # size = 2 x 4\n",
    "\n",
    "print(K.shape, Q.shape, V.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q.Kt is torch.Size([2, 3])\n",
      "tensor([[-0.5796,  0.2540, -0.9073],\n",
      "        [-0.1651, -0.7188,  0.5797]])\n"
     ]
    }
   ],
   "source": [
    "# 1. matrix multiply Q and K\n",
    "\n",
    "QKt = tt.matmul(Q, K.T)\n",
    "print(f'Q.Kt is {QKt.shape}\\n{QKt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qkt_scaled is torch.Size([2, 3])\n",
      "tensor([[-0.2898,  0.1270, -0.4536],\n",
      "        [-0.0826, -0.3594,  0.2899]])\n"
     ]
    }
   ],
   "source": [
    "# 2. Scale by 0.5 (since dimension of keys is 4)\n",
    "dk = 4\n",
    "Qkt_scaled = QKt/(dk**0.5)\n",
    "print(f'Qkt_scaled is {Qkt_scaled.shape}\\n{Qkt_scaled}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights is torch.Size([2, 3])\n",
      "tensor([[0.2971, 0.4507, 0.2522],\n",
      "        [0.3116, 0.2362, 0.4522]])\n"
     ]
    }
   ],
   "source": [
    "# 3. apply softmax to get weights\n",
    "attention_weights = tt.softmax(Qkt_scaled, dim=-1)\n",
    "print(f'attention_weights is {attention_weights.shape}\\n{attention_weights}')\n",
    "# one row for each query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_output is torch.Size([2, 2])\n",
      "tensor([[-0.3863, -0.6991],\n",
      "        [-0.2742, -0.5697]])\n"
     ]
    }
   ],
   "source": [
    "# 4. matrix multiply with values\n",
    "\n",
    "attention_output = tt.matmul(attention_weights, V)\n",
    "print(f'attention_output is {attention_output.shape}\\n{attention_output}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for part [b] refer to previously provided solution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
