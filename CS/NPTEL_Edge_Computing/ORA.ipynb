{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal Resource Allocation in Public and Private Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define System Model (MDP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class System: # represents the MDP\n",
    "    \n",
    "    def __init__(self, E, Pefc) -> None:\n",
    "        self.E = E # total VMs at edge\n",
    "        self.H = [] # Record List\n",
    "        self.Pe, self.Pf, self.Pc = Pefc # cost parameters\n",
    "        self.verbose=False\n",
    "        \n",
    "    def reset(self):\n",
    "        self.et = self.E # currently avaialble VMs\n",
    "        self.H.clear() # clear record list\n",
    "        self.t = 0   # time step\n",
    "        return self\n",
    "\n",
    "    def step(self, d, l, a): \n",
    "        # represents handling one user demand\n",
    "        self.t+=1\n",
    "        verb = self.verbose\n",
    "        # d = no of vms requesterd, \n",
    "        # l = duration requested\n",
    "        # a = action (ratio of vms allocated from cloud)\n",
    "        if verb: \n",
    "            print(f'{self.t=}')\n",
    "            print(f'\\tDemand, {d, l}')\n",
    "            print(f'\\tAction, {a}')\n",
    "        \n",
    "        c = int(d*a) # vms allocated from cloud\n",
    "        e = d - c    # vms allocated from edge\n",
    "        r = self.et - e # remaining VMs after allocation\n",
    "        # check if enough vms available?\n",
    "        if r<0:\n",
    "            e = self.et # allocated all from edge\n",
    "            c += (-r) # take remaining from cloud\n",
    "        self.et -= e\n",
    "        if verb: \n",
    "            print(f'\\tAllocated from Cloud, {c=}')\n",
    "            print(f'\\tAllocated from Edge, {e=}')\n",
    "            print(f'\\tRemaining, {self.et=}')\n",
    "        # generate allocation record \n",
    "        if e > 0:\n",
    "            self.H.append([e, l]) #<-- appending a list to a list\n",
    "            if verb:\n",
    "                print(f'\\t\\tAllocation Record, {[e,l]}')\n",
    "                print(f'\\t\\tAllocation Record List {self.H=}')    \n",
    "\n",
    "        # cost at edge node\n",
    "        Ce = (self.E-self.et)*self.Pf + (self.et)*self.Pe\n",
    "\n",
    "        # cost at private cloud\n",
    "        Cpri = c*self.Pc + Ce\n",
    "        if verb:\n",
    "            print(f'\\tCost At Edge Node, {Ce=}')\n",
    "            print(f'\\tCost At Private Cloud, {Cpri=}')\n",
    "\n",
    "        #<------------------------------- round \n",
    "\n",
    "        # update allocation record\n",
    "        for el in self.H: el[-1]-=1\n",
    "        # release exsisting VMs\n",
    "        # remove completed records\n",
    "        i=0\n",
    "        n=0 # no of busy vms (waiting to be released)\n",
    "        while i < len(self.H):\n",
    "            if self.H[i][-1]==0: \n",
    "                n+=self.H[i][0] # reclaim\n",
    "                del self.H[i]   # remove\n",
    "            else: i+=1 # skip\n",
    "        \n",
    "        if verb:\n",
    "            print(f'\\tUpdated Allocation Record List {self.H=}')  \n",
    "            print(f'\\tVMs waiting to be released {n=}')\n",
    "\n",
    "        self.et += n # update available\n",
    "        if verb: print(f'\\tVMs available at next time slot {self.et=}')\n",
    "        return Cpri\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Environment for RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class Environment: # Encapsulates an MDP for agent interaction\n",
    "    def __init__(self, E, D, L, T, Pefc, seed=None ) -> None:\n",
    "        self.E, self.D, self.L, self.T = E, D, L, T\n",
    "\n",
    "        self.nS = self.T*self.D*self.L*(self.E+1)\n",
    "        self.nD = self.D*self.L\n",
    "        self.DL = np.array([ [(d,l) for l in range(1, L+1)] for d in range(1, D+1)])\n",
    "        self.DL_ = self.DL.reshape(self.DL.shape[0]*self.DL.shape[1], self.DL.shape[2])\n",
    "        self.dls = np.arange(len(self.DL_))\n",
    "        self.S = np.zeros(4, dtype=int) #(etdl)\n",
    "        self.A=[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "        self.nA = len(self.A)\n",
    "        self.sim = System(E, Pefc)\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.sim.reset()\n",
    "        self.S[0] = self.sim.et\n",
    "        self.S[1] = self.sim.t\n",
    "        self.S[2:] = self.DL_[self.rng.choice(self.dls)]\n",
    "        return self.S\n",
    "\n",
    "    def step(self, action):\n",
    "        #print(f'{self.S=}, {self.A=}::{action=}')\n",
    "        cost = self.sim.step(d=self.S[2], l=self.S[3], a=self.A[action])\n",
    "        done = not(self.sim.t < self.T)\n",
    "        self.S[0] = self.sim.et\n",
    "        self.S[1] = self.sim.t\n",
    "        self.S[2:] = 0 if done else self.DL_[self.rng.choice(self.dls)]\n",
    "        return self.S, float(-cost), done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'E': 19,\n",
       " 'D': 4,\n",
       " 'L': 3,\n",
       " 'T': 15,\n",
       " 'nS': 3600,\n",
       " 'nD': 12,\n",
       " 'DL': array([[[1, 1],\n",
       "         [1, 2],\n",
       "         [1, 3]],\n",
       " \n",
       "        [[2, 1],\n",
       "         [2, 2],\n",
       "         [2, 3]],\n",
       " \n",
       "        [[3, 1],\n",
       "         [3, 2],\n",
       "         [3, 3]],\n",
       " \n",
       "        [[4, 1],\n",
       "         [4, 2],\n",
       "         [4, 3]]]),\n",
       " 'DL_': array([[1, 1],\n",
       "        [1, 2],\n",
       "        [1, 3],\n",
       "        [2, 1],\n",
       "        [2, 2],\n",
       "        [2, 3],\n",
       "        [3, 1],\n",
       "        [3, 2],\n",
       "        [3, 3],\n",
       "        [4, 1],\n",
       "        [4, 2],\n",
       "        [4, 3]]),\n",
       " 'dls': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]),\n",
       " 'S': array([0, 0, 0, 0]),\n",
       " 'A': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
       " 'nA': 11,\n",
       " 'sim': <__main__.System at 0x1b26a1f1490>,\n",
       " 'rng': Generator(PCG64) at 0x1B26A241B60}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = Environment(E=19, D=4, L=3, T=15, Pefc=(0.03, 0.20, 3.00), seed=13)\n",
    "env.sim.verbose=False\n",
    "env.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_Learning(\n",
    "        mdp,    # formulated mdp \n",
    "        πe,     # behaviour policy\n",
    "        α,      # learning rate\n",
    "        γ,      # discount factor\n",
    "        N,      # number of learning rounds\n",
    "    ):\n",
    "    Q = {}  # initialize Q-Table\n",
    "    s = tuple(mdp.reset()) # reset the mdp and obtain initial state\n",
    "    if s not in Q: \n",
    "        # add obtained state to Q-Table and initalize values as zeros\n",
    "        Q[s] = [0.0 for _ in range(mdp.nA)] \n",
    "\n",
    "    for n in range(N): # learning loop\n",
    "        a = πe(s, Q) # select action using behaviour policy\n",
    "        s_, r,  done = mdp.step(a) # obtain reward(r) and next state(s_)\n",
    "        s_ = tuple(s_)\n",
    "        if s_ not in Q: \n",
    "            # add obtained next state to Q-Table and initalize values as zeros\n",
    "            Q[s_] = [0.0 for _ in range(mdp.nA)]\n",
    "        \n",
    "        Q[s][a] = (1-α) * Q[s][a] + (α) * (r + γ * max(Q[s_])) # update Q-values\n",
    "        if done: # final state reached?\n",
    "            s = tuple(mdp.reset()) # reset the mdp\n",
    "            if s not in Q: Q[s] = [0.0 for _ in range(mdp.nA)]\n",
    "        else:\n",
    "            s = s_  # continue to next time step\n",
    "    return Q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epsilon Greedy Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpsilonGreedyPolicy:\n",
    "    def __init__(self, n_actions, seed=None) -> None: \n",
    "        self.n_actions, self.eps, self.decay, self.rng = n_actions, 1.0, 0.0, np.random.default_rng(seed)\n",
    "    def set_epsilon(self, eps): self.eps = eps\n",
    "    def set_decay(self, delta): self.delta = delta\n",
    "    def __call__(self, state, Q): \n",
    "        a = self.rng.integers(0,self.n_actions) if self.rng.random()<self.eps else np.argmax(Q[state])\n",
    "        self.eps-=self.delta\n",
    "        return a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Q-Learning Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "behave = EpsilonGreedyPolicy(env.nA, seed=2654)\n",
    "behave.set_epsilon(1.0)\n",
    "behave.set_decay(1/100000)\n",
    "q = Q_Learning(env, behave, 0.5, 1.0, 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learnt Q-Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learnt policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_Policy(mdp, Q):\n",
    "    s = tuple(mdp.reset())\n",
    "    done = False\n",
    "    cost = 0.0\n",
    "    actions = []\n",
    "    while not done:\n",
    "        q = Q[s]\n",
    "        a = np.argmax(q)\n",
    "        s_, r,  done = mdp.step(a)\n",
    "        s_ = tuple(s_)\n",
    "        cost+= (-r) # -(cost_at_private_cloud:c_pri)\n",
    "        actions.append(env.A[a])\n",
    "        print(f'{s=}, {a=}:{env.A[a]}, {r=:.5f}, {s_=}, {done=}, {cost=:.5f}')\n",
    "        s= s_\n",
    "    return cost, actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Learnt policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s=(19, 0, 2, 2), a=3:0.3, r=-0.91000, s_=(17, 1, 4, 1), done=False, cost=0.91000\n",
      "s=(17, 1, 4, 1), a=0:0.0, r=-1.59000, s_=(19, 2, 2, 1), done=False, cost=2.50000\n",
      "s=(19, 2, 2, 1), a=5:0.5, r=-3.74000, s_=(19, 3, 1, 2), done=False, cost=6.24000\n",
      "s=(19, 3, 1, 2), a=7:0.7, r=-0.74000, s_=(18, 4, 1, 1), done=False, cost=6.98000\n",
      "s=(18, 4, 1, 1), a=7:0.7, r=-0.91000, s_=(19, 5, 2, 3), done=False, cost=7.89000\n",
      "s=(19, 5, 2, 3), a=8:0.8, r=-3.74000, s_=(18, 6, 3, 1), done=False, cost=11.63000\n",
      "s=(18, 6, 3, 1), a=0:0.0, r=-1.25000, s_=(18, 7, 2, 3), done=False, cost=12.88000\n",
      "s=(18, 7, 2, 3), a=3:0.3, r=-1.08000, s_=(17, 8, 2, 3), done=False, cost=13.96000\n",
      "s=(17, 8, 2, 3), a=0:0.0, r=-1.25000, s_=(15, 9, 3, 3), done=False, cost=15.21000\n",
      "s=(15, 9, 3, 3), a=1:0.1, r=-1.76000, s_=(14, 10, 2, 2), done=False, cost=16.97000\n",
      "s=(14, 10, 2, 2), a=3:0.3, r=-1.76000, s_=(14, 11, 4, 2), done=False, cost=18.73000\n",
      "s=(14, 11, 4, 2), a=2:0.2, r=-2.10000, s_=(15, 12, 4, 1), done=False, cost=20.83000\n",
      "s=(15, 12, 4, 1), a=1:0.1, r=-1.93000, s_=(19, 13, 3, 3), done=False, cost=22.76000\n",
      "s=(19, 13, 3, 3), a=2:0.2, r=-1.08000, s_=(16, 14, 2, 2), done=False, cost=23.84000\n",
      "s=(16, 14, 2, 2), a=2:0.2, r=-1.42000, s_=(14, 15, 0, 0), done=True, cost=25.26000\n",
      "actions: [0.3, 0.0, 0.5, 0.7, 0.7, 0.8, 0.0, 0.3, 0.0, 0.1, 0.3, 0.2, 0.1, 0.2, 0.2]\n",
      "cost 25.26000\n"
     ]
    }
   ],
   "source": [
    "ret, acts = Q_Policy(env, q)\n",
    "print(f'actions: {acts}')\n",
    "print(f'cost {ret:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Simulation\n",
    "\n",
    "(for worked out examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'E': 80, 'H': [], 'Pe': 0.03, 'Pf': 0.2, 'Pc': 3.0, 'verbose': True, 'et': 80, 't': 0}\n"
     ]
    }
   ],
   "source": [
    "S = System(E=80, Pefc=(0.03, 0.20, 3.00)).reset()\n",
    "S.verbose=True\n",
    "print(S.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.t=1\n",
      "\tDemand, (30, 2)\n",
      "\tAction, 0.4\n",
      "\tAllocated from Cloud, c=12\n",
      "\tAllocated from Edge, e=18\n",
      "\tRemaining, self.et=62\n",
      "\t\tAllocation Record, [18, 2]\n",
      "\t\tAllocation Record List self.H=[[18, 2]]\n",
      "\tCost At Edge Node, Ce=5.46\n",
      "\tCost At Private Cloud, Cpri=41.46\n",
      "\tUpdated Allocation Record List self.H=[[18, 1]]\n",
      "\tVMs waiting to be released n=0\n",
      "\tVMs available at next time slot self.et=62\n",
      "{'E': 80, 'H': [[18, 1]], 'Pe': 0.03, 'Pf': 0.2, 'Pc': 3.0, 'verbose': True, 'et': 62, 't': 1}\n"
     ]
    }
   ],
   "source": [
    "cost = S.step(d=30, l=2, a=0.4)\n",
    "print(S.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.t=2\n",
      "\tDemand, (10, 1)\n",
      "\tAction, 0.7\n",
      "\tAllocated from Cloud, c=7\n",
      "\tAllocated from Edge, e=3\n",
      "\tRemaining, self.et=59\n",
      "\t\tAllocation Record, [3, 1]\n",
      "\t\tAllocation Record List self.H=[[18, 1], [3, 1]]\n",
      "\tCost At Edge Node, Ce=5.970000000000001\n",
      "\tCost At Private Cloud, Cpri=26.97\n",
      "\tUpdated Allocation Record List self.H=[]\n",
      "\tVMs waiting to be released n=21\n",
      "\tVMs available at next time slot self.et=80\n",
      "{'E': 80, 'H': [], 'Pe': 0.03, 'Pf': 0.2, 'Pc': 3.0, 'verbose': True, 'et': 80, 't': 2}\n"
     ]
    }
   ],
   "source": [
    "cost = S.step(d=10, l=1, a=0.7)\n",
    "print(S.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.t=3\n",
      "\tDemand, (20, 2)\n",
      "\tAction, 0.8\n",
      "\tAllocated from Cloud, c=16\n",
      "\tAllocated from Edge, e=4\n",
      "\tRemaining, self.et=76\n",
      "\t\tAllocation Record, [4, 2]\n",
      "\t\tAllocation Record List self.H=[[4, 2]]\n",
      "\tCost At Edge Node, Ce=3.08\n",
      "\tCost At Private Cloud, Cpri=51.08\n",
      "\tUpdated Allocation Record List self.H=[[4, 1]]\n",
      "\tVMs waiting to be released n=0\n",
      "\tVMs available at next time slot self.et=76\n",
      "{'E': 80, 'H': [[4, 1]], 'Pe': 0.03, 'Pf': 0.2, 'Pc': 3.0, 'verbose': True, 'et': 76, 't': 3}\n"
     ]
    }
   ],
   "source": [
    "cost = S.step(d=20, l=2, a=0.8)\n",
    "print(S.__dict__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
