{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ECG_10_[BASE].ipynb","provenance":[{"file_id":"1J5cuzyRx4ipySODOz_-7RhQ349UiFajE","timestamp":1590384321091}],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1J5cuzyRx4ipySODOz_-7RhQ349UiFajE","authorship_tag":"ABX9TyPwldQeCRM6Fp3tmJz3loq2"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"R0KnOnj24WK8","colab_type":"code","colab":{}},"source":["%reset"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AmAt0eBV4uXG","colab_type":"text"},"source":["# [ 0_IMPORTS ]"]},{"cell_type":"code","metadata":{"id":"xfdnlj8y41qm","colab_type":"code","colab":{}},"source":["import datetime\n","import os\n","import random\n","import statistics as stats\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","\n","import scipy.signal as scsig\n","from scipy.io import loadmat\n","from scipy.signal import medfilt\n","import pywt\n","from pywt import wavedec\n","#import hrv\n","#from ecgdetectors import Detectors\n","\n","import tensorflow as tf\n","from tensorflow.keras.layers import Dense, Input, LSTM, Conv1D, MaxPooling1D, Flatten\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow import keras\n","from tensorflow.keras.utils import to_categorical\n","import tensorflow.keras.backend as kbend\n","\n","from sklearn.cluster import DBSCAN\n","from sklearn import metrics\n","import scipy.spatial.distance as disf"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jMKA499Q4_0r","colab_type":"text"},"source":["# [ 1_GLOBAL ]"]},{"cell_type":"code","metadata":{"id":"hpb-HZz75Dsp","colab_type":"code","colab":{}},"source":["\n","#===========================================================================================================\n","# DEFINE SOURCE DIRECTORIES\n","#===========================================================================================================\n","# > _ base working directory\n","global_dir = '/content/drive/My Drive/Masters/workdir/ecg_data' #'/home/spooky/ecg/workdir'\n","print('GLOBAL DIR :: '+global_dir)\n","\n","# >> global annotation and mapping, common for all ECG from https://physionet.org/about/database/\n","global_annot = '/content/drive/My Drive/Masters/workdir/ecg_data/annotations.txt' #'/home/spooky/ecg/workdir/ecg_code/v2/annotations.txt'\n","#os.path.join(global_dir, 'annotations.txt' ) \n","print('GLOBAL ANNOTATIONS :: '+global_annot)\n","\n","# >> global model directory, contains model weights, use load_weights(), save_weights() \n","global_modeldir = os.path.join(global_dir, 'db_model') \n","os.makedirs(global_modeldir , exist_ok = True) \n","print('GLOBAL MODEL DIR :: '+global_modeldir)\n","\n","# >> global dataset directory, contains manually generated datasets to be used for experiments\n","global_datadir = os.path.join(global_dir, 'db_dataset') \n","os.makedirs(global_datadir , exist_ok = True) \n","print('GLOBAL DATA DIR :: '+global_datadir)\n","\n","\n","#===========================================================================================================\n","ds_name = 'custom_ds'\n","ds_dir = os.path.join(global_datadir, ds_name) \n","os.makedirs(ds_dir , exist_ok = True) \n","print('CUSTOM DATA DIR :: '+ds_dir)\n","#%%\n","\n","#===========================================================================================================\n","#  Define annotation mapping dictionary (from global_annot)\n","#=========================================================================================================== \n","g_map_data = np.loadtxt(global_annot, dtype='str',delimiter=\"\\t\")\n","g_map={}\n","g_map_beat_ants=[]\n","g_map_non_beat_ants=[]\n","print('ANNOTATION MAPPING :: ')\n","for a in g_map_data:\n","\n","    g_mit_label = a[0] # orignal mit label (char)\n","    g_int_label = a[1] # mapped integer label (int)\n","    g_beat_description = a[2] # description (str)\n","\n","    g_map[g_mit_label]= int(g_int_label) ##<<----------------mapping dictionary\n","\n","    print(g_mit_label+'\\t'+g_int_label+'\\t'+g_beat_description)\n","    \n","    if int(g_int_label)>-2:\n","        g_map_beat_ants.append(g_mit_label)  #<<----beat annotation\n","    else:\n","        g_map_non_beat_ants.append(g_mit_label)  #<<----beat annotation\n","\n","#g_map_keys = g_map.keys()\n","#print('\\nAll Annotations : [' + str(len(g_map_keys))+'] :: ' + str(g_map_keys))\n","print('')\n","print('Beat Annotations : [' + str(len(g_map_beat_ants))+'] :: ' + str(g_map_beat_ants))\n","print('Non-Beat Annotations : [' + str(len(g_map_non_beat_ants))+'] :: ' + str(g_map_non_beat_ants))\n","print('All Annotations : [' + str(len(g_map.keys()))+'] :: ' + str(g_map.keys()))\n","print('')\n","def mapstd(peak_label):\n","    res = np.zeros(len(peak_label),dtype='int')\n","    for i in range(0, len(peak_label)):\n","        res[i] = g_map[peak_label[i]]\n","    return res\n","\n","g_LMAX = np.max(np.array(list(g_map.values()))) # this is max mapping value starting from 0\n","g_LMIN = -1 # this means unmapped (RR beat), \n","#anything less than g_LMIN is unmapped(Non RR beat) and anythone greater is mapped(RR beat)\n","print('Integer Label Range [ '+str(g_LMIN)+ ' : '+str(g_LMAX)+' ]')\n","g_LABELS= ['N','X']\n","g_COLOR=['tab:green','tab:red']\n","# [N] Normal, \n","# [S] Supraventricular-Premature, \n","# [V] Ventricular-Premature, \n","# [F] Fusion, \n","#===========================================================================================================\n","\n","#------------------------------------------------------------------------------------------------\n","# signal sampling params\n","#------------------------------------------------------------------------------------------------\n","BASIC_SRATE = 128 #Hz\n","print('Basic sampling rate(Hz): '+str(BASIC_SRATE))\n","\n","# fixed input dimension for beat vector\n","v_dimC = int(round((3*BASIC_SRATE))) # 3 seconds\n","print('Fixed dimension of beat vector: '+str(v_dimC))\n","# beat and non-beat annotations, signal data types\n","g_BEAT_POSTFIX, g_NBEAT_POSTFIX = 'BEAT', 'NBEAT' \n","g_SIG_II_POSTFIX = 'SIG_II'\n","g_FIX_II_POSTFIX = 'FIX_II'\n","\n","#%%\n","\n","#------------------------------------------------------------------------------------------------\n","# Hear-Rate Params\n","#------------------------------------------------------------------------------------------------\n","H_min = 20          #bpm\n","max_rri = 60/H_min  #sec\n","\n","H_low = 60          #bpm\n","hig_rri = 60/H_low  #sec\n","\n","H_hig = 100         #bpm\n","low_rri = 60/H_hig  #sec\n","\n","H_max = 240         #bpm\n","min_rri = 60/H_max  #sec\n","\n","#%%\n","#=========================================================================================================================\n","#======================= NEURAL NETWORK PERFORMANCE MEASURES\n","#=========================================================================================================================\n","# 3.3 :: define performance evaluation functions\n","\n","def get_performance(conf_matrix):\n","    #how many classes? = len of conf_matril\n","    nos_class = len(conf_matrix[0,:]) # len of 0th row\n","    res = np.zeros((0,8),dtype ='float64')\n","    for i in range(0,nos_class):\n","        # for each class calculate 4 performance measure - ACC, PRE, SEN, SPF, \n","        # first compute TP, TN, FP, FN\n","        TP = conf_matrix[i,i]\n","        FP = np.sum(conf_matrix[:,i]) - TP\n","        FN = np.sum(conf_matrix[i,:]) - TP\n","        TN = np.sum(conf_matrix) - FN - FP - TP\n","\n","        ACC = (TP+TN)   /   (TP+FP+FN+TN)\n","        PRE = (TP)      /   (TP+FP)\n","        SEN = (TP)      /   (TP+FN)\n","        SPF = (TN)      /   (TN+FP)\n","\n","        res_i = np.array([TP, FN, FP, TN, ACC, PRE, SEN, SPF])\n","        res = np.vstack((res,res_i))\n","    return res\n","\n","\n","#------------------------------------------------------------------PRINTING\n","\n","def print_lstr(class_labels):\n","    g_LSTR=''   # HEADER ROW for printing confusing matrix\n","    for i in range(0,len(class_labels)):\n","        g_LSTR+='\\t'+str(class_labels[i])\n","    return  g_LSTR\n","\n","def print_cf_row(cf_row,nos_labels):\n","    res = ''\n","    for j in range(0,nos_labels):\n","        res += '\\t'+ str(cf_row[j])\n","    return res\n","def print_conf_matrix(conf_matrix, suffix, class_labels):\n","    res=(suffix+'A\\\\P' + print_lstr(class_labels)+'\\n')\n","    nos_l=len(class_labels)\n","    for i in range(0,nos_l):\n","        res+=(suffix+str(class_labels[i]) + print_cf_row(conf_matrix[i],nos_l )+'\\n')\n","    return res\n","def print_performance(perf_measures, class_labels):\n","    nos_class = len(perf_measures[:,0])\n","    print('Performance for '+str(nos_class)+' classes')\n","    print ('Class\\tACC\\tPRE\\tSEN\\tSPF')\n","    for i in range(0, nos_class):\n","        perf_i = np.round(perf_measures [i,:],2)\n","        #print('\\tT.P : '+str(perf_i[0])+'\\tF.N : '+str(perf_i[1]))\n","        #print('\\tF.P : '+str(perf_i[2])+'\\tT.N : '+str(perf_i[3]))\n","        print(str(class_labels[i])+'\\t'+str(perf_i[4])+'\\t'+str(perf_i[5])+'\\t'+str(perf_i[6])+'\\t'+str(perf_i[7]))\n","    return\n","#------------------------------------------------------------------\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t4j5Acg_57cl","colab_type":"text"},"source":["# [ 2_CLASS_DEFS ]"]},{"cell_type":"code","metadata":{"id":"lgUkvPIQ6AKA","colab_type":"code","colab":{}},"source":["#Class Definitions\n","#---------------------------------------------------------------------------------------------------------------------------------------------\n","# CLASS ecg_db : represents one ECG database\n","#---------------------------------------------------------------------------------------------------------------------------------------------\n","class ecg_db:\n","    def __init__(self, dbname,  exclude_recs, tag_recs, sampling_rate):\n","        print('\\nInitailze new ecg database ... ')\n","        self.name = dbname  #str\n","        self.srate = sampling_rate #float or int\n","        self.dir_ds = os.path.join(global_datadir , dbname+'_ds') #str\n","        self.recs_all = set(np.loadtxt(os.path.join(self.dir_ds,'RECORDS'), dtype='str',delimiter=\"\\n\")) #set\n","        self.recs_exc = set(exclude_recs)\n","        self.recs = set.difference(self.recs_all, self.recs_exc) \n","        self.recs_tag = set(tag_recs)\n","\n","        self.recs_dict = {} # initially empty, will be loaded on demand using function 'get_record'\n","        self.info()\n","\n","    def info(self):\n","        print( 'DB NAME :: '+ self.name)\n","        print( 'SAMPLING RATE :: '+ str(self.srate))\n","        print( 'DATA DIR :: ' + self.dir_ds )\n","        print( 'RECORD SET :: [' +str(len(self.recs))+'] ' + str(self.recs) )\n","        return 0\n","\n","    def get_record(self,rec):\n","        if not (rec in self.recs_dict.keys()):\n","            self.recs_dict[rec] = ecg_record(self,rec)\n","        return self.recs_dict[rec]\n","    \n","    def get_random_record(self, recset):\n","        rec = random.choice(list(recset))\n","        if not (rec in self.recs_dict.keys()):\n","            self.recs_dict[rec] = ecg_record(self,rec)\n","        return self.recs_dict[rec]\n","\n","#---------------------------------------------------------------------------------------------------------------------------------------------\n","\n","#---------------------------------------------------------------------------------------------------------------------------------------------\n","# CLASS ecg_record : represents one ECG Record in any database\n","#---------------------------------------------------------------------------------------------------------------------------------------------\n","g_SUPRESS_DATA_WARNING=False\n","class ecg_record:\n","\n","    def __init__(self, db, recname):\n","        self.db = db                                # class:{ecg_db}    object this record belongs to\n","        self.rec = recname                          # string            name of this record\n","        self.name = db.name + '_'+ recname          # string            full name including db.name\n","        if recname in db.recs_all:\n","            if recname in db.recs_exc:\n","                print('WARNING:: Record \"'+ recname +'\" is marked excluded from database '+ db.name )\n","        else:\n","            print('WARNING:: Record \"'+ recname +'\" not found in database '+ db.name )\n","        self.data = {}                              # dict dict of npy data file content used in self.read_data('key')\n","        self.binfo = None                           # class binfo       \n","\n","    def read_binfo(self):\n","        if self.binfo == None:\n","            self.binfo = ecg_binfo(self)\n","        return self.binfo\n","    \n","    def load_data(self, data_type):\n","        ipath = os.path.join(self.db.dir_ds, self.rec + '_'+data_type+'.npy')\n","        try: # try to load this data\n","            self.data[data_type] = np.load(ipath) # adds this to dictionary so next time it can read\n","            return self.data[data_type] #= np.load(self.dirs[s])\n","        except:\n","            if g_SUPRESS_DATA_WARNING == False:\n","                print('WARNING:: Cant load \"'+data_type+ '\" file at '+ str(ipath) )\n","            return np.array([])\n","        \n","    def read_data(self, data_type):\n","        if data_type in self.data.keys():\n","            return self.data[data_type] #= np.load(self.dirs[s])\n","        else:\n","            return self.load_data(data_type)\n","\n","    def save_data(self, data_type, data_array):\n","        ipath = os.path.join(self.db.dir_ds, self.rec + '_'+data_type+'.npy')\n","        np.save(ipath, data_array)\n","        return ipath\n","\n","    def del_data(self, data_type, vb):\n","        ipath = os.path.join(self.db.dir_ds, self.rec + '_'+data_type+'.npy')\n","        if os.path.exists(ipath):\n","            if vb:\n","                print('Removing: '+str(ipath))\n","            os.remove(ipath)\n","            return 1\n","        else:\n","            return 0\n","\n","#---------------------------------------------------------------------------------------------------------------------------------------------\n","\n","#------------------------------------------------------------------------------------------------\n","\n","class ecg_binfo:\n","    def __init__(self, rec):\n","        self.rec = rec          # the record object\n","        rr_peaks_ants = rec.read_data(g_BEAT_POSTFIX)       # orignal ant file [ *  '625310' 'N' * ]\n","        # slice array\n","        rr_peaks_int = rr_peaks_ants[:,0].astype('int')     # col0 : samples * 62531 *  <---------------- not excluded\n","        rr_ants_str = rr_peaks_ants[:,1]                    # col1 : labels * 'N' *     <---------------- not excluded\n","        # excluded first and last\n","        self.rr_peaks = rr_peaks_int[1:-1]                  # col0 : samples (int) 62531 ==>==>==> sample# (orignal)\n","        self.rr_prev = rr_peaks_int[0:-2]                   # prev R peak (in samples)\n","        self.rr_next = rr_peaks_int[2:]                                           # next R peak (in samples)\n","        self.nos_rr_peaks = len(self.rr_peaks)              # no fo RR peaks (excluding first and last)\n","        \n","        self.rr_labels = rr_ants_str[1:-1]                  # col1 : labels (str)  'N'  ==>==>==> mit label (orignal)\n","        self.rr_plabels = rr_ants_str[0:-2]                  # col1 : labels (str)  'N'  ==>==>==> mit label (orignal)\n","        self.rr_nlabels = rr_ants_str[2:]                  # col1 : labels (str)  'N'  ==>==>==> mit label (orignal)\n","        \n","        self.rr_int_labels = mapstd(self.rr_labels)         # col1 : mapped int labels ==>==>==> int label (mapped -1, 0 ...) cant be -2 in \n","        self.rr_int_plabels = mapstd(self.rr_plabels) \n","        self.rr_int_nlabels = mapstd(self.rr_nlabels) \n","\n","        #temporal info\n","        self.rr_peaks_sec = self.rr_peaks / rec.db.srate             # col0 : time in sec (float) ==>==>==> sample (time in sec) sample#/srate\n","        self.rri_prev = (self.rr_peaks - self.rr_prev) / rec.db.srate   # prev RRI (in sec) \n","        self.rri_next = (self.rr_next - self.rr_peaks) / rec.db.srate  # next RRI (in sec) \n","        self.rri_delta = (self.rri_next - self.rri_prev)        # difference b/w prev and next RRI in seconds \n","        self.rri_dur = (self.rri_next + self.rri_prev)\n","        #self.rri_avg = (self.dur) / (2)    # avg of prev and next RRI in seconds ==>==>==> length of the beat (prev R to next R peak)\n","        #self.rr_signal = []\n","        #self.rr_signal_fixed = []\n","        self.sr_ratio = BASIC_SRATE/self.rec.db.srate\n","\n","    def get_signal_data_var(self, ith_peak): # data_type = g_SIG_II_POSTFIX\n","    # prev peak to next peak\n","        sel_sig = self.rec.read_data(g_SIG_II_POSTFIX) \n","        ff = int(self.rr_prev[ith_peak]*self.sr_ratio)\n","        tt = int(self.rr_next[ith_peak]*self.sr_ratio)\n","        pp = int(self.rr_peaks[ith_peak]*self.sr_ratio)\n","        return sel_sig[ff:tt+1], (pp-ff) #<- also return position of peak\n","    \n","    def get_signal_data_fix(self, ith_peak, v_left_sec, v_right_sec): # data_type = g_SIG_II_POSTFIX\n","        sel_sig = self.rec.read_data(g_SIG_II_POSTFIX) \n","        #sr_ratio = BASIC_SRATE/self.rec.db.srate\n","        ff = int((self.rr_peaks[ith_peak]*self.sr_ratio)-(v_left_sec*BASIC_SRATE))\n","        tt = int((self.rr_peaks[ith_peak]*self.sr_ratio)+(v_right_sec*BASIC_SRATE))\n","        pp = int(self.rr_peaks[ith_peak]*self.sr_ratio)\n","        return sel_sig[ff:tt+1], (pp-ff) #<- also return position of peak\n","    \n","#-----------------------------------------------------------------------------------------------\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nda73nsb6MEs","colab_type":"text"},"source":["# [ 3_BUILD_ALL_DB ]"]},{"cell_type":"code","metadata":{"id":"N4Ng7DvJ6QvJ","colab_type":"code","colab":{}},"source":["all_db = {}\n","#------------------------------------------------------------------------\n","mitdb_ex = ['102', '104', '107', '217', \n","            '212', '231',  '207']\n","all_db['mitdb'] = ecg_db('mitdb',  mitdb_ex, [], 360)\n","#------------------------------------------------------------------------\n","svdb_ex = []\n","all_db['svdb'] = ecg_db('svdb',  svdb_ex, [], 128)\n","#------------------------------------------------------------------------\n","incartdb_ex = []\n","all_db['incartdb'] = ecg_db('incartdb', incartdb_ex, [], 257)\n","#------------------------------------------------------------------------\n","#print(all_db.values())\n","print('')\n","print(all_db.keys())\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NgNc1QvnL8UE","colab_type":"text"},"source":["## [ 3.0_REPORT_DBS ]"]},{"cell_type":"code","metadata":{"id":"AcKTu7G-MB73","colab_type":"code","colab":{}},"source":["heading = 'DB_RECORD'\n","for i in range(0,len(g_map_beat_ants)):\n","    heading+='\\t'+str(g_map_beat_ants[i])\n","heading+='\\tTOTAL'\n","print(heading)\n","\n","for idb in all_db.keys():\n","    sel_db = all_db[idb]\n","    #if idb != 'mitdb':\n","    #    continue\n","    for irec in sel_db.recs:\n","       # if irec != '208':\n","       #     continue\n","        sel_rec = sel_db.get_record(irec)\n","        rst = sel_rec.name + '\\t'\n","\n","        sbi = sel_rec.read_binfo()\n","\n","        count_all = 0\n","        for i in range(0,len(g_map_beat_ants)):\n","            count_i = len(np.where(sbi.rr_labels==g_map_beat_ants[i])[0])\n","            count_all+=count_i\n","            rst+=str(count_i)+'\\t'\n","        rst+=str(count_all)\n","        print(rst)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fao6o-Zc6a37","colab_type":"text"},"source":["## [ 3.1_REP_NORMALS ]"]},{"cell_type":"code","metadata":{"id":"DfZbkP-y6pT0","colab_type":"code","colab":{}},"source":["#------------------------------------------------------------------------\n","lim_first_F_sec = 5*60 # 5 or 30 minutes #<<====select this\n","#------------------------------------------------------------------------\n","work_db = all_db #<<------------ select working db\n","\n","g_REP_II_POSTFIX = 'REP_'+str(lim_first_F_sec) # representative normal all record\n","lim_delta_rri = 0.04\n","lim_min_Nbeats = 3\n","#------------------------------------------------------------------------\n","\n","print('=================================================')\n","print('Representative Normal')\n","print('lim_delta_rri:'+str(lim_delta_rri))\n","print('lim_min_Nbeats_per_episode:'+str(lim_min_Nbeats))\n","print('lim_first_F_sec:'+str(lim_first_F_sec))\n","print('g_REP_II_POSTFIX:'+str(g_REP_II_POSTFIX))\n","print('=================================================')\n","\n","timestamp_start = datetime.datetime.now()\n","print('REC\\ttotal_beats_in_n_query\\ttotal_n_episodes\\tvalid_n_episodes\\tResult')\n","\n","for idb in work_db.keys():\n","    sel_db = work_db[idb]\n","    #if idb != 'mitdb':\n","    #    continue\n","    for irec in sel_db.recs:      \n","       # if irec != '208':\n","      #      continue\n","        sel_rec = sel_db.get_record(irec)\n","        rst = sel_rec.name\n","\n","#--------# load signal----------------------------------------\n","        sel_sig = sel_rec.read_data(g_SIG_II_POSTFIX)\n","        if len(sel_sig)<1:\n","            rst+='\\tSignal doesnt exist, Skip this record'\n","            print(rst)\n","            continue\n","        \n","#--------# load beat info----------------------------------------\n","        sbi = sel_rec.read_binfo()\n","\n","#-------# Normal Episodes----------------------------------------\n","        ne_list = []\n","        ne_query = (\n","                    (sbi.rr_peaks_sec <= lim_first_F_sec) &\n","                    (np.absolute(sbi.rri_delta)<=lim_delta_rri) & \n","                    (sbi.rr_int_labels==0)  &\n","                    (sbi.rr_int_plabels==0)  &\n","                    (sbi.rr_int_nlabels==0)\n","                  )\n","        \n","        ne_list = np.where(ne_query)[0]\n","        \n","        if len(ne_list)<lim_min_Nbeats:\n","            rst+='\\tNot enough N beats within rri limits, Skip this record'\n","            print(rst )\n","            continue\n","        else:\n","            rst+='\\t'+str(len(ne_list))   \n","            \n","        ne_list1 = np.hstack((np.sort(ne_list),np.array([-1])))\n","        n_epi = []\n","        # extract episodes from ne_list\n","        n_s = ne_list[0]\n","        delta = 1\n","        for i in range(1, len(ne_list1)):\n","            n_e = ne_list1[i]\n","            if n_e == n_s + delta:\n","                delta+=1\n","            else:\n","                # check if enough number of N beats exist\n","                # if delta >=lim_min_Nbeats:\n","                n_epi.append([n_s,n_s+delta])\n","                n_s = n_e\n","                delta = 1\n","\n","        if len(n_epi)==0:\n","            rst+='\\tNot enough episodes, Skip this record'\n","            print(rst)\n","            continue    \n","        else:\n","            rst+='\\t'+ str(len(n_epi))\n","\n","        # select from all episodes\n","        # [epi_index,nos_beats, avg_dur,var_dur,max_dur(signal_len) ]\n","        \n","        mega_epi = np.zeros((0,2*v_dimC + 4),dtype='float')\n","        # 2*vdim for resampled median and mean, \n","        # +4 for avg_dur, var_dur, nos_beats, actual signal_len\n","        \n","        epi_stats = np.zeros((0,4),dtype='float')\n","        #epi_short = 0\n","        for j in range(0, len(n_epi)):\n","            sepi = n_epi[j]\n","            bepi = sepi[1]-sepi[0]\n","            if bepi<lim_min_Nbeats:\n","                # print('Not enough beats in this episode, skip')\n","                # epi_short+=1\n","                continue\n","            else:\n","                sdur =  sbi.rri_dur[sepi[0]:sepi[1]]\n","                sdur_avg = round(stats.mean(sdur),3)\n","                sdur_var = round(stats.variance(sdur),5)\n","                epi_stats = np.vstack((epi_stats,np.array([j,bepi,sdur_avg,sdur_var])))\n","                # print('Avg_duration = '+ str(sdur_avg)+ ' | bpm = '+ str(60/sdur_avg))\n","                # print('VAr_duration = '+ str(sdur_var))\n","                # print('#'+str(j)+'\\t'+str(bepi)+'\\t'+str(sdur_avg)+'\\t'+str(sdur_var))\n","                \n","                #now for each episode find            \n","                all_epi_signals = []\n","                all_epi_pk = []\n","                sg_left=[]\n","                sg_right=[]\n","                sll,slr = [],[]\n","                \n","                for i in range(sepi[0],sepi[1]):\n","                    sg,pk = sbi.get_signal_data_var(i)\n","                    all_epi_signals.append(sg)\n","                    all_epi_pk.append(pk)\n","                    sg_left.append(sg[0:pk])\n","                    sg_right.append(sg[pk:])\n","                    sll.append(pk)\n","                    slr.append(len(sg)-pk)\n","                \n","                ll_max = max(sll)\n","                lr_max = max(slr)\n","                l_max = ll_max+lr_max                \n","                \n","                sg_all2 =  np.zeros((0,l_max))\n","                for i in range(0, bepi):    \n","                    sg_all2 = np.vstack((\n","                                    sg_all2,\n","                                    np.hstack((\n","                                        scsig.resample(sg_left[i],ll_max), \n","                                        scsig.resample(sg_right[i],lr_max)\n","                                        ))\n","                                    ))\n","                \n","                x3_men = np.zeros(l_max)\n","                x3_med = np.zeros(l_max)\n","                #x3_var = np.zeros(l_max)\n","                for i in range(0, l_max):\n","                    x3_men[i] = stats.mean(sg_all2[:,i])\n","                    x3_med[i] = stats.median(sg_all2[:,i])\n","                    #x3_var[i] = stats.variance(sg_all2[:,i])     \n","                \n","                # [nos_beats,signal_len, avgd,vard, mean,median] signal_len/Basic_srate = duration\n","                rec_epi = np.array([ bepi,l_max,sdur_avg,sdur_var ])\n","                rec_epi = np.hstack((rec_epi,\n","                                     scsig.resample(x3_men,v_dimC),\n","                                     scsig.resample(x3_med,v_dimC) ))\n","                mega_epi = np.vstack((mega_epi, rec_epi ))\n","        rst+= '\\t'+ str(len(mega_epi))\n","        if len(mega_epi) > 0:      \n","            sel_rec.save_data(g_REP_II_POSTFIX, mega_epi)\n","            rst+= '\\t Success'\n","        else:\n","            rst+= '\\t Failed'\n","        print(rst)\n","\n","\n","print('\\nDone')\n","timestamp_dur = datetime.datetime.now() - timestamp_start\n","print('Elapsed time = ' + str(timestamp_dur))\n","#------------------------------------------------------------------------\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PRLTl93y7dac","colab_type":"text"},"source":["# [ 4_PLOT_SIGNALS ]"]},{"cell_type":"markdown","metadata":{"id":"Y97CbTc17jDE","colab_type":"text"},"source":["\n","DB NAME :: mitdb\n","\n","RECORD SET :: [48] \n","{'114', '116', '111', '103', '230', '123', '232',\n"," '200', '234', '203', '209', '215', '231', '207', \n"," '201', '202', '214', '101', '113', '210', '105', \n"," '117', '119', '212', '122', '213', '205', '208', \n"," '220', '233', '118', '124', '100', '228', '219', \n"," '102', '108', '221', '107', '223', '106', '121', \n"," '109', '217', '115', '222', '104', '112'}\n","\n","\n","DB NAME :: svdb\n","\n","RECORD SET :: [78] \n","{'802', '859', '845', '872', '879', '842', '843', \n"," '868', '863', '891', '874', '848', '883', '854', \n"," '829', '841', '844', '805', '889', '855', '850', \n"," '856', '809', '825', '857', '812', '877', '811', \n"," '840', '803', '810', '858', '887', '869', '881', \n"," '822', '878', '867', '800', '804', '893', '876', \n"," '849', '871', '875', '808', '862', '847', '846', \n"," '827', '873', '821', '884', '828', '866', '824', \n"," '865', '864', '820', '886', '888', '861', '826', \n"," '801', '885', '860', '823', '851', '806', '892', \n"," '852', '880', '807', '894', '853', '890', '882', '870'}\n","\n","\n","DB NAME :: incartdb\n","\n","RECORD SET :: [75] \n","{'I56', 'I07', 'I29', 'I33', 'I37', 'I42', 'I09', \n"," 'I12', 'I71', 'I04', 'I65', 'I74', 'I60', 'I61', \n"," 'I02', 'I57', 'I08', 'I05', 'I54', 'I67', 'I43', \n"," 'I19', 'I31', 'I27', 'I38', 'I39', 'I36', 'I17', \n"," 'I20', 'I52', 'I13', 'I45', 'I11', 'I73', 'I28', \n"," 'I01', 'I63', 'I49', 'I18', 'I46', 'I15', 'I26', \n"," 'I34', 'I50', 'I66', 'I72', 'I41', 'I53', 'I25', \n"," 'I62', 'I22', 'I35', 'I64', 'I55', 'I24', 'I03', \n"," 'I32', 'I48', 'I14', 'I68', 'I59', 'I70', 'I75', \n"," 'I47', 'I10', 'I06', 'I30', 'I40', 'I69', 'I51', \n"," 'I44', 'I16', 'I21', 'I58', 'I23'}\n","\n"," dict_keys(['mitdb', 'svdb', 'incartdb'])"]},{"cell_type":"markdown","metadata":{"id":"0Jhe9WAT77Ig","colab_type":"text"},"source":["## [ 4.1_Select_Record ]"]},{"cell_type":"code","metadata":{"id":"FpDscZBK8BDa","colab_type":"code","colab":{}},"source":["\n","idb = 'mitdb'\n","irec = '214'\n","\n","sel_db = all_db[idb]\n","sel_rec = sel_db.get_record(irec)\n","print(sel_rec.name)\n","\n","# load signal\n","sel_sig = sel_rec.read_data(g_SIG_II_POSTFIX)\n","print('Total signal length @ ' + str(BASIC_SRATE) + 'Hz = ' + str(sel_sig.shape))\n","\n","# load beat info\n","sel_binfo = sel_rec.read_binfo()\n","print('Total beats = '+ str(sel_binfo.nos_rr_peaks))\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lMtr4kN6_JjG","colab_type":"text"},"source":["### [ 4.1.1_Query_Meta_Data ]"]},{"cell_type":"code","metadata":{"id":"TKKJYBzN_QEI","colab_type":"code","colab":{}},"source":["# what is the time stamp for ith R-peak\n","ith_rpeak = 1417\n","\n","tstamp = sel_binfo.rr_peaks_sec[ith_rpeak]\n","print(tstamp)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9SfMEe158MOF","colab_type":"text"},"source":["## [ 4.2_Prepare_Variables ]"]},{"cell_type":"code","metadata":{"id":"Zo8SUvSV8Z5a","colab_type":"code","colab":{}},"source":["#-----------------------------------------\n","# seperate out beats\n","print('Type of beats')\n","sel_btypes = {}\n","\n","xsum = 0\n","for i in range(0,len(g_LABELS)):\n","    sel_btypes[i] = np.where(sel_binfo.rr_int_labels==i)[0]\n","    print(str(g_LABELS[i])+'\\t'+str(len(sel_btypes[i])))\n","    xsum+=len(sel_btypes[i])\n","print('sum\\t'+str(xsum))\n","\n","sel_btypes[-1] = np.where(sel_binfo.rr_int_labels==-1)[0]\n","print('x\\t'+str(len(sel_btypes[-1])))\n","\n","\n","# copy to local variables\n","sel_rri_dur = sel_binfo.rri_dur\n","sel_rri_delta = sel_binfo.rri_delta\n","sel_rri_p = sel_binfo.rri_prev\n","sel_rri_n = sel_binfo.rri_next\n","sel_labels = sel_binfo.rr_int_labels\n","sel_xrange = np.arange(0,sel_binfo.nos_rr_peaks)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LxvxFTuC8dbo","colab_type":"text"},"source":["## [ 4.3_Plot_RRI_&_Duration ]"]},{"cell_type":"code","metadata":{"id":"3bCaxO-V8pcL","colab_type":"code","colab":{}},"source":["# plot RRI\n","\n","plt.figure(0, figsize=(10,5))\n","plt.ylim(-0.5,3.5)\n","\n","#plt.title('duration')\n","plt.plot(sel_rri_dur,linewidth = 0.5 ,color='black')\n","plt.scatter(sel_xrange,sel_rri_dur, label='duration', marker='.',color='black')\n","#plt.figure(1, figsize=(10,5))\n","#plt.ylim(-1,1)\n","#plt.title('delta')\n","plt.plot(np.absolute(sel_rri_delta),linewidth = 0.5,color='red' )\n","plt.scatter(sel_xrange,np.absolute(sel_rri_delta), label='delta', marker='.',color='red')\n","\n","\n","plt.hlines(0,0,sel_binfo.nos_rr_peaks, linewidth=0.3)\n","plt.scatter(sel_btypes[-1],np.zeros(len(sel_btypes[-1]))-0.25,  marker='.', color='black', label='unknown '+str(len(sel_btypes[-1])))\n","for i in range(0, len(g_LABELS)):\n","    plt.scatter(sel_btypes[i],np.zeros(len(sel_btypes[i]))-0.25,  marker='.', color=g_COLOR[i], label=g_LABELS[i]+' '+str(len(sel_btypes[i])))\n","plt.legend(bbox_to_anchor=(0,1.02,1,0.2), loc=\"lower left\",\n","                mode=\"expand\", borderaxespad=0, ncol=3)\n","plt.hlines(lim_delta_rri,0,sel_binfo.nos_rr_peaks,linewidth=0.3,color='green')\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fv06ifwV82Vi","colab_type":"text"},"source":["## [ 4.4_Plot_RRIs_only ]"]},{"cell_type":"code","metadata":{"id":"QOrwMow086QF","colab_type":"code","colab":{}},"source":["# only Prev_RRIs for all beats\n","\n","plt.figure(1, figsize=(10,5))\n","plt.ylim(0,3)\n","plt.title('RRIs(prev)')\n","plt.plot(sel_rri_p,linewidth = 0.5, color='black')\n","plt.scatter(sel_xrange,sel_rri_p, label='RRi', marker='.', color='black')\n","plt.scatter(sel_btypes[-1],np.zeros(len(sel_btypes[-1]))+2,  marker='.', color='black', label='unknown '+str(len(sel_btypes[-1])))\n","for i in range(0, len(g_LABELS)):\n","    plt.scatter(sel_btypes[i],np.zeros(len(sel_btypes[i]))+2,  marker='.', color=g_COLOR[i], label=g_LABELS[i]+' '+str(len(sel_btypes[i])))\n","\n","plt.hlines(max_rri,0,sel_binfo.nos_rr_peaks, color='red', linewidth=0.5)\n","plt.hlines(min_rri,0,sel_binfo.nos_rr_peaks, color='tab:red', linewidth=0.5)\n","plt.hlines(hig_rri,0,sel_binfo.nos_rr_peaks,color='green', linewidth=0.5)\n","plt.hlines(low_rri,0,sel_binfo.nos_rr_peaks,color='tab:green', linewidth=0.5)\n","plt.legend(bbox_to_anchor=(0,1.02,1,0.2), loc=\"lower left\",\n","                mode=\"expand\", borderaxespad=0, ncol=3)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pn80aTig9EAz","colab_type":"text"},"source":["## [ 4.5_Plot_ECG_Signal ]"]},{"cell_type":"code","metadata":{"id":"5eIVyxyN9Jjv","colab_type":"code","colab":{}},"source":["# plot signal segments\n","\n","#<<---------------------------------------------Select Paper Resolution\n","x_scale = 25 * 0.0393701 # mm/sec -> inches/sec\n","y_scale = 10 * 0.0393701 # mm/mV -> inches/sec\n","y_low = -2.5\n","y_high = 3.5\n","#<<--------------------------------------------------------------------\n","\n","#<<---------------------------------------------Select ECG Segment\n","fsec = 1430\n","tsec = fsec+(15)\n","dsec = tsec - fsec\n","#<<--------------------------------------------------------------------\n","\n","\n","ff = fsec * BASIC_SRATE\n","tt = tsec * BASIC_SRATE\n","dd = tt - ff\n","\n","bps = sel_sig[ff:tt]\n","\n","dticks = sel_binfo.rr_peaks[(sel_binfo.rr_peaks_sec >= fsec) & (sel_binfo.rr_peaks_sec < tsec)]\n","dlabels = sel_binfo.rr_labels[(sel_binfo.rr_peaks_sec >= fsec) & (sel_binfo.rr_peaks_sec < tsec)]\n","dticks = (dticks / sel_rec.db.srate)*BASIC_SRATE - ff\n","\n","plt.figure(2, figsize = (dsec*x_scale ,(y_high-y_low) * y_scale) )\n","plt.xlim(0, len(bps))\n","plt.ylim(y_low,y_high)\n","plt.xticks(dticks,dlabels)\n","#x_grid = np.arange(0,tt-ff, 1*BASIC_SRATE)\n","#plt.xticks(x_grid)\n","plt.grid(axis='x')\n","\n","#drris = sel_binfo.rri_delta[(sel_binfo.rr_peaks_sec >= fsec) & (sel_binfo.rr_peaks_sec < tsec)]\n","#drrid = sel_binfo.rri_dur[(sel_binfo.rr_peaks_sec >= fsec) & (sel_binfo.rr_peaks_sec < tsec)]\n","# RED: rri_delta\n","#plt.scatter(dticks,drris, marker='s',color='tab:red')\n","# GREEN = Duration\n","#plt.scatter(dticks,drrid, marker='s',color='tab:green')\n","\n","plt.plot(bps, linewidth=0.5, color='black')\n","plt.hlines(0,0,len(bps), linewidth=0.3)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cib7erXz9rhb","colab_type":"text"},"source":["## [ 4.5_Plot_Single_Beats ]"]},{"cell_type":"code","metadata":{"id":"Cgp5fYJT9wGP","colab_type":"code","colab":{}},"source":["#<<---------------------------------------------Select Beats Index to be plotted\n","bi = random.randint(0, sel_binfo.nos_rr_peaks-1)\n","#bi = 1730\n","bi =  np.random.choice(sel_btypes[1], size=1, replace=False, p=None)[0]\n","#<<-------------------------------------------------------------------------------\n","print('#'+ str(bi) + ' of ' + str(sel_binfo.nos_rr_peaks))\n","\n","# plot beats\n","#sigs = sel_fsig[bi]\n","#sigt = sel_bsig[bi]\n","\n","# print info\n","slabel = sel_binfo.rr_labels[bi]\n","ilabel = sel_binfo.rr_int_labels[bi]\n","tstamp = sel_binfo.rr_peaks_sec[bi]\n","tdur = sel_binfo.rri_dur[bi]\n","tprev = sel_binfo.rri_prev[bi]\n","tnext = sel_binfo.rri_next[bi]\n","\n","print('Label: '+ slabel + '['+ str(ilabel) +']')\n","print('Timestamp: '+ str(tstamp))\n","print('Duration: '+ str(tdur))\n","print('RRIs: '+ str(tprev)+ ','+ str(tnext))\n","\n","#---------------------------] Plotted using varible length (prev_R to next_R peak)\n","sg,pk = sel_binfo.get_signal_data_var(bi)\n","plt.figure(1)\n","plt.ylim(-2,3.5)\n","print(sg.shape)\n","print(pk)\n","plt.plot(sg)\n","plt.vlines(pk,-2,3.5, linewidth=0.5)\n","\n","#------------------------------] Plotted using fixed length (in seconds) on either side of R peak\n","sg,pk = sel_binfo.get_signal_data_fix(bi,1.5,1.5)\n","plt.figure(2)\n","print(sg.shape)\n","print(pk)\n","plt.plot(sg)\n","plt.vlines(pk,0,2)\n","\n","#------------------------------] Plotted Resampled signal and peak location\n","# X_res2 = scsig.resample(sg,v_dimC)\n","# plt.figure(3)\n","# print(X_res2.shape)\n","# plt.plot(X_res2)\n","# pk1 = pk*( len(X_res2)/(len(sg) ))\n","# plt.vlines(pk1,0,2)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jG7Q_NP1-ZOm","colab_type":"text"},"source":["## [ 4.6_Plot_Rep_Normal_Set ]"]},{"cell_type":"code","metadata":{"id":"CErrFUrP-dy1","colab_type":"code","colab":{}},"source":["# plot representative set\n","\n","#<<---------------------------------------------Select rep_norm set to be plotted\n","g_REP_II_POSTFIX = 'REP_1800'\n","#g_REP_II_POSTFIX = 'REP_300'\n","\n","\n","jx = sel_rec.load_data(g_REP_II_POSTFIX)\n","print (sel_rec.name+'\\t'+str(jx.shape))\n","print ('Total reps = '+ str(len(jx)))\n","\n","plt.figure(0)\n","plt.ylabel('duration variance')\n","plt.ylabel('nos beats')\n","plt.ylim(-0.001, 0.01)\n","\n","plt.scatter(jx[:,0], jx[:,3],marker='.', color='black')\n","for i in range(0,len(jx)):\n","    plt.annotate(str(i),xy=(jx[i,0], jx[i,3]))\n","\n","#[nos_beats,signal_len, avgd,vard, mean,median] signal_len/Basic_srate = duration\n","print('#epi\\t#beats\\tsig_len\\tavg_dur\\tvar_dur\\tmax_dur')\n","plt.figure(1)\n","plt.ylim(-2,3.5)\n","plt.xlim(-10,v_dimC+10)\n","for cepi in range(0,len(jx)):\n","    iepi = jx[cepi]\n","    n0 = round(iepi[0])\n","    n1 = round(iepi[1])\n","    n2 = round(iepi[2],3)\n","    n3 = round(iepi[3],3)\n","    n4 = round(n1/(128),3)\n","    print(str(cepi)+'\\t'+str(n0)+'\\t'+str(n1)+'\\t'+str(n2)+'\\t'+str(n3)+'\\t'+str(n4))\n","    n_med = iepi[-v_dimC:]\n","    n_men = iepi[4:4+v_dimC]\n","    #<<---------------------------------------------Select Rep_N Median or Mean Beat to be plotted\n","    plt.plot(n_med, linewidth=0.3, color='tab:green') \n","    #plt.plot(n_men, linewidth=0.3, color='tab:blue')\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wKV2n0Lh-wL0","colab_type":"text"},"source":["### [ 4.6.1_Plot_Single_Rep_Normal ]"]},{"cell_type":"code","metadata":{"id":"5I8b4X4y-2oI","colab_type":"code","colab":{}},"source":["#<<---------------------------------------------Select index from Rep_Normal Set \n","sel_episode = 12\n","\n","print (sel_rec.name+'\\tepisode#'+str(sel_episode))\n","iepi = jx[sel_episode]\n","jx_men = iepi[4:4+v_dimC]\n","jx_med = iepi[-v_dimC:]\n","\n","n0 = round(iepi[0])\n","n1 = round(iepi[1])\n","n2 = round(iepi[2],3)\n","n3 = round(iepi[3],3)\n","n4 = round(n1/(128),3)\n","print('#beats = '+str(n0)+'\\nsig_len = '+str(n1)+'\\navg_dur = '+str(n2)+'\\nvar_dur = '+str(n3)+'\\nmax_dur = '+str(n4))\n","\n","plt.figure(sel_episode+2)\n","plt.title('#epi '+str(sel_episode))\n","#plt.plot(jx_men,label='mean')\n","plt.plot(jx_med,label='median')\n","plt.legend()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5XCa8-uR_aNY","colab_type":"text"},"source":["# [ 5_PREPARE_WORKING_DBs ]"]},{"cell_type":"code","metadata":{"id":"lV914CmU_ib6","colab_type":"code","colab":{}},"source":["#-----------------------------------------------------------------------------------------\n","#-----------------------------------------------------------------------------------------\n","#-----------------------------------------------------------------------------------------\n","#<<--------------------- FOR TRAINING model_01\n","train_db1 = {} \n","#------------------------------------------------------------------------\n","mitdb_ex = ['102', '104', '107', '217', \n","            '212', '231',  '207']\n","            #'232'] #<- no rep normal\n","train_db1['mitdb'] = ecg_db('mitdb',  mitdb_ex, [], 360)\n","#------------------------------------------------------------------------\n","svdb_ex = [] #<-- les than 10 nrep normals\n","train_db1['svdb'] = ecg_db('svdb',  svdb_ex, [], 128)\n","#------------------------------------------------------------------------\n","#incartdb_ex = []\n","#train_db1['incartdb'] = ecg_db('incartdb', incartdb_ex, [], 257)\n","#------------------------------------------------------------------------\n","#print(train_db1.values())\n","print('')\n","print(train_db1.keys())\n","\n","\n","#-----------------------------------------------------------------------------------------\n","#-----------------------------------------------------------------------------------------\n","#-----------------------------------------------------------------------------------------\n","#<<--------------------- FOR TESTING model_01\n","test_db1 = {} \n","#------------------------------------------------------------------------\n","#mitdb_ex = ['102', '104', '107', '217', \n","#            '212', '231',  '207']\n","#            #'232'] #<- no rep normal\n","#test_db1['mitdb'] = ecg_db('mitdb',  mitdb_ex, [], 360)\n","#------------------------------------------------------------------------\n","#svdb_ex = [] #<-- les than 10 nrep normals\n","#test_db1['svdb'] = ecg_db('svdb',  svdb_ex, [], 128)\n","#------------------------------------------------------------------------\n","incartdb_ex = []\n","test_db1['incartdb'] = ecg_db('incartdb', incartdb_ex, [], 257)\n","#------------------------------------------------------------------------\n","#print(test_db1.values())\n","print('')\n","print(test_db1.keys())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tLsBe6if_4Ps","colab_type":"text"},"source":["# [ 6_GENRATE_DATASETS ]"]},{"cell_type":"code","metadata":{"id":"5p-FmelP__RU","colab_type":"code","colab":{}},"source":["# CELL 0\n","'''\n","1. Select train_db dict object [CELL 1]\n","2. Select g_CLASS_II_POSTFIX and limit values [CELL 2]\n","3. Select your query [CELL 3]\n","'''\n","#%% CELL 1\n","#------------------------------------------------------------------------\n","train_db = train_db1\n","\n","#%% CELL 2\n","#------------------------------------------------------------------------\n","g_CLASS_II_POSTFIX = 'CLASS'   ##<<<<---------------- [select your post fix]\n","lim_lower, lim_upper = 40, 100 ##<<<<---------------- [select your beat limits]\n","\n","# log file --------------------------------------------------------------------\n","log_file= os.path.join(global_datadir, g_CLASS_II_POSTFIX+'_db_build_log.txt') \n","def print_log(log_string):\n","    log_handle.write(log_string+'\\n')\n","\n","#%% CELL 3\n","#------------------------------------------------------------------------\n","\n","all_total_sveb = 0\n","log_handle = open(log_file,'w')\n","timestamp_start = datetime.datetime.now()\n","print('\\n Start Iteration for '+g_CLASS_II_POSTFIX+' \\n')\n","print_log(g_CLASS_II_POSTFIX+'_LOG_START ['+str(timestamp_start)+ ']')\n","print_log('nos_beat_limits[lower,upper] = ['+ str(lim_lower)+ ','+ str(lim_upper)+']')\n","for idb in train_db.keys():\n","    sel_db = train_db[idb]\n","    #if idb!='svdb':\n","    #    continue\n","    for irec in sel_db.recs:\n","    #    if irec!='865':\n","    #        continue\n","        rst = ''\n","        sel_rec = sel_db.get_record(irec)      \n","        sel_sig = sel_rec.read_data(g_SIG_II_POSTFIX)\n","        rst += str(sel_rec.name)+'\\t'\n","        \n","        #============================================================\n","        print_log('\\n\\n[Selected Record = '+str(sel_rec.name)+ ']')\n","        #============================================================\n","        \n","        if len(sel_sig)<1:\n","            rst+='\\tSignal doesnt exist, Skip this record'\n","            print(rst)\n","            \n","            #============================================================\n","            print_log(' >>Signal doesnt exist, Skip this record')\n","            #============================================================\n","                    \n","            continue\n","        \n","        sbi = sel_rec.read_binfo()      # load beat info\n","    \n","\n","    #----------------------------------------------------------------------------------\n","    #----------------------------------------------------------------------------------\n","        sveb_list = []\n","        sveb_query = () ##<<<<<<<<<<<<<<<<<<<<---------------[Select your query]\n","        sveb_list = np.where(sveb_query)[0]\n","    #----------------------------------------------------------------------------------\n","    #----------------------------------------------------------------------------------\n","    \n","    \n","        \n","        if len(sveb_list)<lim_lower:\n","            rst+='\\tNot enough CLASS beats, Skip this record'\n","            print(rst )\n","            #============================================================\n","            print_log(' >>Invalid query_count = '+str(len(sveb_list))+ ' - skip record')\n","            #============================================================\n","            continue\n","        else:\n","            \n","            #============================================================\n","            print_log(' >>Valid query_count = '+str(len(sveb_list)))\n","            #============================================================\n","            \n","            \n","            rst+='\\tquery:'+str(len(sveb_list))\n","            sveb_sel = np.zeros((0,v_dimC+2),dtype='float') # +2 for peak location and duration\n","            \n","            if len(sveb_list)<=lim_upper: \n","                #============================================================\n","                print_log('CASE_1::query_count <= upper_limit : Need to select all class beats, iterate ...')\n","                #============================================================\n","                rst+='\\tquery<=upperlimit'\n","                # is within selction limits, select all class beats\n","                for ibeat in sveb_list:\n","                    sg,pk = sbi.get_signal_data_var(ibeat)\n","                    \n","                    #============================================================\n","                    print_log('\\tbeat# '+str(ibeat) + '\\tLabel='+sbi.rr_labels[ibeat]+ '\\tTS='+str(round(sbi.rr_peaks_sec[ibeat],2))+'\\tDUR='+str(sbi.rri_dur[ibeat]))\n","                    #============================================================\n","                    \n","                    sg_resamp = scsig.resample(sg,v_dimC)\n","                    pk_resamp = round(pk*( len(sg_resamp)/(len(sg) )))\n","                    beat_duration = sbi.rri_dur[ibeat]\n","                    \n","                    #[ orignal_duration(secs), peak_location(samples),resampled_signal{array}]\n","                    a_resamp = np.hstack((beat_duration,pk_resamp,sg_resamp))\n","                    \n","                    #============================================================\n","                    #print_log('\\tMeta: ['+ str(len(a_resamp)) +']:'+str(a_resamp[0:3]))\n","                    #============================================================\n","                    \n","                    sveb_sel = np.vstack((sveb_sel, a_resamp)) # done now save it\n","                    \n","                #============================================================\n","                print_log('CASE_1::End of Selection, beats_selected = '+ str(sveb_sel.shape))\n","                #============================================================\n","                   \n","            else: # len(sveb_list)>lim_upper\n","                # more than upper_limit find episodes\n","                \n","                #============================================================\n","                print_log('CASE_2::query_count > upper_limit : Do not select all class beats. Find episodes...')\n","                #============================================================\n","                \n","                rst+='\\tquery>upperlimit'\n","                sveb_list1 = np.hstack((np.sort(sveb_list),np.array([-1])))\n","                \n","                sveb_epi = []\n","                # extract episodes from sveb_list\n","                s_s = sveb_list[0]\n","                delta = 1\n","                for i in range(1, len(sveb_list1)):\n","                    s_e = sveb_list1[i]\n","                    if s_e == s_s + delta:\n","                        delta+=1\n","                    else:\n","                        sveb_epi.append([s_s,s_s+delta])\n","                        s_s = s_e\n","                        delta = 1      \n","                        \n","                if len(sveb_epi)==0:\n","                    rst+='\\tImpossible::Not enough class episodes, Skip this record'#<<- this cannot happen\n","                    print(rst)\n","                    print_log('CASE_2::Impossible, no class episodes exist!!')\n","                    continue    \n","                else:\n","                    rst+='\\t'+ str(len(sveb_epi))    \n","                #============================================================\n","                print_log(' >>found episodes : '+ str(len(sveb_epi))+'\\n >>compare #episodes and upper selection limit..')\n","                #============================================================               \n","  \n","                if len(sveb_epi)<=lim_upper:\n","                    delta_ratio = lim_upper/len(sveb_list)\n","                    \n","                    #============================================================\n","                    print_log('CASE_2.1::Less episodes than upper limit : Selection ratio [upper_limit/total_beats] = '+str(round(delta_ratio,2)))\n","                    #============================================================                      \n","                    \n","                    rst+='\\t#epi<=upperlimit, delta_ratio='+ str(round(delta_ratio,2))\n","                    # take delta_ratio times beats from each episode\n","                    \n","                    #============================================================ \n","                    print_log(' >>Prepare rsel: take delta_ratio times beats from each episode, iterate...')\n","                    #============================================================ \n","                    \n","                    for iepi in range(0,len(sveb_epi)):\n","                        i_episode = sveb_epi[iepi]\n","\n","                        beats_in_epi = i_episode[1]-i_episode[0]\n","\n","                        beats_taken = int(int(beats_in_epi*delta_ratio))\n","                        if beats_taken==0:\n","                            beats_taken = 1 # atleast take one beat from each episode\n","                        \n","                        #============================================================ \n","                        print_log('\\tepisode# '+ str(iepi)+'='+str(i_episode)+\n","                              ' has '+ str(beats_in_epi)+ ' beats, randomly take '+\n","                              str(beats_taken)+ ' beats')                        \n","                        #============================================================ \n","\n","                        a = np.arange(i_episode[0],i_episode[1])\n","                        rsel = np.random.choice(a, size=beats_taken, replace=False, p=None)\n","                        \n","                        print_log('\\t >>Selected: '+ str(rsel)+' iterate...')\n","                        for ibeat in rsel:\n","                            sg,pk = sbi.get_signal_data_var(ibeat)\n","                            \n","                            #============================================================\n","                            print_log('\\t\\tbeat# '+str(ibeat) + '\\tL='+sbi.rr_labels[ibeat]+ '\\tTS='+str(round(sbi.rr_peaks_sec[ibeat],2))+'\\tDUR='+str(sbi.rri_dur[ibeat]))\n","                            #============================================================\n","                            \n","                            sg_resamp = scsig.resample(sg,v_dimC)\n","                            pk_resamp = round(pk*( len(sg_resamp)/(len(sg) )))\n","                            beat_duration = sbi.rri_dur[ibeat]\n","                            \n","                            #[ orignal_duration(secs), peak_location(samples),resampled_signal{array}]\n","                            a_resamp = np.hstack((beat_duration,pk_resamp,sg_resamp))\n","                            \n","                            #============================================================ \n","                            #print_log('\\tMeta: ['+ str(len(a_resamp)) +']:'+str(a_resamp[0:3]))\n","                            #============================================================ \n","                            \n","                            sveb_sel = np.vstack((sveb_sel, a_resamp))  # done now save it\n","                            \n","                        #============================================================\n","                        #print_log('\\tend of episode iteration sbeats_selected(this episode) = '+ str(sveb_sel.shape))\n","                        #============================================================\n","                        \n","                    #============================================================\n","                    print_log('end of all episode iteration beats_selected(overall) = '+ str(sveb_sel.shape))\n","                    #============================================================\n","                    \n","                else: # is in b/w upper and lower limit, select one from each episode\n","\n","                    delta_epi = int(len(sveb_epi) / lim_upper) #how many extra episodes\n","                    \n","                    #============================================================\n","                    print_log('CASE_2.2::More episodes than upper limit, index step = int[total_episodes / upperlimit] = '+str(round(delta_epi,2)))\n","                    #============================================================  \n","\n","                    rst+='\\t#epi>upperlimit delta_epi='+ str(round(delta_epi,2))\n","                    ist = 0\n","                    rsel=np.zeros(lim_upper,dtype='int')\n","                    \n","                    ##============================================================  \n","                    print_log(' >>Prepare rsel: step indices, select ONE beat randomly from each episode, iterate...')\n","                    #============================================================  \n","                    \n","                    for ix in range(0,lim_upper):\n","                        i_episode = sveb_epi[ist]\n","                        beats_in_epi = i_episode[1]-i_episode[0]\n","                        j_sel = i_episode[0]\n","                        \n","                        if beats_in_epi > 1:\n","                            j_sel = random.randint(i_episode[0],i_episode[1]-1)\n","                            \n","                        #============================================================  \n","                        print_log('\\tepisode# '+ str(ist)+'='+str(i_episode)+\n","                              ' has '+ str(beats_in_epi)+ ' beats, take random # '+\n","                              str(j_sel))                            \n","                        #============================================================  \n","                        \n","                        rsel[ix] = j_sel\n","                        ist+=delta_epi\n","                        \n","                    #============================================================  \n","                    print_log('Selected Striding: '+ str(rsel)+' iterate...')\n","                    #============================================================  \n","                    \n","                    for ibeat in rsel:\n","                        sg,pk = sbi.get_signal_data_var(ibeat)\n","                        \n","                        #============================================================\n","                        print_log('\\tbeat# '+str(ibeat) + '\\tL='+sbi.rr_labels[ibeat]+ '\\tTS='+str(round(sbi.rr_peaks_sec[ibeat],2))+'\\tDUR='+str(sbi.rri_dur[ibeat]))\n","                        #============================================================\n","                        \n","                        sg_resamp = scsig.resample(sg,v_dimC)\n","                        pk_resamp = round(pk*( len(sg_resamp)/(len(sg) )))\n","                        beat_duration = sbi.rri_dur[ibeat]\n","                        \n","                        #[ orignal_duration(secs), peak_location(samples),resampled_signal{array}]\n","                        a_resamp = np.hstack((beat_duration,pk_resamp,sg_resamp))\n","                        \n","                        #============================================================  \n","                        #print_log('\\tMeta: ['+ str(len(a_resamp)) +']:'+str(a_resamp[0:3]))\n","                        #============================================================  \n","                        \n","                        sveb_sel = np.vstack((sveb_sel, a_resamp))    \n","                        \n","                    #============================================================\n","                    print_log('end of iteration beats_selected = '+ str(sveb_sel.shape))\n","                    #============================================================\n","                    \n","            #============================================================\n","            print_log('end of record, total_beats_selected = '+ str(sveb_sel.shape))\n","            #============================================================\n","            \n","            rst+='\\ttotal_CLASS_BEATS:'+ str(len(sveb_sel))\n","            print(rst)   \n","            \n","            sel_rec.save_data(g_CLASS_II_POSTFIX,sveb_sel)\n","            \n","            all_total_sveb+=len(sveb_sel)            \n","            \n","    # loop end record ----------------------------------------------------------------------------------\n","# loop end database ----------------------------------------------------------------------------------\n","\n","timestamp_dur = datetime.datetime.now() - timestamp_start\n","print('Elapsed time = ' + str(timestamp_dur))\n","print('\\nEnd of Procedure, grand_total_class_beats = '+ str(all_total_sveb))\n","print_log('\\nEnd of Procedure, grand_total_beats = '+ str(all_total_sveb))\n","print_log('\\n'+g_CLASS_II_POSTFIX+'_LOG_END, elapsed time = ['+str(timestamp_dur)+ ']')\n","log_handle.close()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ESMzET2bASSz","colab_type":"text"},"source":["## [ 6.1_S_CLASS_DS ]"]},{"cell_type":"code","metadata":{"id":"B5tsuK6MAbpV","colab_type":"code","colab":{}},"source":["# CELL 0\n","'''\n","1. Build train_db dict object [CELL 1]\n","2. Select g_CLASS_II_POSTFIX and limit values [CELL 2]\n","3. Select your query [CELL 3]\n","'''\n","#%% CELL 1\n","#------------------------------------------------------------------------\n","\n","train_db = train_db1\n","\n","#%% CELL 2\n","#------------------------------------------------------------------------\n","\n","g_CLASS_II_POSTFIX = 'S'   ##<<<<---------------- [select your post fix]\n","lim_lower, lim_upper = 40, 100 ##<<<<---------------- [select your beat limits]\n","\n","# log file --------------------------------------------------------------------\n","log_file= os.path.join(global_datadir, g_CLASS_II_POSTFIX+'_db_build_log.txt') \n","def print_log(log_string):\n","    log_handle.write(log_string+'\\n')\n","\n","#%% CELL 3\n","#------------------------------------------------------------------------\n","\n","all_total_sveb = 0\n","log_handle = open(log_file,'w')\n","timestamp_start = datetime.datetime.now()\n","print('\\n Start Iteration for '+g_CLASS_II_POSTFIX+' \\n')\n","print_log(g_CLASS_II_POSTFIX+'_LOG_START ['+str(timestamp_start)+ ']')\n","print_log('nos_beat_limits[lower,upper] = ['+ str(lim_lower)+ ','+ str(lim_upper)+']')\n","for idb in train_db.keys():\n","    sel_db = train_db[idb]\n","    #if idb!='svdb':\n","    #    continue\n","    for irec in sel_db.recs:\n","    #    if irec!='865':\n","    #        continue\n","        rst = ''\n","        sel_rec = sel_db.get_record(irec)      \n","        sel_sig = sel_rec.read_data(g_SIG_II_POSTFIX)\n","        rst += str(sel_rec.name)+'\\t'\n","        \n","        #============================================================\n","        print_log('\\n\\n[Selected Record = '+str(sel_rec.name)+ ']')\n","        #============================================================\n","        \n","        if len(sel_sig)<1:\n","            rst+='\\tSignal doesnt exist, Skip this record'\n","            print(rst)\n","            \n","            #============================================================\n","            print_log(' >>Signal doesnt exist, Skip this record')\n","            #============================================================\n","                    \n","            continue\n","        \n","        sbi = sel_rec.read_binfo()      # load beat info\n","    \n","\n","    #----------------------------------------------------------------------------------\n","    #----------------------------------------------------------------------------------\n","        sveb_list = []\n","        sveb_query = (\n","                    (sbi.rr_labels=='A')  |\n","                    (sbi.rr_labels=='a')  |\n","                    (sbi.rr_labels=='J')  |\n","                    (sbi.rr_labels=='S')  \n","                  )\n","        ##<<<<<<<<<<<<<<<<<<<<---------------[Select your query]\n","        sveb_list = np.where(sveb_query)[0]\n","    #----------------------------------------------------------------------------------\n","    #----------------------------------------------------------------------------------\n","    \n","    \n","        \n","        if len(sveb_list)<lim_lower:\n","            rst+='\\tNot enough CLASS beats, Skip this record'\n","            print(rst )\n","            #============================================================\n","            print_log(' >>Invalid query_count = '+str(len(sveb_list))+ ' - skip record')\n","            #============================================================\n","            continue\n","        else:\n","            \n","            #============================================================\n","            print_log(' >>Valid query_count = '+str(len(sveb_list)))\n","            #============================================================\n","            \n","            \n","            rst+='\\tquery:'+str(len(sveb_list))\n","            sveb_sel = np.zeros((0,v_dimC+2),dtype='float') # +2 for peak location and duration\n","            \n","            if len(sveb_list)<=lim_upper: \n","                #============================================================\n","                print_log('CASE_1::query_count <= upper_limit : Need to select all class beats, iterate ...')\n","                #============================================================\n","                rst+='\\tquery<=upperlimit'\n","                # is within selction limits, select all class beats\n","                for ibeat in sveb_list:\n","                    sg,pk = sbi.get_signal_data_var(ibeat)\n","                    \n","                    #============================================================\n","                    print_log('\\tbeat# '+str(ibeat) + '\\tLabel='+sbi.rr_labels[ibeat]+ '\\tTS='+str(round(sbi.rr_peaks_sec[ibeat],2))+'\\tDUR='+str(sbi.rri_dur[ibeat]))\n","                    #============================================================\n","                    \n","                    sg_resamp = scsig.resample(sg,v_dimC)\n","                    pk_resamp = round(pk*( len(sg_resamp)/(len(sg) )))\n","                    beat_duration = sbi.rri_dur[ibeat]\n","                    \n","                    #[ orignal_duration(secs), peak_location(samples),resampled_signal{array}]\n","                    a_resamp = np.hstack((beat_duration,pk_resamp,sg_resamp))\n","                    \n","                    #============================================================\n","                    #print_log('\\tMeta: ['+ str(len(a_resamp)) +']:'+str(a_resamp[0:3]))\n","                    #============================================================\n","                    \n","                    sveb_sel = np.vstack((sveb_sel, a_resamp)) # done now save it\n","                    \n","                #============================================================\n","                print_log('CASE_1::End of Selection, beats_selected = '+ str(sveb_sel.shape))\n","                #============================================================\n","                   \n","            else: # len(sveb_list)>lim_upper\n","                # more than upper_limit find episodes\n","                \n","                #============================================================\n","                print_log('CASE_2::query_count > upper_limit : Do not select all class beats. Find episodes...')\n","                #============================================================\n","                \n","                rst+='\\tquery>upperlimit'\n","                sveb_list1 = np.hstack((np.sort(sveb_list),np.array([-1])))\n","                \n","                sveb_epi = []\n","                # extract episodes from sveb_list\n","                s_s = sveb_list[0]\n","                delta = 1\n","                for i in range(1, len(sveb_list1)):\n","                    s_e = sveb_list1[i]\n","                    if s_e == s_s + delta:\n","                        delta+=1\n","                    else:\n","                        sveb_epi.append([s_s,s_s+delta])\n","                        s_s = s_e\n","                        delta = 1      \n","                        \n","                if len(sveb_epi)==0:\n","                    rst+='\\tImpossible::Not enough class episodes, Skip this record'#<<- this cannot happen\n","                    print(rst)\n","                    print_log('CASE_2::Impossible, no class episodes exist!!')\n","                    continue    \n","                else:\n","                    rst+='\\t'+ str(len(sveb_epi))    \n","                #============================================================\n","                print_log(' >>found episodes : '+ str(len(sveb_epi))+'\\n >>compare #episodes and upper selection limit..')\n","                #============================================================               \n","  \n","                if len(sveb_epi)<=lim_upper:\n","                    delta_ratio = lim_upper/len(sveb_list)\n","                    \n","                    #============================================================\n","                    print_log('CASE_2.1::Less episodes than upper limit : Selection ratio [upper_limit/total_beats] = '+str(round(delta_ratio,2)))\n","                    #============================================================                      \n","                    \n","                    rst+='\\t#epi<=upperlimit, delta_ratio='+ str(round(delta_ratio,2))\n","                    # take delta_ratio times beats from each episode\n","                    \n","                    #============================================================ \n","                    print_log(' >>Prepare rsel: take delta_ratio times beats from each episode, iterate...')\n","                    #============================================================ \n","                    \n","                    for iepi in range(0,len(sveb_epi)):\n","                        i_episode = sveb_epi[iepi]\n","\n","                        beats_in_epi = i_episode[1]-i_episode[0]\n","\n","                        beats_taken = int(int(beats_in_epi*delta_ratio))\n","                        if beats_taken==0:\n","                            beats_taken = 1 # atleast take one beat from each episode\n","                        \n","                        #============================================================ \n","                        print_log('\\tepisode# '+ str(iepi)+'='+str(i_episode)+\n","                              ' has '+ str(beats_in_epi)+ ' beats, randomly take '+\n","                              str(beats_taken)+ ' beats')                        \n","                        #============================================================ \n","\n","                        a = np.arange(i_episode[0],i_episode[1])\n","                        rsel = np.random.choice(a, size=beats_taken, replace=False, p=None)\n","                        \n","                        print_log('\\t >>Selected: '+ str(rsel)+' iterate...')\n","                        for ibeat in rsel:\n","                            sg,pk = sbi.get_signal_data_var(ibeat)\n","                            \n","                            #============================================================\n","                            print_log('\\t\\tbeat# '+str(ibeat) + '\\tL='+sbi.rr_labels[ibeat]+ '\\tTS='+str(round(sbi.rr_peaks_sec[ibeat],2))+'\\tDUR='+str(sbi.rri_dur[ibeat]))\n","                            #============================================================\n","                            \n","                            sg_resamp = scsig.resample(sg,v_dimC)\n","                            pk_resamp = round(pk*( len(sg_resamp)/(len(sg) )))\n","                            beat_duration = sbi.rri_dur[ibeat]\n","                            \n","                            #[ orignal_duration(secs), peak_location(samples),resampled_signal{array}]\n","                            a_resamp = np.hstack((beat_duration,pk_resamp,sg_resamp))\n","                            \n","                            #============================================================ \n","                            #print_log('\\tMeta: ['+ str(len(a_resamp)) +']:'+str(a_resamp[0:3]))\n","                            #============================================================ \n","                            \n","                            sveb_sel = np.vstack((sveb_sel, a_resamp))  # done now save it\n","                            \n","                        #============================================================\n","                        #print_log('\\tend of episode iteration sbeats_selected(this episode) = '+ str(sveb_sel.shape))\n","                        #============================================================\n","                        \n","                    #============================================================\n","                    print_log('end of all episode iteration beats_selected(overall) = '+ str(sveb_sel.shape))\n","                    #============================================================\n","                    \n","                else: # is in b/w upper and lower limit, select one from each episode\n","\n","                    delta_epi = int(len(sveb_epi) / lim_upper) #how many extra episodes\n","                    \n","                    #============================================================\n","                    print_log('CASE_2.2::More episodes than upper limit, index step = int[total_episodes / upperlimit] = '+str(round(delta_epi,2)))\n","                    #============================================================  \n","\n","                    rst+='\\t#epi>upperlimit delta_epi='+ str(round(delta_epi,2))\n","                    ist = 0\n","                    rsel=np.zeros(lim_upper,dtype='int')\n","                    \n","                    ##============================================================  \n","                    print_log(' >>Prepare rsel: step indices, select ONE beat randomly from each episode, iterate...')\n","                    #============================================================  \n","                    \n","                    for ix in range(0,lim_upper):\n","                        i_episode = sveb_epi[ist]\n","                        beats_in_epi = i_episode[1]-i_episode[0]\n","                        j_sel = i_episode[0]\n","                        \n","                        if beats_in_epi > 1:\n","                            j_sel = random.randint(i_episode[0],i_episode[1]-1)\n","                            \n","                        #============================================================  \n","                        print_log('\\tepisode# '+ str(ist)+'='+str(i_episode)+\n","                              ' has '+ str(beats_in_epi)+ ' beats, take random # '+\n","                              str(j_sel))                            \n","                        #============================================================  \n","                        \n","                        rsel[ix] = j_sel\n","                        ist+=delta_epi\n","                        \n","                    #============================================================  \n","                    print_log('Selected Striding: '+ str(rsel)+' iterate...')\n","                    #============================================================  \n","                    \n","                    for ibeat in rsel:\n","                        sg,pk = sbi.get_signal_data_var(ibeat)\n","                        \n","                        #============================================================\n","                        print_log('\\tbeat# '+str(ibeat) + '\\tL='+sbi.rr_labels[ibeat]+ '\\tTS='+str(round(sbi.rr_peaks_sec[ibeat],2))+'\\tDUR='+str(sbi.rri_dur[ibeat]))\n","                        #============================================================\n","                        \n","                        sg_resamp = scsig.resample(sg,v_dimC)\n","                        pk_resamp = round(pk*( len(sg_resamp)/(len(sg) )))\n","                        beat_duration = sbi.rri_dur[ibeat]\n","                        \n","                        #[ orignal_duration(secs), peak_location(samples),resampled_signal{array}]\n","                        a_resamp = np.hstack((beat_duration,pk_resamp,sg_resamp))\n","                        \n","                        #============================================================  \n","                        #print_log('\\tMeta: ['+ str(len(a_resamp)) +']:'+str(a_resamp[0:3]))\n","                        #============================================================  \n","                        \n","                        sveb_sel = np.vstack((sveb_sel, a_resamp))    \n","                        \n","                    #============================================================\n","                    print_log('end of iteration beats_selected = '+ str(sveb_sel.shape))\n","                    #============================================================\n","                    \n","            #============================================================\n","            print_log('end of record, total_beats_selected = '+ str(sveb_sel.shape))\n","            #============================================================\n","            \n","            rst+='\\ttotal_CLASS_BEATS:'+ str(len(sveb_sel))\n","            print(rst)   \n","            \n","            sel_rec.save_data(g_CLASS_II_POSTFIX,sveb_sel)\n","            \n","            all_total_sveb+=len(sveb_sel)            \n","            \n","    # loop end record ----------------------------------------------------------------------------------\n","# loop end database ----------------------------------------------------------------------------------\n","\n","timestamp_dur = datetime.datetime.now() - timestamp_start\n","print('Elapsed time = ' + str(timestamp_dur))\n","print('\\nEnd of Procedure, grand_total_class_beats = '+ str(all_total_sveb))\n","print_log('\\nEnd of Procedure, grand_total_beats = '+ str(all_total_sveb))\n","print_log('\\n'+g_CLASS_II_POSTFIX+'_LOG_END, elapsed time = ['+str(timestamp_dur)+ ']')\n","log_handle.close()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1R_BAOiyAklo","colab_type":"text"},"source":["## [ 6.2_V_CLASS_DS ]"]},{"cell_type":"code","metadata":{"id":"acWTpXB2Ao2O","colab_type":"code","colab":{}},"source":["# CELL 0\n","'''\n","1. Build train_db dict object [CELL 1]\n","2. Select g_CLASS_II_POSTFIX and limit values [CELL 2]\n","3. Select your query [CELL 3]\n","'''\n","#%% CELL 1\n","#------------------------------------------------------------------------\n","\n","train_db = train_db1\n","\n","#%% CELL 2\n","#------------------------------------------------------------------------\n","\n","g_CLASS_II_POSTFIX = 'V'   ##<<<<---------------- [select your post fix]\n","lim_lower, lim_upper = 40, 100 ##<<<<---------------- [select your beat limits]\n","\n","# log file --------------------------------------------------------------------\n","log_file= os.path.join(global_datadir, g_CLASS_II_POSTFIX+'_db_build_log.txt') \n","def print_log(log_string):\n","    log_handle.write(log_string+'\\n')\n","\n","#%% CELL 3\n","#------------------------------------------------------------------------\n","\n","all_total_sveb = 0\n","log_handle = open(log_file,'w')\n","timestamp_start = datetime.datetime.now()\n","print('\\n Start Iteration for '+g_CLASS_II_POSTFIX+' \\n')\n","print_log(g_CLASS_II_POSTFIX+'_LOG_START ['+str(timestamp_start)+ ']')\n","print_log('nos_beat_limits[lower,upper] = ['+ str(lim_lower)+ ','+ str(lim_upper)+']')\n","for idb in train_db.keys():\n","    sel_db = train_db[idb]\n","    #if idb!='svdb':\n","    #    continue\n","    for irec in sel_db.recs:\n","    #    if irec!='865':\n","    #        continue\n","        rst = ''\n","        sel_rec = sel_db.get_record(irec)      \n","        sel_sig = sel_rec.read_data(g_SIG_II_POSTFIX)\n","        rst += str(sel_rec.name)+'\\t'\n","        \n","        #============================================================\n","        print_log('\\n\\n[Selected Record = '+str(sel_rec.name)+ ']')\n","        #============================================================\n","        \n","        if len(sel_sig)<1:\n","            rst+='\\tSignal doesnt exist, Skip this record'\n","            print(rst)\n","            \n","            #============================================================\n","            print_log(' >>Signal doesnt exist, Skip this record')\n","            #============================================================\n","                    \n","            continue\n","        \n","        sbi = sel_rec.read_binfo()      # load beat info\n","    \n","\n","    #----------------------------------------------------------------------------------\n","    #----------------------------------------------------------------------------------\n","        sveb_list = []\n","        sveb_query = ((sbi.rr_labels=='V')) ##<<<<<<<<<<<<<<<<<<<<---------------[Select your query]\n","        sveb_list = np.where(sveb_query)[0]\n","    #----------------------------------------------------------------------------------\n","    #----------------------------------------------------------------------------------\n","    \n","    \n","        \n","        if len(sveb_list)<lim_lower:\n","            rst+='\\tNot enough CLASS beats, Skip this record'\n","            print(rst )\n","            #============================================================\n","            print_log(' >>Invalid query_count = '+str(len(sveb_list))+ ' - skip record')\n","            #============================================================\n","            continue\n","        else:\n","            \n","            #============================================================\n","            print_log(' >>Valid query_count = '+str(len(sveb_list)))\n","            #============================================================\n","            \n","            \n","            rst+='\\tquery:'+str(len(sveb_list))\n","            sveb_sel = np.zeros((0,v_dimC+2),dtype='float') # +2 for peak location and duration\n","            \n","            if len(sveb_list)<=lim_upper: \n","                #============================================================\n","                print_log('CASE_1::query_count <= upper_limit : Need to select all class beats, iterate ...')\n","                #============================================================\n","                rst+='\\tquery<=upperlimit'\n","                # is within selction limits, select all class beats\n","                for ibeat in sveb_list:\n","                    sg,pk = sbi.get_signal_data_var(ibeat)\n","                    \n","                    #============================================================\n","                    print_log('\\tbeat# '+str(ibeat) + '\\tLabel='+sbi.rr_labels[ibeat]+ '\\tTS='+str(round(sbi.rr_peaks_sec[ibeat],2))+'\\tDUR='+str(sbi.rri_dur[ibeat]))\n","                    #============================================================\n","                    \n","                    sg_resamp = scsig.resample(sg,v_dimC)\n","                    pk_resamp = round(pk*( len(sg_resamp)/(len(sg) )))\n","                    beat_duration = sbi.rri_dur[ibeat]\n","                    \n","                    #[ orignal_duration(secs), peak_location(samples),resampled_signal{array}]\n","                    a_resamp = np.hstack((beat_duration,pk_resamp,sg_resamp))\n","                    \n","                    #============================================================\n","                    #print_log('\\tMeta: ['+ str(len(a_resamp)) +']:'+str(a_resamp[0:3]))\n","                    #============================================================\n","                    \n","                    sveb_sel = np.vstack((sveb_sel, a_resamp)) # done now save it\n","                    \n","                #============================================================\n","                print_log('CASE_1::End of Selection, beats_selected = '+ str(sveb_sel.shape))\n","                #============================================================\n","                   \n","            else: # len(sveb_list)>lim_upper\n","                # more than upper_limit find episodes\n","                \n","                #============================================================\n","                print_log('CASE_2::query_count > upper_limit : Do not select all class beats. Find episodes...')\n","                #============================================================\n","                \n","                rst+='\\tquery>upperlimit'\n","                sveb_list1 = np.hstack((np.sort(sveb_list),np.array([-1])))\n","                \n","                sveb_epi = []\n","                # extract episodes from sveb_list\n","                s_s = sveb_list[0]\n","                delta = 1\n","                for i in range(1, len(sveb_list1)):\n","                    s_e = sveb_list1[i]\n","                    if s_e == s_s + delta:\n","                        delta+=1\n","                    else:\n","                        sveb_epi.append([s_s,s_s+delta])\n","                        s_s = s_e\n","                        delta = 1      \n","                        \n","                if len(sveb_epi)==0:\n","                    rst+='\\tImpossible::Not enough class episodes, Skip this record'#<<- this cannot happen\n","                    print(rst)\n","                    print_log('CASE_2::Impossible, no class episodes exist!!')\n","                    continue    \n","                else:\n","                    rst+='\\t'+ str(len(sveb_epi))    \n","                #============================================================\n","                print_log(' >>found episodes : '+ str(len(sveb_epi))+'\\n >>compare #episodes and upper selection limit..')\n","                #============================================================               \n","  \n","                if len(sveb_epi)<=lim_upper:\n","                    delta_ratio = lim_upper/len(sveb_list)\n","                    \n","                    #============================================================\n","                    print_log('CASE_2.1::Less episodes than upper limit : Selection ratio [upper_limit/total_beats] = '+str(round(delta_ratio,2)))\n","                    #============================================================                      \n","                    \n","                    rst+='\\t#epi<=upperlimit, delta_ratio='+ str(round(delta_ratio,2))\n","                    # take delta_ratio times beats from each episode\n","                    \n","                    #============================================================ \n","                    print_log(' >>Prepare rsel: take delta_ratio times beats from each episode, iterate...')\n","                    #============================================================ \n","                    \n","                    for iepi in range(0,len(sveb_epi)):\n","                        i_episode = sveb_epi[iepi]\n","\n","                        beats_in_epi = i_episode[1]-i_episode[0]\n","\n","                        beats_taken = int(int(beats_in_epi*delta_ratio))\n","                        if beats_taken==0:\n","                            beats_taken = 1 # atleast take one beat from each episode\n","                        \n","                        #============================================================ \n","                        print_log('\\tepisode# '+ str(iepi)+'='+str(i_episode)+\n","                              ' has '+ str(beats_in_epi)+ ' beats, randomly take '+\n","                              str(beats_taken)+ ' beats')                        \n","                        #============================================================ \n","\n","                        a = np.arange(i_episode[0],i_episode[1])\n","                        rsel = np.random.choice(a, size=beats_taken, replace=False, p=None)\n","                        \n","                        print_log('\\t >>Selected: '+ str(rsel)+' iterate...')\n","                        for ibeat in rsel:\n","                            sg,pk = sbi.get_signal_data_var(ibeat)\n","                            \n","                            #============================================================\n","                            print_log('\\t\\tbeat# '+str(ibeat) + '\\tL='+sbi.rr_labels[ibeat]+ '\\tTS='+str(round(sbi.rr_peaks_sec[ibeat],2))+'\\tDUR='+str(sbi.rri_dur[ibeat]))\n","                            #============================================================\n","                            \n","                            sg_resamp = scsig.resample(sg,v_dimC)\n","                            pk_resamp = round(pk*( len(sg_resamp)/(len(sg) )))\n","                            beat_duration = sbi.rri_dur[ibeat]\n","                            \n","                            #[ orignal_duration(secs), peak_location(samples),resampled_signal{array}]\n","                            a_resamp = np.hstack((beat_duration,pk_resamp,sg_resamp))\n","                            \n","                            #============================================================ \n","                            #print_log('\\tMeta: ['+ str(len(a_resamp)) +']:'+str(a_resamp[0:3]))\n","                            #============================================================ \n","                            \n","                            sveb_sel = np.vstack((sveb_sel, a_resamp))  # done now save it\n","                            \n","                        #============================================================\n","                        #print_log('\\tend of episode iteration sbeats_selected(this episode) = '+ str(sveb_sel.shape))\n","                        #============================================================\n","                        \n","                    #============================================================\n","                    print_log('end of all episode iteration beats_selected(overall) = '+ str(sveb_sel.shape))\n","                    #============================================================\n","                    \n","                else: # is in b/w upper and lower limit, select one from each episode\n","\n","                    delta_epi = int(len(sveb_epi) / lim_upper) #how many extra episodes\n","                    \n","                    #============================================================\n","                    print_log('CASE_2.2::More episodes than upper limit, index step = int[total_episodes / upperlimit] = '+str(round(delta_epi,2)))\n","                    #============================================================  \n","\n","                    rst+='\\t#epi>upperlimit delta_epi='+ str(round(delta_epi,2))\n","                    ist = 0\n","                    rsel=np.zeros(lim_upper,dtype='int')\n","                    \n","                    ##============================================================  \n","                    print_log(' >>Prepare rsel: step indices, select ONE beat randomly from each episode, iterate...')\n","                    #============================================================  \n","                    \n","                    for ix in range(0,lim_upper):\n","                        i_episode = sveb_epi[ist]\n","                        beats_in_epi = i_episode[1]-i_episode[0]\n","                        j_sel = i_episode[0]\n","                        \n","                        if beats_in_epi > 1:\n","                            j_sel = random.randint(i_episode[0],i_episode[1]-1)\n","                            \n","                        #============================================================  \n","                        print_log('\\tepisode# '+ str(ist)+'='+str(i_episode)+\n","                              ' has '+ str(beats_in_epi)+ ' beats, take random # '+\n","                              str(j_sel))                            \n","                        #============================================================  \n","                        \n","                        rsel[ix] = j_sel\n","                        ist+=delta_epi\n","                        \n","                    #============================================================  \n","                    print_log('Selected Striding: '+ str(rsel)+' iterate...')\n","                    #============================================================  \n","                    \n","                    for ibeat in rsel:\n","                        sg,pk = sbi.get_signal_data_var(ibeat)\n","                        \n","                        #============================================================\n","                        print_log('\\tbeat# '+str(ibeat) + '\\tL='+sbi.rr_labels[ibeat]+ '\\tTS='+str(round(sbi.rr_peaks_sec[ibeat],2))+'\\tDUR='+str(sbi.rri_dur[ibeat]))\n","                        #============================================================\n","                        \n","                        sg_resamp = scsig.resample(sg,v_dimC)\n","                        pk_resamp = round(pk*( len(sg_resamp)/(len(sg) )))\n","                        beat_duration = sbi.rri_dur[ibeat]\n","                        \n","                        #[ orignal_duration(secs), peak_location(samples),resampled_signal{array}]\n","                        a_resamp = np.hstack((beat_duration,pk_resamp,sg_resamp))\n","                        \n","                        #============================================================  \n","                        #print_log('\\tMeta: ['+ str(len(a_resamp)) +']:'+str(a_resamp[0:3]))\n","                        #============================================================  \n","                        \n","                        sveb_sel = np.vstack((sveb_sel, a_resamp))    \n","                        \n","                    #============================================================\n","                    print_log('end of iteration beats_selected = '+ str(sveb_sel.shape))\n","                    #============================================================\n","                    \n","            #============================================================\n","            print_log('end of record, total_beats_selected = '+ str(sveb_sel.shape))\n","            #============================================================\n","            \n","            rst+='\\ttotal_CLASS_BEATS:'+ str(len(sveb_sel))\n","            print(rst)   \n","            \n","            sel_rec.save_data(g_CLASS_II_POSTFIX,sveb_sel)\n","            \n","            all_total_sveb+=len(sveb_sel)            \n","            \n","    # loop end record ----------------------------------------------------------------------------------\n","# loop end database ----------------------------------------------------------------------------------\n","\n","timestamp_dur = datetime.datetime.now() - timestamp_start\n","print('Elapsed time = ' + str(timestamp_dur))\n","print('\\nEnd of Procedure, grand_total_class_beats = '+ str(all_total_sveb))\n","print_log('\\nEnd of Procedure, grand_total_beats = '+ str(all_total_sveb))\n","print_log('\\n'+g_CLASS_II_POSTFIX+'_LOG_END, elapsed time = ['+str(timestamp_dur)+ ']')\n","log_handle.close()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zipy-TzoAt9M","colab_type":"text"},"source":["## [ 6.3_F_CLASS_DS ]"]},{"cell_type":"code","metadata":{"id":"K7VSuV07AxRB","colab_type":"code","colab":{}},"source":["# CELL 0\n","'''\n","1. Build train_db dict object [CELL 1]\n","2. Select g_CLASS_II_POSTFIX and limit values [CELL 2]\n","3. Select your query [CELL 3]\n","'''\n","#%% CELL 1\n","#------------------------------------------------------------------------\n","\n","train_db = train_db1\n","\n","#%% CELL 2\n","#------------------------------------------------------------------------\n","\n","g_CLASS_II_POSTFIX = 'F'   ##<<<<---------------- [select your post fix]\n","lim_lower, lim_upper = 40, 100 ##<<<<---------------- [select your beat limits]\n","\n","# log file --------------------------------------------------------------------\n","log_file= os.path.join(global_datadir, g_CLASS_II_POSTFIX+'_db_build_log.txt') \n","def print_log(log_string):\n","    log_handle.write(log_string+'\\n')\n","\n","#%% CELL 3\n","#------------------------------------------------------------------------\n","\n","all_total_sveb = 0\n","log_handle = open(log_file,'w')\n","timestamp_start = datetime.datetime.now()\n","print('\\n Start Iteration for '+g_CLASS_II_POSTFIX+' \\n')\n","print_log(g_CLASS_II_POSTFIX+'_LOG_START ['+str(timestamp_start)+ ']')\n","print_log('nos_beat_limits[lower,upper] = ['+ str(lim_lower)+ ','+ str(lim_upper)+']')\n","for idb in train_db.keys():\n","    sel_db = train_db[idb]\n","    #if idb!='svdb':\n","    #    continue\n","    for irec in sel_db.recs:\n","    #    if irec!='865':\n","    #        continue\n","        rst = ''\n","        sel_rec = sel_db.get_record(irec)      \n","        sel_sig = sel_rec.read_data(g_SIG_II_POSTFIX)\n","        rst += str(sel_rec.name)+'\\t'\n","        \n","        #============================================================\n","        print_log('\\n\\n[Selected Record = '+str(sel_rec.name)+ ']')\n","        #============================================================\n","        \n","        if len(sel_sig)<1:\n","            rst+='\\tSignal doesnt exist, Skip this record'\n","            print(rst)\n","            \n","            #============================================================\n","            print_log(' >>Signal doesnt exist, Skip this record')\n","            #============================================================\n","                    \n","            continue\n","        \n","        sbi = sel_rec.read_binfo()      # load beat info\n","    \n","\n","    #----------------------------------------------------------------------------------\n","    #----------------------------------------------------------------------------------\n","        sveb_list = []\n","        sveb_query = (\n","                    (sbi.rr_labels=='F')  |\n","                    (sbi.rr_labels=='e')  |\n","                    (sbi.rr_labels=='j')  |\n","                    (sbi.rr_labels=='n')  \n","                  )\n","        ##<<<<<<<<<<<<<<<<<<<<---------------[Select your query]\n","        sveb_list = np.where(sveb_query)[0]\n","    #----------------------------------------------------------------------------------\n","    #----------------------------------------------------------------------------------\n","    \n","    \n","        \n","        if len(sveb_list)<lim_lower:\n","            rst+='\\tNot enough CLASS beats, Skip this record'\n","            print(rst )\n","            #============================================================\n","            print_log(' >>Invalid query_count = '+str(len(sveb_list))+ ' - skip record')\n","            #============================================================\n","            continue\n","        else:\n","            \n","            #============================================================\n","            print_log(' >>Valid query_count = '+str(len(sveb_list)))\n","            #============================================================\n","            \n","            \n","            rst+='\\tquery:'+str(len(sveb_list))\n","            sveb_sel = np.zeros((0,v_dimC+2),dtype='float') # +2 for peak location and duration\n","            \n","            if len(sveb_list)<=lim_upper: \n","                #============================================================\n","                print_log('CASE_1::query_count <= upper_limit : Need to select all class beats, iterate ...')\n","                #============================================================\n","                rst+='\\tquery<=upperlimit'\n","                # is within selction limits, select all class beats\n","                for ibeat in sveb_list:\n","                    sg,pk = sbi.get_signal_data_var(ibeat)\n","                    \n","                    #============================================================\n","                    print_log('\\tbeat# '+str(ibeat) + '\\tLabel='+sbi.rr_labels[ibeat]+ '\\tTS='+str(round(sbi.rr_peaks_sec[ibeat],2))+'\\tDUR='+str(sbi.rri_dur[ibeat]))\n","                    #============================================================\n","                    \n","                    sg_resamp = scsig.resample(sg,v_dimC)\n","                    pk_resamp = round(pk*( len(sg_resamp)/(len(sg) )))\n","                    beat_duration = sbi.rri_dur[ibeat]\n","                    \n","                    #[ orignal_duration(secs), peak_location(samples),resampled_signal{array}]\n","                    a_resamp = np.hstack((beat_duration,pk_resamp,sg_resamp))\n","                    \n","                    #============================================================\n","                    #print_log('\\tMeta: ['+ str(len(a_resamp)) +']:'+str(a_resamp[0:3]))\n","                    #============================================================\n","                    \n","                    sveb_sel = np.vstack((sveb_sel, a_resamp)) # done now save it\n","                    \n","                #============================================================\n","                print_log('CASE_1::End of Selection, beats_selected = '+ str(sveb_sel.shape))\n","                #============================================================\n","                   \n","            else: # len(sveb_list)>lim_upper\n","                # more than upper_limit find episodes\n","                \n","                #============================================================\n","                print_log('CASE_2::query_count > upper_limit : Do not select all class beats. Find episodes...')\n","                #============================================================\n","                \n","                rst+='\\tquery>upperlimit'\n","                sveb_list1 = np.hstack((np.sort(sveb_list),np.array([-1])))\n","                \n","                sveb_epi = []\n","                # extract episodes from sveb_list\n","                s_s = sveb_list[0]\n","                delta = 1\n","                for i in range(1, len(sveb_list1)):\n","                    s_e = sveb_list1[i]\n","                    if s_e == s_s + delta:\n","                        delta+=1\n","                    else:\n","                        sveb_epi.append([s_s,s_s+delta])\n","                        s_s = s_e\n","                        delta = 1      \n","                        \n","                if len(sveb_epi)==0:\n","                    rst+='\\tImpossible::Not enough class episodes, Skip this record'#<<- this cannot happen\n","                    print(rst)\n","                    print_log('CASE_2::Impossible, no class episodes exist!!')\n","                    continue    \n","                else:\n","                    rst+='\\t'+ str(len(sveb_epi))    \n","                #============================================================\n","                print_log(' >>found episodes : '+ str(len(sveb_epi))+'\\n >>compare #episodes and upper selection limit..')\n","                #============================================================               \n","  \n","                if len(sveb_epi)<=lim_upper:\n","                    delta_ratio = lim_upper/len(sveb_list)\n","                    \n","                    #============================================================\n","                    print_log('CASE_2.1::Less episodes than upper limit : Selection ratio [upper_limit/total_beats] = '+str(round(delta_ratio,2)))\n","                    #============================================================                      \n","                    \n","                    rst+='\\t#epi<=upperlimit, delta_ratio='+ str(round(delta_ratio,2))\n","                    # take delta_ratio times beats from each episode\n","                    \n","                    #============================================================ \n","                    print_log(' >>Prepare rsel: take delta_ratio times beats from each episode, iterate...')\n","                    #============================================================ \n","                    \n","                    for iepi in range(0,len(sveb_epi)):\n","                        i_episode = sveb_epi[iepi]\n","\n","                        beats_in_epi = i_episode[1]-i_episode[0]\n","\n","                        beats_taken = int(int(beats_in_epi*delta_ratio))\n","                        if beats_taken==0:\n","                            beats_taken = 1 # atleast take one beat from each episode\n","                        \n","                        #============================================================ \n","                        print_log('\\tepisode# '+ str(iepi)+'='+str(i_episode)+\n","                              ' has '+ str(beats_in_epi)+ ' beats, randomly take '+\n","                              str(beats_taken)+ ' beats')                        \n","                        #============================================================ \n","\n","                        a = np.arange(i_episode[0],i_episode[1])\n","                        rsel = np.random.choice(a, size=beats_taken, replace=False, p=None)\n","                        \n","                        print_log('\\t >>Selected: '+ str(rsel)+' iterate...')\n","                        for ibeat in rsel:\n","                            sg,pk = sbi.get_signal_data_var(ibeat)\n","                            \n","                            #============================================================\n","                            print_log('\\t\\tbeat# '+str(ibeat) + '\\tL='+sbi.rr_labels[ibeat]+ '\\tTS='+str(round(sbi.rr_peaks_sec[ibeat],2))+'\\tDUR='+str(sbi.rri_dur[ibeat]))\n","                            #============================================================\n","                            \n","                            sg_resamp = scsig.resample(sg,v_dimC)\n","                            pk_resamp = round(pk*( len(sg_resamp)/(len(sg) )))\n","                            beat_duration = sbi.rri_dur[ibeat]\n","                            \n","                            #[ orignal_duration(secs), peak_location(samples),resampled_signal{array}]\n","                            a_resamp = np.hstack((beat_duration,pk_resamp,sg_resamp))\n","                            \n","                            #============================================================ \n","                            #print_log('\\tMeta: ['+ str(len(a_resamp)) +']:'+str(a_resamp[0:3]))\n","                            #============================================================ \n","                            \n","                            sveb_sel = np.vstack((sveb_sel, a_resamp))  # done now save it\n","                            \n","                        #============================================================\n","                        #print_log('\\tend of episode iteration sbeats_selected(this episode) = '+ str(sveb_sel.shape))\n","                        #============================================================\n","                        \n","                    #============================================================\n","                    print_log('end of all episode iteration beats_selected(overall) = '+ str(sveb_sel.shape))\n","                    #============================================================\n","                    \n","                else: # is in b/w upper and lower limit, select one from each episode\n","\n","                    delta_epi = int(len(sveb_epi) / lim_upper) #how many extra episodes\n","                    \n","                    #============================================================\n","                    print_log('CASE_2.2::More episodes than upper limit, index step = int[total_episodes / upperlimit] = '+str(round(delta_epi,2)))\n","                    #============================================================  \n","\n","                    rst+='\\t#epi>upperlimit delta_epi='+ str(round(delta_epi,2))\n","                    ist = 0\n","                    rsel=np.zeros(lim_upper,dtype='int')\n","                    \n","                    ##============================================================  \n","                    print_log(' >>Prepare rsel: step indices, select ONE beat randomly from each episode, iterate...')\n","                    #============================================================  \n","                    \n","                    for ix in range(0,lim_upper):\n","                        i_episode = sveb_epi[ist]\n","                        beats_in_epi = i_episode[1]-i_episode[0]\n","                        j_sel = i_episode[0]\n","                        \n","                        if beats_in_epi > 1:\n","                            j_sel = random.randint(i_episode[0],i_episode[1]-1)\n","                            \n","                        #============================================================  \n","                        print_log('\\tepisode# '+ str(ist)+'='+str(i_episode)+\n","                              ' has '+ str(beats_in_epi)+ ' beats, take random # '+\n","                              str(j_sel))                            \n","                        #============================================================  \n","                        \n","                        rsel[ix] = j_sel\n","                        ist+=delta_epi\n","                        \n","                    #============================================================  \n","                    print_log('Selected Striding: '+ str(rsel)+' iterate...')\n","                    #============================================================  \n","                    \n","                    for ibeat in rsel:\n","                        sg,pk = sbi.get_signal_data_var(ibeat)\n","                        \n","                        #============================================================\n","                        print_log('\\tbeat# '+str(ibeat) + '\\tL='+sbi.rr_labels[ibeat]+ '\\tTS='+str(round(sbi.rr_peaks_sec[ibeat],2))+'\\tDUR='+str(sbi.rri_dur[ibeat]))\n","                        #============================================================\n","                        \n","                        sg_resamp = scsig.resample(sg,v_dimC)\n","                        pk_resamp = round(pk*( len(sg_resamp)/(len(sg) )))\n","                        beat_duration = sbi.rri_dur[ibeat]\n","                        \n","                        #[ orignal_duration(secs), peak_location(samples),resampled_signal{array}]\n","                        a_resamp = np.hstack((beat_duration,pk_resamp,sg_resamp))\n","                        \n","                        #============================================================  \n","                        #print_log('\\tMeta: ['+ str(len(a_resamp)) +']:'+str(a_resamp[0:3]))\n","                        #============================================================  \n","                        \n","                        sveb_sel = np.vstack((sveb_sel, a_resamp))    \n","                        \n","                    #============================================================\n","                    print_log('end of iteration beats_selected = '+ str(sveb_sel.shape))\n","                    #============================================================\n","                    \n","            #============================================================\n","            print_log('end of record, total_beats_selected = '+ str(sveb_sel.shape))\n","            #============================================================\n","            \n","            rst+='\\ttotal_CLASS_BEATS:'+ str(len(sveb_sel))\n","            print(rst)   \n","            \n","            sel_rec.save_data(g_CLASS_II_POSTFIX,sveb_sel)\n","            \n","            all_total_sveb+=len(sveb_sel)            \n","            \n","    # loop end record ----------------------------------------------------------------------------------\n","# loop end database ----------------------------------------------------------------------------------\n","\n","timestamp_dur = datetime.datetime.now() - timestamp_start\n","print('Elapsed time = ' + str(timestamp_dur))\n","print('\\nEnd of Procedure, grand_total_class_beats = '+ str(all_total_sveb))\n","print_log('\\nEnd of Procedure, grand_total_beats = '+ str(all_total_sveb))\n","print_log('\\n'+g_CLASS_II_POSTFIX+'_LOG_END, elapsed time = ['+str(timestamp_dur)+ ']')\n","log_handle.close()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nwt8Ln-6A0oH","colab_type":"text"},"source":["## [ 6.4_N_CLASS_DS ]"]},{"cell_type":"code","metadata":{"id":"tCYaG14dA46Z","colab_type":"code","colab":{}},"source":["# CELL 0\n","'''\n","1. Build train_db dict object [CELL 1]\n","2. Select g_CLASS_II_POSTFIX and limit values [CELL 2]\n","3. Select your query [CELL 3]\n","'''\n","#%% CELL 1\n","#------------------------------------------------------------------------\n","\n","train_db = train_db1\n","\n","#%% CELL 2\n","#------------------------------------------------------------------------\n","\n","g_CLASS_II_POSTFIX = 'N'   ##<<<<---------------- [select your post fix]\n","lim_lower, lim_upper = 40, 100 ##<<<<---------------- [select your beat limits]\n","\n","# log file --------------------------------------------------------------------\n","log_file= os.path.join(global_datadir, g_CLASS_II_POSTFIX+'_db_build_log.txt') \n","def print_log(log_string):\n","    log_handle.write(log_string+'\\n')\n","\n","#%% CELL 3\n","#------------------------------------------------------------------------\n","\n","all_total_sveb = 0\n","log_handle = open(log_file,'w')\n","timestamp_start = datetime.datetime.now()\n","print('\\n Start Iteration for '+g_CLASS_II_POSTFIX+' \\n')\n","print_log(g_CLASS_II_POSTFIX+'_LOG_START ['+str(timestamp_start)+ ']')\n","print_log('nos_beat_limits[lower,upper] = ['+ str(lim_lower)+ ','+ str(lim_upper)+']')\n","for idb in train_db.keys():\n","    sel_db = train_db[idb]\n","    #if idb!='mitdb':\n","     #   continue\n","    for irec in sel_db.recs:\n","        #if irec!='122':\n","         #   continue\n","        rst = ''\n","        sel_rec = sel_db.get_record(irec)      \n","        sel_sig = sel_rec.read_data(g_SIG_II_POSTFIX)\n","        rst += str(sel_rec.name)+'\\t'\n","        \n","        #============================================================\n","        print_log('\\n\\n[Selected Record = '+str(sel_rec.name)+ ']')\n","        #============================================================\n","        \n","        if len(sel_sig)<1:\n","            rst+='\\tSignal doesnt exist, Skip this record'\n","            print(rst)\n","            \n","            #============================================================\n","            print_log(' >>Signal doesnt exist, Skip this record')\n","            #============================================================\n","                    \n","            continue\n","        \n","        sbi = sel_rec.read_binfo()      # load beat info\n","    \n","\n","    #----------------------------------------------------------------------------------\n","    #----------------------------------------------------------------------------------\n","        sveb_list = []\n","        sveb_query = (\n","                    #(np.absolute(sbi.rri_delta)<=lim_delta_rri) & \n","                    (sbi.rr_int_labels==0)  &\n","                    (sbi.rr_int_plabels==0)  &\n","                    (sbi.rr_int_nlabels==0)\n","            ) ##<<<<<<<<<<<<<<<<<<<<---------------[Select your query]\n","        sveb_list = np.where(sveb_query)[0]\n","    #----------------------------------------------------------------------------------\n","    #----------------------------------------------------------------------------------\n","    \n","    \n","        \n","        if len(sveb_list)<lim_lower:\n","            rst+='\\tNot enough CLASS beats, Skip this record'\n","            print(rst )\n","            #============================================================\n","            print_log(' >>Invalid query_count = '+str(len(sveb_list))+ ' - skip record')\n","            #============================================================\n","            continue\n","        else:\n","            \n","            #============================================================\n","            print_log(' >>Valid query_count = '+str(len(sveb_list)))\n","            #============================================================\n","            \n","            \n","            rst+='\\tquery:'+str(len(sveb_list))\n","            sveb_sel = np.zeros((0,v_dimC+2),dtype='float') # +2 for peak location and duration\n","            \n","            if len(sveb_list)<=lim_upper: \n","                #============================================================\n","                print_log('CASE_1::query_count <= upper_limit : Need to select all class beats, iterate ...')\n","                #============================================================\n","                rst+='\\tquery<=upperlimit'\n","                # is within selction limits, select all class beats\n","                for ibeat in sveb_list:\n","                    sg,pk = sbi.get_signal_data_var(ibeat)\n","                    \n","                    #============================================================\n","                    print_log('\\tbeat# '+str(ibeat) + '\\tLabel='+sbi.rr_labels[ibeat]+ '\\tTS='+str(round(sbi.rr_peaks_sec[ibeat],2))+'\\tDUR='+str(sbi.rri_dur[ibeat]))\n","                    #============================================================\n","                    \n","                    sg_resamp = scsig.resample(sg,v_dimC)\n","                    pk_resamp = round(pk*( len(sg_resamp)/(len(sg) )))\n","                    beat_duration = sbi.rri_dur[ibeat]\n","                    \n","                    #[ orignal_duration(secs), peak_location(samples),resampled_signal{array}]\n","                    a_resamp = np.hstack((beat_duration,pk_resamp,sg_resamp))\n","                    \n","                    #============================================================\n","                    #print_log('\\tMeta: ['+ str(len(a_resamp)) +']:'+str(a_resamp[0:3]))\n","                    #============================================================\n","                    \n","                    sveb_sel = np.vstack((sveb_sel, a_resamp)) # done now save it\n","                    \n","                #============================================================\n","                print_log('CASE_1::End of Selection, beats_selected = '+ str(sveb_sel.shape))\n","                #============================================================\n","                   \n","            else: # len(sveb_list)>lim_upper\n","                # more than upper_limit find episodes\n","                \n","                #============================================================\n","                print_log('CASE_2::query_count > upper_limit : Do not select all class beats. Find episodes...')\n","                #============================================================\n","                \n","                rst+='\\tquery>upperlimit'\n","                sveb_list1 = np.hstack((np.sort(sveb_list),np.array([-1])))\n","                \n","                sveb_epi = []\n","                # extract episodes from sveb_list\n","                s_s = sveb_list[0]\n","                delta = 1\n","                for i in range(1, len(sveb_list1)):\n","                    s_e = sveb_list1[i]\n","                    if s_e == s_s + delta:\n","                        delta+=1\n","                    else:\n","                        sveb_epi.append([s_s,s_s+delta])\n","                        s_s = s_e\n","                        delta = 1      \n","                        \n","                if len(sveb_epi)==0:\n","                    rst+='\\tImpossible::Not enough class episodes, Skip this record'#<<- this cannot happen\n","                    print(rst)\n","                    print_log('CASE_2::Impossible, no class episodes exist!!')\n","                    continue    \n","                else:\n","                    rst+='\\t'+ str(len(sveb_epi))    \n","                #============================================================\n","                print_log(' >>found episodes : '+ str(len(sveb_epi))+'\\n >>compare #episodes and upper selection limit..')\n","                #============================================================               \n","  \n","                if len(sveb_epi)<=lim_upper:\n","                    delta_ratio = lim_upper/len(sveb_list)\n","                    \n","                    #============================================================\n","                    print_log('CASE_2.1::Less episodes than upper limit : Selection ratio [upper_limit/total_beats] = '+str(round(delta_ratio,2)))\n","                    #============================================================                      \n","                    \n","                    rst+='\\t#epi<=upperlimit, delta_ratio='+ str(round(delta_ratio,2))\n","                    # take delta_ratio times beats from each episode\n","                    \n","                    #============================================================ \n","                    print_log(' >>Prepare rsel: take delta_ratio times beats from each episode, iterate...')\n","                    #============================================================ \n","                    \n","                    for iepi in range(0,len(sveb_epi)):\n","                        i_episode = sveb_epi[iepi]\n","\n","                        beats_in_epi = i_episode[1]-i_episode[0]\n","\n","                        beats_taken = int(int(beats_in_epi*delta_ratio))\n","                        if beats_taken==0:\n","                            beats_taken = 1 # atleast take one beat from each episode\n","                        \n","                        #============================================================ \n","                        print_log('\\tepisode# '+ str(iepi)+'='+str(i_episode)+\n","                              ' has '+ str(beats_in_epi)+ ' beats, randomly take '+\n","                              str(beats_taken)+ ' beats')                        \n","                        #============================================================ \n","\n","                        a = np.arange(i_episode[0],i_episode[1])\n","                        rsel = np.random.choice(a, size=beats_taken, replace=False, p=None)\n","                        \n","                        print_log('\\t >>Selected: '+ str(rsel)+' iterate...')\n","                        for ibeat in rsel:\n","                            sg,pk = sbi.get_signal_data_var(ibeat)\n","                            \n","                            #============================================================\n","                            print_log('\\t\\tbeat# '+str(ibeat) + '\\tL='+sbi.rr_labels[ibeat]+ '\\tTS='+str(round(sbi.rr_peaks_sec[ibeat],2))+'\\tDUR='+str(sbi.rri_dur[ibeat]))\n","                            #============================================================\n","                            \n","                            sg_resamp = scsig.resample(sg,v_dimC)\n","                            pk_resamp = round(pk*( len(sg_resamp)/(len(sg) )))\n","                            beat_duration = sbi.rri_dur[ibeat]\n","                            \n","                            #[ orignal_duration(secs), peak_location(samples),resampled_signal{array}]\n","                            a_resamp = np.hstack((beat_duration,pk_resamp,sg_resamp))\n","                            \n","                            #============================================================ \n","                            #print_log('\\tMeta: ['+ str(len(a_resamp)) +']:'+str(a_resamp[0:3]))\n","                            #============================================================ \n","                            \n","                            sveb_sel = np.vstack((sveb_sel, a_resamp))  # done now save it\n","                            \n","                        #============================================================\n","                        #print_log('\\tend of episode iteration sbeats_selected(this episode) = '+ str(sveb_sel.shape))\n","                        #============================================================\n","                        \n","                    #============================================================\n","                    print_log('end of all episode iteration beats_selected(overall) = '+ str(sveb_sel.shape))\n","                    #============================================================\n","                    \n","                else: # is in b/w upper and lower limit, select one from each episode\n","\n","                    delta_epi = int(len(sveb_epi) / lim_upper) #how many extra episodes\n","                    \n","                    #============================================================\n","                    print_log('CASE_2.2::More episodes than upper limit, index step = int[total_episodes / upperlimit] = '+str(round(delta_epi,2)))\n","                    #============================================================  \n","\n","                    rst+='\\t#epi>upperlimit delta_epi='+ str(round(delta_epi,2))\n","                    ist = 0\n","                    rsel=np.zeros(lim_upper,dtype='int')\n","                    \n","                    ##============================================================  \n","                    print_log(' >>Prepare rsel: step indices, select ONE beat randomly from each episode, iterate...')\n","                    #============================================================  \n","                    \n","                    for ix in range(0,lim_upper):\n","                        i_episode = sveb_epi[ist]\n","                        beats_in_epi = i_episode[1]-i_episode[0]\n","                        j_sel = i_episode[0]\n","                        \n","                        if beats_in_epi > 1:\n","                            j_sel = random.randint(i_episode[0],i_episode[1]-1)\n","                            \n","                        #============================================================  \n","                        print_log('\\tepisode# '+ str(ist)+'='+str(i_episode)+\n","                              ' has '+ str(beats_in_epi)+ ' beats, take random # '+\n","                              str(j_sel))                            \n","                        #============================================================  \n","                        \n","                        rsel[ix] = j_sel\n","                        ist+=delta_epi\n","                        \n","                    #============================================================  \n","                    print_log('Selected Striding: '+ str(rsel)+' iterate...')\n","                    #============================================================  \n","                    \n","                    for ibeat in rsel:\n","                        sg,pk = sbi.get_signal_data_var(ibeat)\n","                        \n","                        #============================================================\n","                        print_log('\\tbeat# '+str(ibeat) + '\\tL='+sbi.rr_labels[ibeat]+ '\\tTS='+str(round(sbi.rr_peaks_sec[ibeat],2))+'\\tDUR='+str(sbi.rri_dur[ibeat]))\n","                        #============================================================\n","                        \n","                        sg_resamp = scsig.resample(sg,v_dimC)\n","                        pk_resamp = round(pk*( len(sg_resamp)/(len(sg) )))\n","                        beat_duration = sbi.rri_dur[ibeat]\n","                        \n","                        #[ orignal_duration(secs), peak_location(samples),resampled_signal{array}]\n","                        a_resamp = np.hstack((beat_duration,pk_resamp,sg_resamp))\n","                        \n","                        #============================================================  \n","                        #print_log('\\tMeta: ['+ str(len(a_resamp)) +']:'+str(a_resamp[0:3]))\n","                        #============================================================  \n","                        \n","                        sveb_sel = np.vstack((sveb_sel, a_resamp))    \n","                        \n","                    #============================================================\n","                    print_log('end of iteration beats_selected = '+ str(sveb_sel.shape))\n","                    #============================================================\n","                    \n","            #============================================================\n","            print_log('end of record, total_beats_selected = '+ str(sveb_sel.shape))\n","            #============================================================\n","            \n","            rst+='\\ttotal_CLASS_BEATS:'+ str(len(sveb_sel))\n","            print(rst)   \n","            \n","            sel_rec.save_data(g_CLASS_II_POSTFIX,sveb_sel)\n","            \n","            all_total_sveb+=len(sveb_sel)            \n","            \n","    # loop end record ----------------------------------------------------------------------------------\n","# loop end database ----------------------------------------------------------------------------------\n","\n","timestamp_dur = datetime.datetime.now() - timestamp_start\n","print('Elapsed time = ' + str(timestamp_dur))\n","print('\\nEnd of Procedure, grand_total_class_beats = '+ str(all_total_sveb))\n","print_log('\\nEnd of Procedure, grand_total_beats = '+ str(all_total_sveb))\n","print_log('\\n'+g_CLASS_II_POSTFIX+'_LOG_END, elapsed time = ['+str(timestamp_dur)+ ']')\n","log_handle.close()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5JRCWFYdBMjb","colab_type":"text"},"source":["# [ 7_COMPILE_DATASETS ]"]},{"cell_type":"markdown","metadata":{"id":"i0_eFdU9c3xY","colab_type":"text"},"source":["## [ 7.1_Compile_Training_Set ]"]},{"cell_type":"code","metadata":{"id":"_KgxSgWpBXVu","colab_type":"code","colab":{}},"source":["#<<---------------------------------- Select save name of this dataset\n","ds_name = 'custom_set_1'\n","ds_path = os.path.join(ds_dir, ds_name+'.npy') \n","\n","#<<---------------------------------- Select which working db to compile from\n","train_db = train_db1    \n","\n","#<<---------------------------------- SELCT PARAMS\n","g_REP_NORM_POSTFIX = 'REP_1800' # for taining use rep norm from full record\n","g_CLASS_N_POSTFIX = 'N'\n","g_CLASS_S_POSTFIX = 'S'\n","g_CLASS_V_POSTFIX = 'V'\n","g_CLASS_F_POSTFIX = 'F'\n","lim_min_rep_norms = 10 # at least this many rep norms must exist\n","#lim_lower, lim_upper = 40, 100 ##<<<<---------------- [select your beat limits]\n","#------------------------------------------------------------------------\n","\n","g_SUPRESS_DATA_WARNING=True # supress 'file not found' warnings from ecg_record class\n","\n","timestamp_start = datetime.datetime.now()\n","print('\\n Start Iteration for train_db \\n')\n","print('DB_REC\\t#r\\t#n\\t#s\\t#v\\t#f\\t#a\\tN~A\\tselN\\tselA\\tselNA\\trec_input')\n","mega_input = np.zeros((0,1+v_dimC+1+v_dimC+1))\n","for idb in train_db.keys():\n","    sel_db = train_db[idb]\n","    #if idb!='svdb':\n","     #   continue\n","    for irec in sel_db.recs:\n","        #if irec!='865':\n","         #   continue\n","        sel_rec = sel_db.get_record(irec)   \n","        \n","        #============================================================\n","        # print_log('\\n\\n[Selected Record = '+str(sel_rec.name)+ ']')\n","        #============================================================\n","        rst=sel_rec.name+'\\t'\n","        \n","        # first laod representative normal file\n","        npy_rep = sel_rec.read_data(g_REP_NORM_POSTFIX)\n","        nos_rep = len(npy_rep)\n","        \n","        # check if enough normal episodes\n","        if nos_rep<lim_min_rep_norms:\n","            #============================================================\n","            # print_log(' >> Not enough Representative Normals, skip record')\n","            #============================================================ \n","            rst+=' >> Not enough Representative Normals, skip record\\t'\n","            print(rst)\n","            continue\n","        else:\n","            #============================================================\n","            # print_log(' >> Nos Representative Normals = '+str(nos_rep))\n","            #============================================================           \n","            rst+=str(nos_rep)+'\\t'\n","        \n","        # Now load S,V,F beats, returns blank array if file doesn't exist\n","        npy_N = sel_rec.read_data(g_CLASS_N_POSTFIX)\n","        npy_S = sel_rec.read_data(g_CLASS_S_POSTFIX)\n","        npy_V = sel_rec.read_data(g_CLASS_V_POSTFIX)\n","        npy_F = sel_rec.read_data(g_CLASS_F_POSTFIX)\n","        \n","        nos_N, nos_S, nos_V, nos_F = len(npy_N), len(npy_S), len(npy_V), len(npy_F)\n","        nos_A = nos_S + nos_V + nos_F\n","        \n","        #============================================================\n","        # print_log(' >> Nos [N] = ['+str(nos_N)+']')\n","        # print_log(' >> Nos [S,V,F] = ['+str(nos_S)+','+str(nos_V)+','+str(nos_F)+'] = '+str(nos_A))\n","        #============================================================         \n","        rst+=str(nos_N)+'\\t'+str(nos_S)+'\\t'+str(nos_V)+'\\t'+str(nos_F)+'\\t'+str(nos_A)+'\\t'\n","        \n","        if nos_N == 0 or nos_A==0:\n","            #============================================================\n","            # print_log(' >> Cannot continue with zero beats, skip record')\n","            #============================================================\n","            rst+=' >> Cannot continue with zero beats, skip record\\t'\n","            print(rst)\n","            continue\n","        \n","        if nos_S == 0:\n","            npy_S = np.zeros((0,v_dimC+2))\n","            \n","        if nos_V == 0:\n","            npy_V = np.zeros((0,v_dimC+2))\n","            \n","        if nos_F == 0:\n","            npy_F = np.zeros((0,v_dimC+2))\n","        \n","\n","        \n","        # need to select as many as nos_A beats..and concatenate label = 1 (for abnormal)\n","        #label_A = np.ones((nos_A,1))\n","        sel_A = np.hstack((  \n","                        np.ones((nos_A,1)),             #<<----label\n","                        np.vstack((npy_S,npy_V,npy_F))  #<<----data\n","                        ))\n","        sel_N = []\n","        a = np.arange(0,nos_N)\n","        if nos_N>=nos_A:\n","            # random choice from nos_N \n","            #============================================================\n","            # print_log('CASE_1:: nos_N>=nos_A')\n","            #============================================================  \n","            rst+= ' N>=A\\t'\n","            sel_N = np.hstack((\n","                np.zeros((nos_A,1)),\n","                npy_N[ np.random.choice( a, size=nos_A, replace=False, p=None ) ]\n","                            ))\n","        else:\n","            # repeate N beats - how many to repeat ?\n","            #============================================================\n","            # print_log('CASE_2:: nos_N<nos_A')\n","            #============================================================  \n","            rst+= ' N<A\\t'\n","            nos_repeat = nos_A%nos_N\n","            times_repeat = int(nos_A/nos_N)\n","            \n","            npy_NT = np.zeros((0,v_dimC+2))\n","            for nr in range(0,times_repeat):\n","                npy_NT = np.vstack((npy_NT,npy_N))\n","            \n","            sel_N = np.hstack((\n","                        np.zeros((nos_A,1)),            \n","                        np.vstack((\n","                            npy_NT,    \n","                            npy_N[ np.random.choice( a, size=nos_repeat, replace=False, p=None ) ]\n","                                ))\n","                            ))\n","        #----- endof selection\n","        #============================================================\n","        # print_log('End of Selection :: N = '+ str(len(sel_N))+ ' A = '+str(len(sel_A)))\n","        #============================================================ \n","        rst+= str(len(sel_N))+ '\\t'+str(len(sel_A))+'\\t'\n","        \n","        sel_data = np.vstack((sel_A,sel_N))\n","        \n","        #============================================================ \n","        # print_log('Total beats :: '+ str(len(sel_data)))\n","        #============================================================ \n","        rst+= str(len(sel_data))+'\\t'\n","        \n","        \n","        # now select rep_normals to be used for training with data\n","        # >> sort by nos_beats and select high count episodes\n","        # col 0 contains nos_beats in that episode \n","        npy_rep_sort = npy_rep[np.argsort(npy_rep[:, 0])][0:lim_min_rep_norms]\n","        # structure of npy_rep is \n","        #               0 nos_beats, \n","        #               1 l_max(resampled length in samples), \n","        #               2 avg_dur(sec), \n","        #               3 var_dur, \n","        #               4:4+v_dimC mean_signal(array of len v_dimC), \n","        #               -v_dimC: median_signal(array of len v_dimC)\n","        \n","        # now total samples would be (nos_A + nos_N) * lim_min_rep_norms\n","        # inputs=[input_N, input_N_dur,input_C, input_C_dur],\n","        rec_input = np.zeros((0,1+v_dimC+1+v_dimC+1))\n","        for rr in npy_rep_sort:\n","\n","            #input_N = rr[4:4+v_dimC]  #<<------- mean representaion\n","            input_N = rr[-v_dimC:]  #<<------- median representaion\n","            \n","            #input_N_dur = rr[1]/BASIC_SRATE  #<<----------- max_duration of episode\n","            input_N_dur = rr[2]  #<<----------- avg_duration of episode\n","            \n","            for ss in sel_data: \n","            # NOTE : int lable has been stacked in front of array, shift index by 1\n","                input_label = ss[0] #<<----- label\n","                \n","                input_C = ss[-v_dimC:] #<<----- resampled signal\n","                \n","                input_C_dur = ss[1] #<<----- orginal duration of beat in seconds\n","                \n","                \n","                final_input = np.hstack((\n","                                        input_label,\n","                                        input_N,\n","                                        input_N_dur,\n","                                        input_C,\n","                                        input_C_dur\n","                                        ))\n","                \n","                rec_input = np.vstack((rec_input,final_input))\n","                \n","        #============================================================ \n","        # print_log('Record selection :: '+ str(rec_input.shape))\n","        #============================================================\n","        rst+= str(len(rec_input))\n","        print(rst)\n","\n","        mega_input = np.vstack((mega_input,rec_input))\n","\n","#============================================================ \n","# print_log('Total selection :: '+ str(mega_input.shape))\n","#============================================================\n","#rst+= str(len(mega_input))+'\\t'\n","print('\\nDone! Total beats = '+ str(len(mega_input)))\n","timestamp_dur = datetime.datetime.now() - timestamp_start\n","print('Elapsed time = ' + str(timestamp_dur))\n","\n","#%%\n","# save mega_input\n","np.save(ds_path,mega_input)\n","print('saved at '+ str(ds_path))\n","\n","#%%\n","g_SUPRESS_DATA_WARNING=False # resume 'file not found' warnings\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UeFD7TwZcn1d","colab_type":"text"},"source":["## [ 7.2_Compile_Testing_Set ]"]},{"cell_type":"code","metadata":{"id":"c-GZ99BQcwsY","colab_type":"code","colab":{}},"source":["#<<---------------------------------- Select save name of this dataset\n","ds_name = 'custom_set_test_1'\n","ds_path = os.path.join(ds_dir, ds_name+'.npy') \n","\n","#<<---------------------------------- Select which working db to compile from\n","g_REP_NORM_POSTFIX = 'REP_300'\n","lim_min_rep_norms = 1\n","#<<---------------------------------- Select which working db to compile from\n","test_db = test_db1\n","\n","g_SUPRESS_DATA_WARNING=True # supress 'file not found' warnings from ecg_record class\n","print('db_rec\\t#beats\\t#r\\t#stacked')\n","timestamp_start = datetime.datetime.now()\n","mega_input = np.zeros((0,1+v_dimC+1+v_dimC+1))\n","for idb in test_db.keys():\n","    #if idb!='svdb':\n","     #   continue\n","    sel_db = test_db[idb]\n","    for irec in sel_db.recs:\n","        #if irec!='865':\n","         #   continue\n","        #------------------------------------------------------------------------\n","        sel_rec = sel_db.get_record(irec)\n","        #print(sel_rec.name)\n","        #------------------------------------------------------------------------\n","        # load signal\n","        sel_sig = sel_rec.read_data(g_SIG_II_POSTFIX)\n","        rst=sel_rec.name+'\\t'\n","        #print('signal shape = ' + str(sel_sig.shape))\n","        if len(sel_sig)<1:\n","            rst+=' >>Signal cannot be loaded\\t'\n","            print(rst)\n","            continue\n","        #else:\n","        #    print(' >>Signal loaded succesfully')\n","\n","        # load beat info\n","        sbi = sel_rec.read_binfo()\n","        rst+=str(sbi.nos_rr_peaks)+'\\t'\n","\n","\n","        # first laod representative normal file\n","        \n","        npy_rep = sel_rec.read_data(g_REP_NORM_POSTFIX)\n","        nos_rep = len(npy_rep)\n","\n","        # check if enough normal episodes\n","        if nos_rep<lim_min_rep_norms:\n","            rst+=' >> Not enough Representative Normals\\t'\n","            print(rst)\n","            continue\n","        else:\n","            rst+=str(nos_rep)+'\\t'\n","\n","        all_beats = np.zeros((0,v_dimC+1+1))\n","        for ibeat in range(0,sbi.nos_rr_peaks):\n","            sg,pk = sbi.get_signal_data_var(ibeat)\n","            #============================================================\n","            #print_log('\\tbeat# '+str(ibeat) + '\\tLabel='+sbi.rr_labels[ibeat]+ '\\tTS='+str(round(sbi.rr_peaks_sec[ibeat],2))+'\\tDUR='+str(sbi.rri_dur[ibeat]))\n","            #============================================================\n","            sg_resamp = scsig.resample(sg,v_dimC)\n","            #pk_resamp = round(pk*( len(sg_resamp)/(len(sg) ))) #<<------ peak value not required now\n","            beat_duration = sbi.rri_dur[ibeat]\n","            beat_label = sbi.rr_int_labels[ibeat]\n","\n","            a_resamp = np.hstack((beat_label,beat_duration,sg_resamp)) \n","            all_beats = np.vstack((all_beats, a_resamp)) # done now save it   \n","\n","\n","        sel_replace = False\n","        if nos_rep<len(all_beats):\n","            sel_replace=True\n","\n","        a = np.arange(0,nos_rep) \n","        npy_rep_sel = npy_rep[np.random.choice( a, size=len(all_beats), replace=sel_replace, p=None )]\n","\n","        rec_input = np.zeros((0,1+v_dimC+1+v_dimC+1))\n","        for rs in range(0,len(all_beats)):\n","            rr = npy_rep_sel[rs]\n","            ss = all_beats[rs]\n","\n","            #input_N = rr[4:4+v_dimC]  #<<------- mean representaion\n","            input_N = rr[-v_dimC:]  #<<------- median representaion\n","            \n","            #input_N_dur = rr[1]/BASIC_SRATE  #<<----------- max_duration of episode\n","            input_N_dur = rr[2]  #<<----------- avg_duration of episode\n","        \n","            input_label = ss[0] #<<----- label\n","            \n","            input_C = ss[-v_dimC:] #<<----- resampled signal\n","            \n","            input_C_dur = ss[1] #<<----- orginal duration of beat in seconds\n","            \n","            \n","            final_input = np.hstack((\n","                                    input_label,\n","                                    input_N,\n","                                    input_N_dur,\n","                                    input_C,\n","                                    input_C_dur\n","                                    ))\n","            \n","            rec_input = np.vstack((rec_input,final_input))\n","        \n","        rst+=str(len(rec_input))\n","        print(rst)\n","        mega_input = np.vstack((mega_input,rec_input))\n","\n","np.save(ds_path,mega_input)\n","print('saved at '+ str(ds_path))\n","print('Done! Final Input shape:'+ str(mega_input.shape))\n","timestamp_dur = datetime.datetime.now() - timestamp_start\n","print('Elapsed time = ' + str(timestamp_dur))\n","g_SUPRESS_DATA_WARNING=False # supress 'file not found' warnings from ecg_record class"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7t_J-PRBT3TL","colab_type":"text"},"source":["## [ 7.3_Compile_Testing_Set_Class ]"]},{"cell_type":"code","metadata":{"id":"BeHBuVCzT9qs","colab_type":"code","colab":{}},"source":["#<<---------------------------------- Select save name of this dataset\n","ds_name = 'custom_set_test_1_Class_N'\n","ds_path = os.path.join(ds_dir, ds_name+'.npy') \n","\n","#<<---------------------------------- Select which working db to compile from\n","g_REP_NORM_POSTFIX = 'REP_300'\n","lim_min_rep_norms = 1\n","#<<---------------------------------- Select which working db to compile from\n","test_db = test_db1\n","\n","g_SUPRESS_DATA_WARNING=True # supress 'file not found' warnings from ecg_record class\n","print('db_rec\\t#beats\\t#r\\t#stacked')\n","timestamp_start = datetime.datetime.now()\n","mega_input = np.zeros((0,1+v_dimC+1+v_dimC+1))\n","for idb in test_db.keys():\n","    #if idb!='svdb':\n","     #   continue\n","    sel_db = test_db[idb]\n","    for irec in sel_db.recs:\n","        #if irec!='865':\n","         #   continue\n","        #------------------------------------------------------------------------\n","        sel_rec = sel_db.get_record(irec)\n","        #print(sel_rec.name)\n","        #------------------------------------------------------------------------\n","        # load signal\n","        sel_sig = sel_rec.read_data(g_SIG_II_POSTFIX)\n","        rst=sel_rec.name+'\\t'\n","        #print('signal shape = ' + str(sel_sig.shape))\n","        if len(sel_sig)<1:\n","            rst+=' >>Signal cannot be loaded\\t'\n","            print(rst)\n","            continue\n","        #else:\n","        #    print(' >>Signal loaded succesfully')\n","\n","        # load beat info\n","        sbi = sel_rec.read_binfo()\n","        rst+=str(sbi.nos_rr_peaks)+'\\t'\n","\n","\n","        # first laod representative normal file\n","        \n","        npy_rep = sel_rec.read_data(g_REP_NORM_POSTFIX)\n","        nos_rep = len(npy_rep)\n","\n","        # check if enough normal episodes\n","        if nos_rep<lim_min_rep_norms:\n","            rst+=' >> Not enough Representative Normals\\t'\n","            print(rst)\n","            continue\n","        else:\n","            rst+=str(nos_rep)+'\\t'\n","\n","    #----------------------------------------------------------------------------------\n","    # S = [A,a,J,S]\n","    # V = [V]\n","    # F = [F,e,j,n]\n","    # N = [N,L,R] \n","    #----------------------------------------------------------------------------------\n","        class_list = []\n","        class_query = (\n","                    #(sbi.rr_labels=='F')  |\n","                    (sbi.rr_labels=='N')  |\n","                    (sbi.rr_labels=='L')  |\n","                    (sbi.rr_labels=='R')  \n","                  )\n","        ##<<<<<<<<<<<<<<<<<<<<---------------[Select your query]\n","        class_list = np.where(class_query)[0]\n","    #----------------------------------------------------------------------------------\n","    #----------------------------------------------------------------------------------\n","\n","        if len(class_list)==0:\n","            rst+=' >> Not enough class beats'\n","            print(rst)\n","            continue\n","            \n","        all_beats = np.zeros((0,v_dimC+1+1))\n","        for ibeat in class_list:\n","            sg,pk = sbi.get_signal_data_var(ibeat)\n","            #============================================================\n","            #print_log('\\tbeat# '+str(ibeat) + '\\tLabel='+sbi.rr_labels[ibeat]+ '\\tTS='+str(round(sbi.rr_peaks_sec[ibeat],2))+'\\tDUR='+str(sbi.rri_dur[ibeat]))\n","            #============================================================\n","            sg_resamp = scsig.resample(sg,v_dimC)\n","            #pk_resamp = round(pk*( len(sg_resamp)/(len(sg) ))) #<<------ peak value not required now\n","            beat_duration = sbi.rri_dur[ibeat]\n","            beat_label = sbi.rr_int_labels[ibeat]\n","            #if beat_label!=1:\n","            #    print('WARNING check beat type')\n","            a_resamp = np.hstack((beat_label,beat_duration,sg_resamp)) \n","            all_beats = np.vstack((all_beats, a_resamp)) # done now save it   \n","\n","\n","        sel_replace = False\n","        if nos_rep<len(all_beats):\n","            sel_replace=True\n","\n","        a = np.arange(0,nos_rep) \n","        npy_rep_sel = npy_rep[np.random.choice( a, size=len(all_beats), replace=sel_replace, p=None )]\n","\n","        rec_input = np.zeros((0,1+v_dimC+1+v_dimC+1))\n","        for rs in range(0,len(all_beats)):\n","            rr = npy_rep_sel[rs]\n","            ss = all_beats[rs]\n","\n","            #input_N = rr[4:4+v_dimC]  #<<------- mean representaion\n","            input_N = rr[-v_dimC:]  #<<------- median representaion\n","            \n","            #input_N_dur = rr[1]/BASIC_SRATE  #<<----------- max_duration of episode\n","            input_N_dur = rr[2]  #<<----------- avg_duration of episode\n","        \n","            input_label = ss[0] #<<----- label\n","            \n","            input_C = ss[-v_dimC:] #<<----- resampled signal\n","            \n","            input_C_dur = ss[1] #<<----- orginal duration of beat in seconds\n","            \n","            \n","            final_input = np.hstack((\n","                                    input_label,\n","                                    input_N,\n","                                    input_N_dur,\n","                                    input_C,\n","                                    input_C_dur\n","                                    ))\n","            \n","            rec_input = np.vstack((rec_input,final_input))\n","        \n","        rst+=str(len(rec_input))\n","        print(rst)\n","        mega_input = np.vstack((mega_input,rec_input))\n","\n","np.save(ds_path,mega_input)\n","print('saved at '+ str(ds_path))\n","print('Done! Final Input shape:'+ str(mega_input.shape))\n","timestamp_dur = datetime.datetime.now() - timestamp_start\n","print('Elapsed time = ' + str(timestamp_dur))\n","g_SUPRESS_DATA_WARNING=False # supress 'file not found' warnings from ecg_record class"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0p69mkglC6SI","colab_type":"text"},"source":["# [ 8_MODEL_DEFINITIONS ]"]},{"cell_type":"code","metadata":{"id":"gTwyzAsLC_EN","colab_type":"code","colab":{}},"source":["'''\n","Callbacks\n","'''\n","cb_esr = tf.keras.callbacks.EarlyStopping(\n","        monitor='accuracy', \n","        min_delta=0.00001, \n","        patience=2, \n","        verbose=0, \n","        mode='auto', \n","        baseline=None, \n","        restore_best_weights=False)\n","cb_listr=[cb_esr] \n","\n","\"\"\"\n","MODEL\n","\n","\"\"\"\n","m_cost = 'sparse_categorical_crossentropy'\n","m_opt = 'rmsprop'\n","\n","def model_01(print_summary, input_shape_N, input_shape_C, fl_filters, nos_output):\n","    \n","    # NORMAL Input  +++++++++++++++++++++++++++++++++++++++++++++++++++++\n","    \n","    input_N = Input( shape=input_shape_N, name = \"input_N\" )\n","    input_N_dur = Input( shape=(1,), name = \"input_N_dur\" ) \n","    # NORMAL Feature extract +++++++++++++++++++++++++++++++++++++++++++++++++++++\n","    \n","    conv_N_1 =           Conv1D(30,                #filters, \n","                          fl_filters,          #kernel_size, \n","                          strides=1, \n","                          padding='valid', \n","                          data_format='channels_last', \n","                          dilation_rate=1, \n","                          activation=tf.nn.leaky_relu, \n","                          use_bias=True, \n","                          kernel_initializer='glorot_uniform', \n","                          bias_initializer='zeros', \n","                          kernel_regularizer=None, \n","                          bias_regularizer=None, \n","                          activity_regularizer=None, \n","                          kernel_constraint=None, \n","                          bias_constraint=None) (input_N) \n","    \n","    pool_N_2 =          MaxPooling1D(pool_size=2, \n","                                  strides=None, \n","                                  padding='valid', \n","                                  data_format='channels_last') (conv_N_1)\n","    \n","    conv_N_3 =           Conv1D(20,                #filters, \n","                          3,                  #kernel_size, \n","                          strides=1, \n","                          padding='valid', \n","                          data_format='channels_last', \n","                          dilation_rate=1, \n","                          activation=tf.nn.leaky_relu, \n","                          use_bias=True, \n","                          kernel_initializer='glorot_uniform', \n","                          bias_initializer='zeros', \n","                          kernel_regularizer=None, \n","                          bias_regularizer=None, \n","                          activity_regularizer=None, \n","                          kernel_constraint=None, \n","                          bias_constraint=None)(pool_N_2)\n","    \n","    pool_N_4 =          MaxPooling1D(pool_size=2, \n","                                  strides=None, \n","                                  padding='valid', \n","                                  data_format='channels_last') (conv_N_3)\n","    \n","    conv_N_5 =          Conv1D(10,                #filters, \n","                          3,                  #kernel_size, \n","                          strides=1, \n","                          padding='valid', \n","                          data_format='channels_last', \n","                          dilation_rate=1, \n","                          activation=tf.nn.leaky_relu, \n","                          use_bias=True, \n","                          kernel_initializer='glorot_uniform', \n","                          bias_initializer='zeros', \n","                          kernel_regularizer=None, \n","                          bias_regularizer=None, \n","                          activity_regularizer=None, \n","                          kernel_constraint=None, \n","                          bias_constraint=None) (pool_N_4)\n","    \n","    pool_N_6 =          MaxPooling1D(pool_size=2, \n","                                  strides=None, \n","                                  padding='valid', \n","                                  data_format='channels_last') (conv_N_5)\n","    \n","    # NORMAL Resgression  +++++++++++++++++++++++++++++++++++++++++++++++++++++\n","    \n","    flat_N_7 = Flatten(data_format=None) (pool_N_6)\n","    \n","    den_Ndur_concat =  tf.concat([flat_N_7, input_N_dur],axis=1, name = \"dense_N_concat\")\n","\n","    #den_N_8 =       Dense(20, \n","    #                activation=tf.nn.leaky_relu, \n","    #                name = \"dense_N\") (den_Ndur_concat)\n","\n","    \n","\n","    # DENSE Regression +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","\n","    #denN_01 = Dense(20, activation=tf.nn.relu, name = \"DENSE_N_01\")(den_N_8)\n","    \n","    #denN_02 = Dense(10, activation=tf.nn.relu, name = \"DENSE_N_02\")(denN_01)\n","\n","#------------------------------------------------------------------------------\n","\n","    # COMPAR Input  +++++++++++++++++++++++++++++++++++++++++++++++++++++\n","    \n","    input_C = Input( shape=input_shape_C, name = \"input_C\" )\n","    input_C_dur = Input( shape=(1,), name = \"input_C_dur\" ) \n","    # NORMAL Feature extract +++++++++++++++++++++++++++++++++++++++++++++++++++++\n","    \n","    conv_C_1 =           Conv1D(30,                #filters, \n","                          fl_filters,          #kernel_size, \n","                          strides=1, \n","                          padding='valid', \n","                          data_format='channels_last', \n","                          dilation_rate=1, \n","                          activation=tf.nn.leaky_relu, \n","                          use_bias=True, \n","                          kernel_initializer='glorot_uniform', \n","                          bias_initializer='zeros', \n","                          kernel_regularizer=None, \n","                          bias_regularizer=None, \n","                          activity_regularizer=None, \n","                          kernel_constraint=None, \n","                          bias_constraint=None) (input_C) \n","    \n","    pool_C_2 =          MaxPooling1D(pool_size=2, \n","                                  strides=None, \n","                                  padding='valid', \n","                                  data_format='channels_last') (conv_C_1)\n","    \n","    conv_C_3 =           Conv1D(20,                #filters, \n","                          3,                  #kernel_size, \n","                          strides=1, \n","                          padding='valid', \n","                          data_format='channels_last', \n","                          dilation_rate=1, \n","                          activation=tf.nn.leaky_relu, \n","                          use_bias=True, \n","                          kernel_initializer='glorot_uniform', \n","                          bias_initializer='zeros', \n","                          kernel_regularizer=None, \n","                          bias_regularizer=None, \n","                          activity_regularizer=None, \n","                          kernel_constraint=None, \n","                          bias_constraint=None)(pool_C_2)\n","    \n","    pool_C_4 =          MaxPooling1D(pool_size=2, \n","                                  strides=None, \n","                                  padding='valid', \n","                                  data_format='channels_last') (conv_C_3)\n","    \n","    conv_C_5 =          Conv1D(10,                #filters, \n","                          3,                  #kernel_size, \n","                          strides=1, \n","                          padding='valid', \n","                          data_format='channels_last', \n","                          dilation_rate=1, \n","                          activation=tf.nn.leaky_relu, \n","                          use_bias=True, \n","                          kernel_initializer='glorot_uniform', \n","                          bias_initializer='zeros', \n","                          kernel_regularizer=None, \n","                          bias_regularizer=None, \n","                          activity_regularizer=None, \n","                          kernel_constraint=None, \n","                          bias_constraint=None) (pool_C_4)\n","    \n","    pool_C_6 =          MaxPooling1D(pool_size=2, \n","                                  strides=None, \n","                                  padding='valid', \n","                                  data_format='channels_last') (conv_C_5)\n","    \n","    # NORMAL Resgression  +++++++++++++++++++++++++++++++++++++++++++++++++++++\n","    \n","    flat_C_7 = Flatten(data_format=None) (pool_C_6)\n","    \n","    den_Cdur_concat =  tf.concat([flat_C_7, input_C_dur],axis=1, name = \"dense_C_concat\")\n","\n","    #den_C_8 =       Dense(20, \n","    #                activation=tf.nn.leaky_relu, \n","    #                name = \"dense_C\") (den_Cdur_concat)\n","\n","    \n","\n","    # DENSE Regression +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","\n","    #denC_01 = Dense(20, activation=tf.nn.relu, name = \"DENSE_C_01\")(den_C_8)\n","    \n","    #denC_02 = Dense(10, activation=tf.nn.relu, name = \"DENSE_C_02\")(denC_01)\n","\n","#------------------------------------------------------------------------------\n","# N C Concat +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","\n","    den_NC_concat =  tf.concat([den_Ndur_concat, den_Cdur_concat],axis=1, name = \"dense_NC_concat\")\n","#------------------------------------------------------------------------------\n","    # DENSE Regression +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","\n","    den_NC_01 = Dense(20, activation=tf.nn.relu, name = \"DENSE_NC_01\")(den_NC_concat)\n","    \n","    den_NC_02 = Dense(10, activation=tf.nn.relu, name = \"DENSE_NC_02\")(den_NC_01)  \n","    \n","# OUTPUT  +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","\n","    den_out = Dense(nos_output, activation=tf.nn.softmax, name = \"OUTPUT_FC\")(den_NC_02)\n","\n","# =============================================================================\n","    \n","    model=Model(inputs=[input_N, input_N_dur,input_C, input_C_dur], outputs=den_out)\n","\n","    model.compile(\n","                  loss=m_cost, \n","                  optimizer=m_opt, \n","                  metrics=['accuracy']\n","                  )\n","    \n","    if print_summary:\n","        print(model.summary())\n","    return model\n","#==============================================================================\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G0hh1UMkDHV4","colab_type":"text"},"source":["# [ 9_EXPERIMENT ]"]},{"cell_type":"code","metadata":{"id":"m43lXiJ2DaNr","colab_type":"code","colab":{}},"source":["# list avaialble datasets\n","ls_datasets = os.listdir(ds_dir)\n","print('Available Datasets:')\n","for ds_i in ls_datasets:\n","    print(ds_i)\n","print('--------------------------')\n","\n","# list available models\n","ls_models = os.listdir(global_modeldir)\n","print('Available Models:')\n","for ms_i in ls_models:\n","    print(ms_i)\n","print('--------------------------')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J_tvzyc0DPGi","colab_type":"text"},"source":["## [ 9.1_TRAINING ]"]},{"cell_type":"code","metadata":{"id":"yQqZiuL4DLEt","colab_type":"code","colab":{}},"source":["# Training\n","##<---------------------------------------------- \n","ds_name = 'custom_set_1'    # SELECT DATASET FOR LOADING TRAINING DATA FROM\n","ds_model = 'model_1'       # SELECT NAME FOR SAVING MODEL WEIGHTS\n","##<----------------------------------------------\n","\n","\n","ds_path = os.path.join(ds_dir, ds_name+'.npy') \n","megaset = np.load(ds_path)    \n","print('Loaded data from '+ str(ds_path)+'\\nShape='+str(megaset.shape))\n","\n","\n","\n","# Training data structure\n","    # input_label,      0 \n","    # input_N,          1:1+v_dimC\n","    # input_N_dur,      1+v_dimC:1+v_dimC+1\n","    # input_C,          1+v_dimC+1:1+v_dimC+1+v_dimC\n","    # input_C_dur       1+v_dimC+1+v_dimC:1+v_dimC+1+v_dimC+1\n","    \n","x_labels = megaset[:,0]\n","x_norm = np.expand_dims(megaset[:,1:1+v_dimC], axis=2) \n","x_norm_dur = megaset[:,1+v_dimC:1+v_dimC+1] #np.expand_dims(, axis=2) \n","x_comp = np.expand_dims(megaset[:,1+v_dimC+1:1+v_dimC+1+v_dimC], axis=2) \n","x_comp_dur = megaset[:,1+v_dimC+1+v_dimC:1+v_dimC+1+v_dimC+1] #np.expand_dims(, axis=2) \n","\n","data_x = [x_norm, x_norm_dur, x_comp,x_comp_dur]\n","data_y = x_labels\n","\n","# Get Model #def model_01(print_summary, input_shape_N, fl_filters, nos_output):\n","model = model_01(True, (v_dimC,1), (v_dimC,1), 7, 2)\n","\n","# Start Training---------------------------------------------------------\n","timestamp_start = datetime.datetime.now()\n","\n","history = model.fit(\n","                    data_x, data_y,\n","                    batch_size=1000,\n","                    epochs=300,\n","                    callbacks=cb_listr,\n","                    #validation_data=([alle_m.reshape((elen,timesteps,1)),alle_t],alle_l),\n","                    shuffle=True,\n","                    verbose=1)\n","\n","timestamp_dur = datetime.datetime.now() - timestamp_start\n","print('Elapsed time = ' + str(timestamp_dur))\n","# End Training---------------------------------------------------------\n","\n","ff=0\n","plt.figure(ff)\n","ff+=1\n","plt.title('ACC: '+ds_name)\n","plt.plot(history.history['accuracy'],color='green')\n","plt.show()\n","\n","plt.figure(ff)\n","ff+=1\n","plt.title('LOSS: '+ds_name)\n","plt.plot(history.history['loss'],color='red')\n","plt.show()\n","\n","\n","# save this model\n","save_model_name = ds_model +'.h5'        # save model weights to this file\n","svmpth = os.path.join(global_modeldir, save_model_name)\n","model.save_weights(svmpth)\n","print('Saved Model Weights at : '+ str(svmpth))\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8C8ll-k7FPXK","colab_type":"text"},"source":["## [ 9.2_TESTING ]"]},{"cell_type":"code","metadata":{"id":"ALKb9XlJFVCz","colab_type":"code","colab":{}},"source":["# Testing\n","##<---------------------------------------------- \n","ds_name = 'custom_set_test_1_Class_N'    # SELECT DATASET FOR LOADING TESTING DATA FROM\n","ds_model = 'model_1'       # SELECT MODEL WEIGHTS TO TEST UPON\n","##<----------------------------------------------\n","\n","ds_path = os.path.join(ds_dir, ds_name+'.npy') \n","megaset = np.load(ds_path)    \n","print('Loaded data from '+ str(ds_path)+'\\nShape='+str(megaset.shape))\n","\n","# Testing data structure\n","    # input_label,      0 \n","    # input_N,          1:1+v_dimC\n","    # input_N_dur,      1+v_dimC:1+v_dimC+1\n","    # input_C,          1+v_dimC+1:1+v_dimC+1+v_dimC\n","    # input_C_dur       1+v_dimC+1+v_dimC:1+v_dimC+1+v_dimC+1\n","    \n","x_labels = megaset[:,0]\n","x_norm = np.expand_dims(megaset[:,1:1+v_dimC], axis=2) \n","x_norm_dur = megaset[:,1+v_dimC:1+v_dimC+1] #np.expand_dims(, axis=2) \n","x_comp = np.expand_dims(megaset[:,1+v_dimC+1:1+v_dimC+1+v_dimC], axis=2) \n","x_comp_dur = megaset[:,1+v_dimC+1+v_dimC:1+v_dimC+1+v_dimC+1] #np.expand_dims(, axis=2) \n","\n","data_x = [x_norm, x_norm_dur, x_comp,x_comp_dur]\n","data_y = x_labels\n","\n","# Get Model #def model_01(print_summary, input_shape_N, fl_filters, nos_output):\n","model = model_01(False, (v_dimC,1), (v_dimC,1), 7, 2)\n","load_model_name = ds_model+ '.h5'     # model used for testing\n","load_model_path = os.path.join(global_modeldir, load_model_name)\n","model.load_weights(load_model_path)\n","print('Loaded Model weights '+ str(load_model_path))\n","#-------------------------------------------------------------------------------------------------------\n","# #evla = model.evaluate( data_x, data_y ) data_med med_rep\n","# #print(evla)\n","#-------------------------------------------------------------------------------------------------------\n","\n","# manual prediction\n","print('Manual Prediction on : ' + ds_name)\n","predx = model.predict( data_x ) # array of  samples x classes(4) - each row is a prediction of sample\n","cmx_global = np.zeros((len(g_LABELS),len(g_LABELS)),dtype='int32')\n","cmx2_global = predx.argmax(axis=1)\n","for i in range(0,len(cmx2_global)):\n","    alabel = int(data_y[i])\n","    plabel = cmx2_global[i]\n","    cmx_global[alabel,plabel]+=1\n","print('\\tConfusion Matrix')\n","print(print_conf_matrix( cmx_global,'', g_LABELS)) #logit('\\t'+str(cmx))\n","print_performance( get_performance(cmx_global) ,g_LABELS ) \n","#------------------------------------------------------------"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nqqVTqwK3v74","colab_type":"text"},"source":["## [ 9.3_RECORD_TESTING ]"]},{"cell_type":"code","metadata":{"id":"BNhE5W4W5xAb","colab_type":"code","colab":{}},"source":["test_db = all_db        #<<---- db dict to read ecg data\n","\n","idb = 'incartdb'           #<<---- ecg_db\n","irec = 'I42'            #<<---- ecg_record\n","\n","sel_db = test_db[idb]\n","sel_rec = sel_db.get_record(irec)\n","\n","# load beat info\n","sbi = sel_rec.read_binfo()\n","print('Total beats = '+str(sbi.nos_rr_peaks))\n","\n","# load signal\n","sel_sig = sel_rec.read_data(g_SIG_II_POSTFIX)\n","if len(sel_sig)<1:\n","    print('Signal cannot be loaded')\n","else:\n","    print('Signal loaded succesfully')\n","\n","#<<---------------------------------- Select save name of this dataset\n","ds_name = 'rec_test_'+idb+'_'+irec\n","ds_path = os.path.join(ds_dir, ds_name+'.npy') "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nJY18S_K7esh","colab_type":"text"},"source":["### [ 9.3.1_Compile_Test_Set ]"]},{"cell_type":"code","metadata":{"id":"VtWdu0BT31K0","colab_type":"code","colab":{}},"source":["\n","#<<---------------------------------- Select which representative normal to use\n","g_REP_NORM_POSTFIX = 'REP_300'\n","lim_min_rep_norms = 1\n","\n","\n","timestamp_start = datetime.datetime.now()\n","print('db_rec\\t#beats\\t#r\\t#stacked')\n","\n","rst=sel_rec.name+'\\t'\n","if len(sel_sig)<1:\n","    rst+=' >>Signal cannot be loaded\\t'\n","    print(rst)\n","else:\n","    rst+=str(sbi.nos_rr_peaks)+'\\t'\n","\n","    # first laod representative normal file\n","    npy_rep = sel_rec.read_data(g_REP_NORM_POSTFIX)\n","    nos_rep = len(npy_rep)\n","\n","    # check if enough normal episodes\n","    if nos_rep<lim_min_rep_norms:\n","        rst+=' >> Not enough Representative Normals\\t'\n","        print(rst)\n","    else:\n","        rst+=str(nos_rep)+'\\t'\n","\n","        all_beats = np.zeros((0,1+v_dimC+1))\n","        for ibeat in range(0,sbi.nos_rr_peaks):\n","            sg,pk = sbi.get_signal_data_var(ibeat)\n","            #============================================================\n","            #print('\\tbeat# '+str(ibeat) + '\\tLabel='+sbi.rr_labels[ibeat]+ '\\tTS='+str(round(sbi.rr_peaks_sec[ibeat],2))+'\\tDUR='+str(sbi.rri_dur[ibeat]))\n","            #============================================================\n","            sg_resamp = scsig.resample(sg,v_dimC)\n","            #pk_resamp = round(pk*( len(sg_resamp)/(len(sg) ))) #<<------ peak value not required now\n","            beat_duration = sbi.rri_dur[ibeat]\n","            beat_label = sbi.rr_int_labels[ibeat]\n","\n","            #beat_index = ibeat              #<<----- for identifying beat later on <<--- NO NEED FOR THIS\n","\n","            a_resamp = np.hstack((beat_label,beat_duration,sg_resamp)) \n","            all_beats = np.vstack((all_beats, a_resamp)) # done now save it   \n","\n","\n","        sel_replace = False\n","        if nos_rep<len(all_beats):\n","            sel_replace=True\n","\n","        a = np.arange(0,nos_rep) \n","        npy_rep_sel = npy_rep[np.random.choice( a, size=len(all_beats), replace=sel_replace, p=None )]\n","\n","        rec_input = np.zeros((0,1+v_dimC+1+v_dimC+1))\n","        for rs in range(0,len(all_beats)): \n","            \n","            rr = npy_rep_sel[rs]\n","            ss = all_beats[rs]\n","            # NOTE:beat_identifier has been stacked at the begin, shift index in ss by +1 <<--- NO NEED FOR THIS\n","\n","            #input_N = rr[4:4+v_dimC]  #<<------- mean representaion\n","            input_N = rr[-v_dimC:]  #<<------- median representaion\n","            \n","            #input_N_dur = rr[1]/BASIC_SRATE  #<<----------- max_duration of episode\n","            input_N_dur = rr[2]  #<<----------- avg_duration of episode\n","\n","            input_label = ss[0] #<<----- label\n","            \n","            input_C = ss[-v_dimC:] #<<----- resampled signal\n","            \n","            input_C_dur = ss[1] #<<----- orginal duration of beat in seconds\n","            \n","            #input_beat_id = ss[0]   #<<----------- identifier for beat in binfo class <<-- NO NEED FOR THIS\n","            \n","            final_input = np.hstack((\n","                                    input_label,\n","                                    input_N,\n","                                    input_N_dur,\n","                                    input_C,\n","                                    input_C_dur,\n","                                    #input_beat_id  # <<-- NO NEED FOR THIS\n","                                    ))\n","            \n","            rec_input = np.vstack((rec_input,final_input))\n","\n","        rst+=str(len(rec_input))\n","        print(rst)\n","        \n","\n","        np.save(ds_path,rec_input)\n","        print('saved at '+ str(ds_path))\n","        print('Done! Final Input shape:'+ str(rec_input.shape))\n","\n","timestamp_dur = datetime.datetime.now() - timestamp_start\n","print('Elapsed time = ' + str(timestamp_dur))\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"za_5p0jY-AGy","colab_type":"text"},"source":["### [ 9.4.2_Test_Record ]"]},{"cell_type":"code","metadata":{"id":"yTVNzK1m-FD6","colab_type":"code","colab":{}},"source":["# Testing\n","##<---------------------------------------------- \n","ds_model = 'model_1'       # SELECT MODEL WEIGHTS TO TEST UPON\n","##<----------------------------------------------\n","\n","megaset = np.load(ds_path)    \n","print('Loaded data from '+ str(ds_path)+'\\nShape='+str(megaset.shape))\n","\n","# Testing data structure\n","    # input_label,      0 \n","    # input_N,          1:1+v_dimC\n","    # input_N_dur,      1+v_dimC:1+v_dimC+1\n","    # input_C,          1+v_dimC+1:1+v_dimC+1+v_dimC\n","    # input_C_dur       1+v_dimC+1+v_dimC:1+v_dimC+1+v_dimC+1\n","    \n","x_labels = megaset[:,0]\n","x_norm = np.expand_dims(megaset[:,1:1+v_dimC], axis=2) \n","x_norm_dur = megaset[:,1+v_dimC:1+v_dimC+1] #np.expand_dims(, axis=2) \n","x_comp = np.expand_dims(megaset[:,1+v_dimC+1:1+v_dimC+1+v_dimC], axis=2) \n","x_comp_dur = megaset[:,1+v_dimC+1+v_dimC:1+v_dimC+1+v_dimC+1] #np.expand_dims(, axis=2) \n","\n","data_x = [x_norm, x_norm_dur, x_comp,x_comp_dur]\n","data_y = x_labels\n","\n","# Get Model #def model_01(print_summary, input_shape_N, fl_filters, nos_output):\n","model = model_01(False, (v_dimC,1), (v_dimC,1), 7, 2)\n","load_model_name = ds_model+ '.h5'     # model used for testing\n","load_model_path = os.path.join(global_modeldir, load_model_name)\n","model.load_weights(load_model_path)\n","print('Loaded Model weights '+ str(load_model_path))\n","#-------------------------------------------------------------------------------------------------------\n","# #evla = model.evaluate( data_x, data_y ) data_med med_rep\n","# #print(evla)\n","#-------------------------------------------------------------------------------------------------------\n","\n","# manual prediction\n","print('Manual Prediction on : ' + ds_name)\n","predx = model.predict( data_x ) # array of  samples x classes(4) - each row is a prediction of sample\n","cmx_global = np.zeros((len(g_LABELS),len(g_LABELS)),dtype='int32')\n","cmx2_global = predx.argmax(axis=1)\n","for i in range(0,len(cmx2_global)):\n","    alabel = int(data_y[i])\n","    plabel = cmx2_global[i]\n","    cmx_global[alabel,plabel]+=1\n","print('\\tConfusion Matrix')\n","print(print_conf_matrix( cmx_global,'', g_LABELS)) #logit('\\t'+str(cmx))\n","print_performance( get_performance(cmx_global) ,g_LABELS ) \n","#------------------------------------------------------------\n","\n","cmx_false_N = np.zeros(len(cmx2_global))\n","cmx_false_N[np.where(\n","                    (cmx2_global==0) &      #<<--- predicted Normal\n","                    (data_y==1)           #<<--- actually Abnormal\n","                    )[0]]=-1\n","\n","cmx_false_A = np.zeros(len(cmx2_global))\n","cmx_false_A[np.where(\n","                    (cmx2_global==1)   &    #<<--- predicted abnorm\n","                    (data_y==0)           #<<--- actually norm\n","                    )[0]]=-1\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vcMPde5K-3nr","colab_type":"text"},"source":["### [ 9.4.3_Plot_Test_Results ]"]},{"cell_type":"code","metadata":{"id":"Xb43sUjE-2xm","colab_type":"code","colab":{}},"source":["# plot signal segments\n","\n","#<<---------------------------------------------Select Paper Resolution\n","x_scale = 25 * 0.0393701 # mm/sec -> inches/sec\n","y_scale = 10 * 0.0393701 # mm/mV -> inches/sec\n","y_low = -2.5\n","y_high = 3.5\n","#<<--------------------------------------------------------------------\n","\n","#<<---------------------------------------------Select ECG Segment\n","fsec = 10\n","tsec = fsec+(90)\n","dsec = tsec - fsec\n","#<<--------------------------------------------------------------------\n","\n","\n","ff = fsec * BASIC_SRATE\n","tt = tsec * BASIC_SRATE\n","dd = tt - ff\n","\n","bps = sel_sig[ff:tt]\n","\n","dticks = sbi.rr_peaks[(sbi.rr_peaks_sec >= fsec) & (sbi.rr_peaks_sec < tsec)]\n","dlabels = sbi.rr_labels[(sbi.rr_peaks_sec >= fsec) & (sbi.rr_peaks_sec < tsec)]\n","dticks = (dticks / sel_rec.db.srate)*BASIC_SRATE - ff\n","\n","plt.figure(2, figsize = (dsec*x_scale ,(y_high-y_low) * y_scale) )\n","plt.xlim(0, len(bps))\n","plt.ylim(y_low,y_high)\n","plt.xticks(dticks,dlabels)\n","#x_grid = np.arange(0,tt-ff, 1*BASIC_SRATE)\n","#plt.xticks(x_grid)\n","plt.grid(axis='x')\n","\n","#drris = sbi.rri_delta[(sbi.rr_peaks_sec >= fsec) & (sbi.rr_peaks_sec < tsec)]\n","#drrid = sbi.rri_dur[(sbi.rr_peaks_sec >= fsec) & (sbi.rr_peaks_sec < tsec)]\n","# RED: rri_delta\n","#plt.scatter(dticks,drris, marker='s',color='tab:red')\n","# GREEN = Duration\n","#plt.scatter(dticks,drrid, marker='s',color='tab:green')\n","\n","dcmx2 = cmx2_global[(sbi.rr_peaks_sec >= fsec) & (sbi.rr_peaks_sec < tsec)] \n","dfalseN = cmx_false_N[(sbi.rr_peaks_sec >= fsec) & (sbi.rr_peaks_sec < tsec)] \n","dfalseA = cmx_false_A[(sbi.rr_peaks_sec >= fsec) & (sbi.rr_peaks_sec < tsec)] \n","# RED: Abnormal\n","plt.scatter(dticks[dcmx2==1],dcmx2[dcmx2==1], marker='s',color='tab:red')\n","# GREEN: Normal\n","plt.scatter(dticks[dcmx2==0],dcmx2[dcmx2==0], marker='s',color='tab:green')\n","\n","# falsely prdicted as Normals, actually abnormal\n","plt.scatter(dticks[dfalseN==-1],dfalseN[dfalseN==-1], marker='x',color='tab:red')\n","\n","# falsely predicted as Abnormals, actually normal\n","plt.scatter(dticks[dfalseA==-1],dfalseA[dfalseA==-1], marker='x',color='tab:green')\n","\n","plt.plot(bps, linewidth=0.5, color='black')\n","plt.hlines(0,0,len(bps), linewidth=0.3)\n"],"execution_count":0,"outputs":[]}]}