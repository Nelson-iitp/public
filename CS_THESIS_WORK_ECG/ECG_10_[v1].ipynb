{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ECG_10_[v1].ipynb","provenance":[{"file_id":"1YoaR25AQ3b2NWVxpSAgD2oE31bVz8Gfn","timestamp":1590386079723},{"file_id":"1J5cuzyRx4ipySODOz_-7RhQ349UiFajE","timestamp":1590384321091}],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"17hcHJJJD2kA3SKzpdwIDd4vMXti7gfIu","authorship_tag":"ABX9TyMKgdTNGzfMrXChWRAeOviW"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"R0KnOnj24WK8","colab_type":"code","colab":{}},"source":["%reset"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AmAt0eBV4uXG","colab_type":"text"},"source":["# [ IMPORTS ]"]},{"cell_type":"code","metadata":{"id":"xfdnlj8y41qm","colab_type":"code","colab":{}},"source":["import datetime\n","import os\n","import random\n","import statistics as stats\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","import scipy.signal as scsig"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jMKA499Q4_0r","colab_type":"text"},"source":["# [ GLOBAL ]"]},{"cell_type":"code","metadata":{"id":"hpb-HZz75Dsp","colab_type":"code","outputId":"f9848d94-0840-46ef-9221-b648a6f81739","executionInfo":{"status":"ok","timestamp":1590738125754,"user_tz":-330,"elapsed":2728,"user":{"displayName":"Nelson Sharma","photoUrl":"","userId":"05205859662695765719"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["#===========================================================================================================\n","# DEFINE SOURCE DIRECTORIES\n","#===========================================================================================================\n","# > _ base working directory\n","global_dir = '/content/drive/My Drive/Masters/workdir/ecg_data' #'/home/spooky/ecg/workdir'\n","print('GLOBAL DIR :: '+global_dir)\n","\n","#===========================================================================================================\n","#  following are required for one time npy database building\n","\n","# >> global MAT directory, contains signal data in matlab (.mat) format\n","global_matdir = os.path.join(global_dir, 'db_mat') \n","print('GLOBAL MAT DIR :: '+global_matdir)\n","\n","# >> global NPY directory, contains signal and meta data in numpy (.npy) format\n","global_npydir = os.path.join(global_dir, 'db_npy') \n","print('GLOBAL NPY DIR :: '+global_npydir)\n","\n","# beat and non-beat annotations, signal data types to be used to save data in npy format\n","g_BEAT_POSTFIX = 'BEAT'         #<<--- beat annotations\n","g_NBEAT_POSTFIX = 'NBEAT'       #<<--- non-beat annotations\n","g_RAW_II_POSTFIX = 'RAW_II'     #<<--- Raw lead2 signal from mat file\n","g_BLF_II_POSTFIX = 'BLF_II'     #<<--- Baseline fitted signal\n","g_RES_II_POSTFIX = 'RES_II'     #<<--- Resampled to BASIC_SRATE\n","g_SIG_II_POSTFIX = 'SIG_II'     #<<--- Removed manual gain\n","#===========================================================================================================\n","\n","#=================================================\n","# Auto-Create other working directory\n","#=================================================\n","# >> model directory, contains model weights, use load_weights(), save_weights() \n","global_modeldir = os.path.join(global_dir, 'db_model')\n","print('GLOBAL MODEL DIR :: ' + global_modeldir)\n","\n","# >> dataset directory, contains manually generated datasets to be used for experiment\n","global_dsdir = os.path.join(global_dir, 'db_dataset') \n","print('GLOBAL DATASET DIR :: ' + global_dsdir)\n","\n","# >> temp directory, contains manually generated temporary data to be used for experiments\n","global_tempdir = os.path.join(global_dir, 'db_temp') \n","print('GLOBAL TEMP DIR :: ' + global_tempdir)\n","#>>----------------------------------------------- \n","\n","# >> annotation directory, contains annotation mapping files to be used for experiments\n","global_antdir = os.path.join(global_dir, 'db_ant') \n","print('GLOBAL ANNOTATION DIR :: ' + global_antdir)\n","#>>----------------------------------------------- \n","\n","# Resample every signal to this rate for consistency\n","BASIC_SRATE = 128 #Hz\n","print('Basic sampling rate(Hz): '+str(BASIC_SRATE))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["GLOBAL DIR :: /content/drive/My Drive/Masters/workdir/ecg_data\n","GLOBAL MAT DIR :: /content/drive/My Drive/Masters/workdir/ecg_data/db_mat\n","GLOBAL NPY DIR :: /content/drive/My Drive/Masters/workdir/ecg_data/db_npy\n","GLOBAL MODEL DIR :: /content/drive/My Drive/Masters/workdir/ecg_data/db_model\n","GLOBAL DATASET DIR :: /content/drive/My Drive/Masters/workdir/ecg_data/db_dataset\n","GLOBAL TEMP DIR :: /content/drive/My Drive/Masters/workdir/ecg_data/db_temp\n","GLOBAL ANNOTATION DIR :: /content/drive/My Drive/Masters/workdir/ecg_data/db_ant\n","Basic sampling rate(Hz): 128\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yMig0xnIpKRk","colab_type":"text"},"source":["# [ EXPERIMENT_SETUP ]"]},{"cell_type":"markdown","metadata":{"id":"jIoB363Xf1nA","colab_type":"text"},"source":["## [ Experiment params ]"]},{"cell_type":"code","metadata":{"id":"hAIO9z1upIiq","colab_type":"code","outputId":"3fc84445-50b2-4ce2-d282-9404d023b4a6","executionInfo":{"status":"ok","timestamp":1590738143331,"user_tz":-330,"elapsed":2694,"user":{"displayName":"Nelson Sharma","photoUrl":"","userId":"05205859662695765719"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["#*************************************************\n","# Define Experiment Secific Param\n","#*************************************************\n","exp_name = 'exp_V_clf'\n","print('Experiment::',exp_name)\n","#>>---------------------------------------------- \n","\n","#=================================================\n","# Signal Sampling Params\n","#=================================================\n","# fixed input dimension for beat vector\n","v_dimC = int(round((3*BASIC_SRATE))) # 3 seconds\n","print('Fixed dimension of beat vector: '+str(v_dimC))\n","#>>-----------------------------------------------\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Experiment:: exp_V_clf\n","Fixed dimension of beat vector: 384\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pYFUnLwrgJgV","colab_type":"text"},"source":["# [ SELECT ANT MAPPER ] "]},{"cell_type":"code","metadata":{"id":"SCCy-YHFgS7c","colab_type":"code","outputId":"5818cdb0-86bf-4e70-d4af-b526baf655b0","executionInfo":{"status":"ok","timestamp":1590738149474,"user_tz":-330,"elapsed":1747,"user":{"displayName":"Nelson Sharma","photoUrl":"","userId":"05205859662695765719"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["ls_ants = os.listdir(global_antdir)\n","print('Available annotation files ['+str(len(ls_ants))+']')\n","for ls_ant in ls_ants:\n","    print(ls_ant)\n","print('--------------------------')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Available annotation files [2]\n","ant_V_clf.txt\n","annotations_basic.txt\n","--------------------------\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lM_1dfQ_g6w2","colab_type":"text"},"source":["## [ *mapping_file* ]"]},{"cell_type":"code","metadata":{"id":"uoCBtyvagNqr","colab_type":"code","outputId":"cf528bc6-bd59-4030-e7de-0b7666f903a9","executionInfo":{"status":"ok","timestamp":1590738222071,"user_tz":-330,"elapsed":4116,"user":{"displayName":"Nelson Sharma","photoUrl":"","userId":"05205859662695765719"}},"colab":{"base_uri":"https://localhost:8080/","height":819}},"source":["#=================================================\n","# Read annotation mapping from file\n","#=================================================\n","ant_file = 'ant_V_clf' + '.txt'\n","\n","exp_annot = os.path.join(global_antdir, ant_file) \n","print('ANNOTATIONS FILE :: '+ exp_annot)\n","g_map_data = np.loadtxt(exp_annot, dtype='str',delimiter=\"\\t\")\n","g_map={}\n","print('ANNOTATION MAPPING :: ')\n","for a in g_map_data:\n","    g_mit_label = a[0] # orignal mit label (char)\n","    g_int_label = a[1] # mapped integer label (int)\n","    g_beat_description = a[2] # description (str)\n","    g_map[g_mit_label]= int(g_int_label) ##<<----------------mapping dictionary\n","    print(g_mit_label+'\\t'+g_int_label+'\\t'+g_beat_description)\n","def mapstd(peak_label):\n","    res = np.zeros(len(peak_label),dtype='int')\n","    for i in range(0, len(peak_label)):\n","        res[i] = g_map[peak_label[i]]\n","    return res\n","print('')\n","print('All Annotations : [' + str(len(g_map))+'] :: ' + str(g_map.keys()))\n","print('')\n","\n","#>>-----------------------------------------------\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["ANNOTATIONS FILE :: /content/drive/My Drive/Masters/workdir/ecg_data/db_ant/ant_V_clf.txt\n","ANNOTATION MAPPING :: \n","N\t0\tNormal beat\n","L\t-1\tLeft bundle branch block beat\n","R\t-1\tRight bundle branch block beat\n","B\t-1\tBundle branch block beat (unspecified)\n","A\t-1\tAtrial premature beat\n","a\t-1\tAberrated atrial premature beat\n","J\t-1\tNodal (junctional) premature beat\n","S\t-1\tSupraventricular premature or ectopic beat (atrial or nodal)\n","V\t1\tPremature ventricular contraction\n","r\t-1\tR-on-T premature ventricular contraction\n","F\t-1\tFusion of ventricular and normal beat\n","e\t-1\tAtrial escape beat\n","j\t-1\tNodal (junctional) escape beat\n","n\t-1\tSupraventricular escape beat (atrial or nodal)\n","E\t-1\tVentricular escape beat\n","/\t-1\tPaced beat\n","f\t-1\tFusion of paced and normal beat\n","Q\t-1\tUnclassifiable \n","?\t-1\tBeat not classified during learning\n","[\t-2\tStart of ventricular flutter/fibrillation\n","!\t-2\tVentricular flutter wave\n","]\t-2\tEnd of ventricular flutter/fibrillation\n","x\t-2\tNon-conducted P-wave (blocked APC)\n","(\t-2\tWaveform onset\n",")\t-2\tWaveform end\n","p\t-2\tPeak of P-wave\n","t\t-2\tPeak of T-wave\n","u\t-2\tPeak of U-wave\n","`\t-2\tPQ junction\n","'\t-2\tJ-point\n","^\t-2\t(Non-captured) pacemaker artifact\n","|\t-2\tIsolated QRS-like artifact [1]\n","~\t-2\tChange in signal quality [1]\n","+\t-2\tRhythm change [2]\n","s\t-2\tST segment change [2]\n","T\t-2\tT-wave change [2]\n","*\t-2\tSystole\n","D\t-2\tDiastole\n","=\t-2\tMeasurement annotation [2]\n","\"\t-2\tComment annotation [2]\n","@\t-2\tLink to external data [3]\n","\n","All Annotations : [41] :: dict_keys(['N', 'L', 'R', 'B', 'A', 'a', 'J', 'S', 'V', 'r', 'F', 'e', 'j', 'n', 'E', '/', 'f', 'Q', '?', '[', '!', ']', 'x', '(', ')', 'p', 't', 'u', '`', \"'\", '^', '|', '~', '+', 's', 'T', '*', 'D', '=', '\"', '@'])\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Z08zIjW7hDUK","colab_type":"text"},"source":["## [ *mapping_labels* ]"]},{"cell_type":"code","metadata":{"id":"5j1QJJybhK9Y","colab_type":"code","outputId":"fed852d9-f282-4961-a021-b6d702130b44","executionInfo":{"status":"ok","timestamp":1590738247343,"user_tz":-330,"elapsed":1612,"user":{"displayName":"Nelson Sharma","photoUrl":"","userId":"05205859662695765719"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#=================================================\n","# Define Custom Class Labels, as per mapped indices\n","#=================================================\n","g_LABELS_MAP = np.array([\n","            ['N','tab:green'],      # Normal\n","            ['V','tab:blue'],      # VEB\n","            ])  #<<--- integer label have one to one correspondence with incides in g_LABELS\n","\n","g_LABELS = g_LABELS_MAP[:,0]\n","g_COLOR = g_LABELS_MAP[:,1]\n","# T10 categorical palette\n","# ['tab:blue', 'tab:orange', 'tab:green', 'tab:red',\n","# 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', \n","# 'tab:olive', 'tab:cyan']\n","print('CLASS LABELS : ', g_LABELS)\n","#>>-----------------------------------------------"],"execution_count":0,"outputs":[{"output_type":"stream","text":["CLASS LABELS :  ['N' 'V']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"t4j5Acg_57cl","colab_type":"text"},"source":["# [ CLASS_DEFS ]"]},{"cell_type":"code","metadata":{"id":"lgUkvPIQ6AKA","colab_type":"code","colab":{}},"source":["#Class Definitions\n","#---------------------------------------------------------------------------------------------------------------------------------------------\n","# CLASS ecg_db : represents one ECG database\n","#---------------------------------------------------------------------------------------------------------------------------------------------\n","class ecg_db:\n","    def __init__(self, dbname,  exclude_recs, tag_recs, sampling_rate):\n","        print('\\nInitailze new ecg database ... ')\n","        self.name = dbname  #str\n","        self.srate = sampling_rate #float or int\n","        self.dir_npy = os.path.join(global_npydir , dbname+'_npy') #str\n","        self.recs_all = set(np.loadtxt(os.path.join(self.dir_npy,'RECORDS'), dtype='str',delimiter=\"\\n\")) #set\n","        self.recs_exc = set(exclude_recs)\n","        self.recs = set.difference(self.recs_all, self.recs_exc) \n","        self.recs_tag = set(tag_recs)\n","        self.recs_dict = {} # initially empty, will be loaded on demand using function 'get_record'\n","        self.info()\n","\n","    def info(self):\n","        print( 'DB NAME :: '+ self.name)\n","        print( 'SAMPLING RATE :: '+ str(self.srate))\n","        print( 'DATA DIR :: ' + self.dir_npy )\n","        print( 'RECORD SET :: [' +str(len(self.recs))+'] ' + str(self.recs) )\n","        return 0\n","\n","    def get_record(self,rec):\n","        if not (rec in self.recs_dict.keys()):\n","            self.recs_dict[rec] = ecg_record(self,rec)\n","        return self.recs_dict[rec]\n","    \n","    def get_random_record(self, recset):\n","        rec = random.choice(list(recset))\n","        if not (rec in self.recs_dict.keys()):\n","            self.recs_dict[rec] = ecg_record(self,rec)\n","        return self.recs_dict[rec]\n","\n","#---------------------------------------------------------------------------------------------------------------------------------------------\n","\n","#---------------------------------------------------------------------------------------------------------------------------------------------\n","# CLASS ecg_record : represents one ECG Record in any database\n","#---------------------------------------------------------------------------------------------------------------------------------------------\n","g_SUPRESS_DATA_WARNING=False\n","class ecg_record:\n","\n","    def __init__(self, db, recname):\n","        self.db = db                                # class:{ecg_db}    object this record belongs to\n","        self.rec = recname                          # string            name of this record\n","        self.name = db.name + '_'+ recname          # string            full name including db.name\n","        if recname in db.recs_all:\n","            if recname in db.recs_exc:\n","                print('WARNING:: Record \"'+ recname +'\" is marked excluded from database '+ db.name )\n","        else:\n","            print('WARNING:: Record \"'+ recname +'\" not found in database '+ db.name )\n","        self.data_npy = {}                          # dict dict of data file content used in self.read_data_npy('key')\n","        self.data_temp = {}                          # dict dict of data file content used in self.read_data_temp('key')\n","        self.binfo = None                           # class binfo       \n","\n","##<------------------------------------------------- get instance of binfo class\n","    def read_binfo(self):\n","        if self.binfo == None:\n","            self.binfo = ecg_binfo(self)\n","        return self.binfo\n","\n","    def refresh_binfo(self):\n","        self.binfo = ecg_binfo(self)\n","        return self.binfo\n","\n","##<------------------------------------------------- data reading for npydir\n","    def load_data(self, data_type):\n","        ipath = os.path.join(self.db.dir_npy, self.rec + '_'+data_type+'.npy')\n","        try: # try to load this data\n","            self.data_npy[data_type] = np.load(ipath) # adds this to dictionary so next time it can read\n","            return self.data_npy[data_type] #= np.load(self.dirs[s])\n","        except:\n","            if g_SUPRESS_DATA_WARNING == False:\n","                print('WARNING:: Cant load \"'+data_type+ '\" file at '+ str(ipath) )\n","            return np.array([])\n","        \n","    def read_data(self, data_type):\n","        if data_type in self.data_npy.keys():\n","            return self.data_npy[data_type] #= np.load(self.dirs[s])\n","        else:\n","            return self.load_data(data_type)\n","\n","##<------------------------------------------------- for tempdir\n","    def load_data_temp(self, data_type, dir_path):\n","        ipath = os.path.join(dir_path, self.rec + '_'+data_type+'.npy')\n","        try: # try to load this data\n","            self.data_temp[data_type] = np.load(ipath) # adds this to dictionary so next time it can read\n","            return self.data_temp[data_type] #= np.load(self.dirs[s])\n","        except:\n","            if g_SUPRESS_DATA_WARNING == False:\n","                print('WARNING:: Cant load \"'+data_type+ '\" file at '+ str(ipath) )\n","            return np.array([])\n","        \n","    def read_data_temp(self, data_type, dir_path):\n","        if data_type in self.data_temp.keys():\n","            return self.data_temp[data_type] #= np.load(self.dirs[s])\n","        else:\n","            return self.load_data_temp(data_type, dir_path)\n","\n","    def save_data_temp(self, data_type, data_array, dir_path):\n","        ipath = os.path.join(dir_path, self.rec + '_'+data_type+'.npy')\n","        np.save(ipath, data_array)\n","        return ipath\n","\n","    def del_data_temp(self, data_type, dir_path, vb):\n","        ipath = os.path.join(dir_path, self.rec + '_'+data_type+'.npy')\n","        if os.path.exists(ipath):\n","            if vb:\n","                print('Removing: '+str(ipath))\n","            os.remove(ipath)\n","            return 1\n","        else:\n","            return 0\n","#------------------------------------------------------------------------------------------------\n","\n","class ecg_binfo:\n","    def __init__(self, rec):\n","        self.rec = rec          # the record object\n","        rr_peaks_ants = rec.read_data(g_BEAT_POSTFIX)       # orignal ant file [ *  '625310' 'N' * ]\n","        # slice array\n","        rr_peaks_int = rr_peaks_ants[:,0].astype('int')     # col0 : samples * 62531 *  <---------------- not excluded\n","        rr_ants_str = rr_peaks_ants[:,1]                    # col1 : labels * 'N' *     <---------------- not excluded\n","        \n","        # excluded first and last\n","        self.rr_peaks = rr_peaks_int[1:-1]                  # col0 : samples (int) 62531 ==>==>==> sample# (orignal)\n","        self.rr_prev = rr_peaks_int[0:-2]                   # prev R peak (in samples)\n","        self.rr_next = rr_peaks_int[2:]                                           # next R peak (in samples)\n","        self.nos_rr_peaks = len(self.rr_peaks)              # no fo RR peaks (excluding first and last)\n","        \n","        self.rr_labels = rr_ants_str[1:-1]                  # col1 : labels (str)  'N'  ==>==>==> mit label (orignal)\n","        self.rr_plabels = rr_ants_str[0:-2]                  # col1 : labels (str)  'N'  ==>==>==> mit label (orignal)\n","        self.rr_nlabels = rr_ants_str[2:]                  # col1 : labels (str)  'N'  ==>==>==> mit label (orignal)\n","\n","        rr_ants_int = mapstd(rr_ants_str)\n","        self.rr_int_labels = rr_ants_int[1:-1]         # col1 : mapped int labels ==>==>==> int label (mapped -1, 0 ...) cant be -2 in \n","        self.rr_int_plabels = rr_ants_int[0:-2]   \n","        self.rr_int_nlabels = rr_ants_int[2:]   \n","\n","        #temporal info\n","        self.rr_peaks_sec = self.rr_peaks / rec.db.srate             # col0 : time in sec (float) ==>==>==> sample (time in sec) sample#/srate\n","        self.rri_prev = (self.rr_peaks - self.rr_prev) / rec.db.srate   # prev RRI (in sec) \n","        self.rri_next = (self.rr_next - self.rr_peaks) / rec.db.srate  # next RRI (in sec) \n","        self.rri_delta = (self.rri_next - self.rri_prev)        # difference b/w prev and next RRI in seconds \n","        self.rri_dur = (self.rri_next + self.rri_prev)\n","        self.sr_ratio = BASIC_SRATE/self.rec.db.srate\n","\n","    def get_signal_data_var(self, ith_peak): # data_type = g_SIG_II_POSTFIX\n","    # prev peak to next peak\n","        sel_sig = self.rec.read_data(g_SIG_II_POSTFIX) \n","        ff = int(self.rr_prev[ith_peak]*self.sr_ratio)\n","        tt = int(self.rr_next[ith_peak]*self.sr_ratio)\n","        pp = int(self.rr_peaks[ith_peak]*self.sr_ratio)\n","        return sel_sig[ff:tt+1], (pp-ff) #<- also return position of peak\n","    \n","    def get_signal_data_fix(self, ith_peak, v_left_sec, v_right_sec): # data_type = g_SIG_II_POSTFIX\n","        sel_sig = self.rec.read_data(g_SIG_II_POSTFIX) \n","        #sr_ratio = BASIC_SRATE/self.rec.db.srate\n","        ff = int((self.rr_peaks[ith_peak]*self.sr_ratio)-(v_left_sec*BASIC_SRATE))\n","        tt = int((self.rr_peaks[ith_peak]*self.sr_ratio)+(v_right_sec*BASIC_SRATE))\n","        pp = int(self.rr_peaks[ith_peak]*self.sr_ratio)\n","        return sel_sig[ff:tt+1], (pp-ff) #<- also return position of peak\n","    \n","#-----------------------------------------------------------------------------------------------\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nda73nsb6MEs","colab_type":"text"},"source":["# [ BUILD_ALL_DB ]"]},{"cell_type":"code","metadata":{"id":"N4Ng7DvJ6QvJ","colab_type":"code","colab":{}},"source":["print('Buidling all_db')\n","all_db = {}\n","#------------------------------------------------------------------------\n","mitdb_ex = []\n","mitdb_tags = []\n","all_db['mitdb'] = ecg_db('mitdb',  mitdb_ex, mitdb_tags, 360)\n","#------------------------------------------------------------------------\n","svdb_ex = []\n","svdb_tags = []\n","all_db['svdb'] = ecg_db('svdb',  svdb_ex, svdb_tags, 128)\n","#------------------------------------------------------------------------\n","incartdb_ex = []\n","incartdb_tags = []\n","all_db['incartdb'] = ecg_db('incartdb', incartdb_ex, incartdb_tags, 257)\n","#------------------------------------------------------------------------\n","print('')\n","print(all_db.keys())\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5XCa8-uR_aNY","colab_type":"text"},"source":["# [ 5_PREPARE_WORKING_DBs ]"]},{"cell_type":"code","metadata":{"id":"lV914CmU_ib6","colab_type":"code","outputId":"9f4237b6-782d-4de6-efd7-e6d1fda9c682","executionInfo":{"status":"ok","timestamp":1590738355210,"user_tz":-330,"elapsed":10486,"user":{"displayName":"Nelson Sharma","photoUrl":"","userId":"05205859662695765719"}},"colab":{"base_uri":"https://localhost:8080/","height":411}},"source":["#-----------------------------------------------------------------------------------------\n","mitdb_ex = ['102', '104', '107', '217', ##<<- Paced reacord\n","            '212', '231',  '207',       ##<<- both L and R BBB\n","            '223',                      ##<<- only record with 16 'e' type beats\n","            '222','124', '201',         ##<<- removes most of 'j' type beats from mitdb\n","            '232',                      ##<<- poor representative normal\n","            '214', '118', '111', '109',         ##<<- removes all L and R type beats\n","            ]\n","\n","svdb_ex = [\n","        \n","            ] #<-- les than 10 nrep normals\n","\n","incartdb_ex = [\n","               'I09', 'I10', 'I11',         # patient 5 only patient in cartdb with 32 'n' type beats\n","               'I59', 'I60', 'I61',         # patient 26 - removes most of 'j' type beats from incartdb\n","               'I16', 'I17',                # patient 8 Transient ischemic attack - removes L and R type\n","                'I70', 'I71'                # patient 30 - both R and N\n","\n","                ]\n","\n","#-----------------------------------------------------------------------------------------\n","#-----------------------------------------------------------------------------------------\n","#<<--------------------- FOR TRAINING model_01\n","train_db1 = {} \n","train_db1['mitdb'] = ecg_db('mitdb',  mitdb_ex, [], 360)\n","train_db1['svdb'] = ecg_db('svdb',  svdb_ex, [], 128)\n","#train_db1['incartdb'] = ecg_db('incartdb', incartdb_ex, [], 257)\n","#------------------------------------------------------------------------\n","print('')\n","print(train_db1.keys())\n","\n","\n","#-----------------------------------------------------------------------------------------\n","#-----------------------------------------------------------------------------------------\n","#<<--------------------- FOR TESTING model_01\n","test_db1 = {} \n","#test_db1['mitdb'] = ecg_db('mitdb',  mitdb_ex, [], 360)\n","#test_db1['svdb'] = ecg_db('svdb',  svdb_ex, [], 128)\n","test_db1['incartdb'] = ecg_db('incartdb', incartdb_ex, [], 257)\n","#------------------------------------------------------------------------\n","print('')\n","print(test_db1.keys())\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","Initailze new ecg database ... \n","DB NAME :: mitdb\n","SAMPLING RATE :: 360\n","DATA DIR :: /content/drive/My Drive/Masters/workdir/ecg_data/db_npy/mitdb_npy\n","RECORD SET :: [32] {'116', '205', '215', '103', '203', '122', '209', '220', '221', '113', '202', '123', '119', '100', '234', '228', '233', '210', '208', '219', '108', '200', '213', '230', '112', '101', '105', '114', '121', '115', '117', '106'}\n","\n","Initailze new ecg database ... \n","DB NAME :: svdb\n","SAMPLING RATE :: 128\n","DATA DIR :: /content/drive/My Drive/Masters/workdir/ecg_data/db_npy/svdb_npy\n","RECORD SET :: [78] {'862', '875', '885', '846', '876', '877', '805', '873', '801', '853', '820', '847', '858', '882', '803', '886', '809', '845', '829', '859', '855', '844', '870', '850', '880', '893', '861', '804', '848', '865', '843', '856', '841', '888', '802', '849', '828', '812', '823', '821', '867', '887', '892', '852', '869', '811', '808', '810', '874', '864', '879', '822', '840', '863', '889', '884', '842', '854', '894', '872', '866', '890', '891', '851', '857', '878', '807', '826', '868', '825', '881', '824', '871', '860', '827', '800', '883', '806'}\n","\n","dict_keys(['mitdb', 'svdb'])\n","\n","Initailze new ecg database ... \n","DB NAME :: incartdb\n","SAMPLING RATE :: 257\n","DATA DIR :: /content/drive/My Drive/Masters/workdir/ecg_data/db_npy/incartdb_npy\n","RECORD SET :: [65] {'I49', 'I39', 'I54', 'I19', 'I56', 'I03', 'I30', 'I44', 'I73', 'I15', 'I05', 'I01', 'I22', 'I53', 'I67', 'I46', 'I25', 'I43', 'I33', 'I21', 'I37', 'I42', 'I14', 'I48', 'I66', 'I24', 'I64', 'I69', 'I51', 'I26', 'I47', 'I36', 'I18', 'I32', 'I38', 'I68', 'I65', 'I75', 'I63', 'I12', 'I23', 'I74', 'I08', 'I27', 'I58', 'I04', 'I72', 'I40', 'I02', 'I55', 'I62', 'I28', 'I20', 'I07', 'I41', 'I35', 'I45', 'I31', 'I57', 'I34', 'I52', 'I06', 'I13', 'I29', 'I50'}\n","\n","dict_keys(['incartdb'])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fao6o-Zc6a37","colab_type":"text"},"source":["# [ REP_NORMALS_TRAINING ]"]},{"cell_type":"code","metadata":{"id":"DfZbkP-y6pT0","colab_type":"code","outputId":"12d93084-98bd-4192-df2c-eafd8bae521b","executionInfo":{"status":"ok","timestamp":1590744063236,"user_tz":-330,"elapsed":99909,"user":{"displayName":"Nelson Sharma","photoUrl":"","userId":"05205859662695765719"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#------------------------------------------------------------------------\n","lim_first_F_sec = 30*60 # 30 minutes for training #<<====select this\n","#------------------------------------------------------------------------\n","work_db = train_db1 #<<------------ select working db\n","\n","g_REP_II_POSTFIX = 'REP_'+str(lim_first_F_sec)+'_'+exp_name # representative normal all record\n","lim_delta_rri = 0.04\n","lim_min_Nbeats = 10\n","#------------------------------------------------------------------------\n","\n","print('=================================================')\n","print('Representative Normal')\n","print('lim_delta_rri:'+str(lim_delta_rri))\n","print('lim_min_Nbeats_per_episode:'+str(lim_min_Nbeats))\n","print('lim_first_F_sec:'+str(lim_first_F_sec))\n","print('g_REP_II_POSTFIX:'+str(g_REP_II_POSTFIX))\n","print('=================================================')\n","\n","timestamp_start = datetime.datetime.now()\n","print('DB_RECORD\\t#query\\t#epi\\tResult')\n","\n","for idb in work_db.keys():\n","    sel_db = work_db[idb]\n","    #if idb != 'mitdb':\n","    #    continue\n","    for irec in sel_db.recs:      \n","       # if irec != '208':\n","      #      continue\n","        sel_rec = sel_db.get_record(irec)\n","        rst = sel_rec.name\n","\n","#--------# load signal----------------------------------------\n","        sel_sig = sel_rec.read_data(g_SIG_II_POSTFIX)\n","        if len(sel_sig)<1:\n","            rst+='\\tSignal doesnt exist, Skip this record'\n","            print(rst)\n","            continue\n","        \n","#--------# load beat info----------------------------------------\n","        sbi = sel_rec.read_binfo()\n","\n","#-------# Normal Episodes----------------------------------------\n","        ne_list = []\n","        ne_query = (\n","                    (sbi.rr_peaks_sec <= lim_first_F_sec) &\n","                    (np.absolute(sbi.rri_delta)<=lim_delta_rri) & \n","                    (sbi.rr_int_labels==0)  &\n","                    (sbi.rr_int_plabels==0)  &\n","                    (sbi.rr_int_nlabels==0)\n","                  )\n","        \n","        ne_list = np.where(ne_query)[0]\n","        \n","        if len(ne_list)<lim_min_Nbeats:\n","            rst+='\\tNot enough N beats within rri limits, Skip this record'\n","            print(rst )\n","            continue\n","        else:\n","            rst+='\\t'+str(len(ne_list))   \n","            \n","        ne_list1 = np.hstack((np.sort(ne_list),np.array([-1])))\n","        n_epi = []\n","        # extract episodes from ne_list\n","        n_s = ne_list[0]\n","        delta = 1\n","        for i in range(1, len(ne_list1)):\n","            n_e = ne_list1[i]\n","            if n_e == n_s + delta:\n","                delta+=1\n","            else:\n","                # check if enough number of N beats exist\n","                if delta >=lim_min_Nbeats:\n","                    n_epi.append([n_s,n_s+delta])\n","                n_s = n_e\n","                delta = 1\n","\n","        rst+='\\t'+ str(len(n_epi))\n","        if len(n_epi)==0:\n","            rst+='\\tFailed'\n","            print(rst)\n","            continue    \n","        # select from all episodes\n","        # [epi_index,nos_beats, avg_dur,var_dur,max_dur(signal_len) ]\n","        \n","        mega_epi = np.zeros((0,2*v_dimC + 4),dtype='float')\n","        # 2*vdim for resampled median and mean, \n","        # +4 for avg_dur, var_dur, nos_beats, actual signal_len\n","        \n","        epi_stats = np.zeros((0,4),dtype='float')\n","        #epi_short = 0\n","        for j in range(0, len(n_epi)):\n","            sepi = n_epi[j]\n","            bepi = sepi[1]-sepi[0]\n","            sdur =  sbi.rri_dur[sepi[0]:sepi[1]]\n","            sdur_avg = round(stats.mean(sdur),3)\n","            sdur_var = round(stats.variance(sdur),5)\n","            epi_stats = np.vstack((epi_stats,np.array([j,bepi,sdur_avg,sdur_var])))\n","            # print('Avg_duration = '+ str(sdur_avg)+ ' | bpm = '+ str(60/sdur_avg))\n","            # print('VAr_duration = '+ str(sdur_var))\n","            # print('#'+str(j)+'\\t'+str(bepi)+'\\t'+str(sdur_avg)+'\\t'+str(sdur_var))\n","            \n","            #now for each episode find            \n","            all_epi_signals = []\n","            all_epi_pk = []\n","            sg_left=[]\n","            sg_right=[]\n","            sll,slr = [],[]\n","            \n","            for i in range(sepi[0],sepi[1]):\n","                sg,pk = sbi.get_signal_data_var(i)\n","                all_epi_signals.append(sg)\n","                all_epi_pk.append(pk)\n","                sg_left.append(sg[0:pk])\n","                sg_right.append(sg[pk:])\n","                sll.append(pk)\n","                slr.append(len(sg)-pk)\n","            \n","            ll_max = max(sll)\n","            lr_max = max(slr)\n","            l_max = ll_max+lr_max                \n","            \n","            sg_all2 =  np.zeros((0,l_max))\n","            for i in range(0, bepi):    \n","                sg_all2 = np.vstack((\n","                                sg_all2,\n","                                np.hstack((\n","                                    scsig.resample(sg_left[i],ll_max), \n","                                    scsig.resample(sg_right[i],lr_max)\n","                                    ))\n","                                ))\n","            \n","            x3_men = np.zeros(l_max)\n","            x3_med = np.zeros(l_max)\n","            #x3_var = np.zeros(l_max)\n","            for i in range(0, l_max):\n","                x3_men[i] = stats.mean(sg_all2[:,i])\n","                x3_med[i] = stats.median(sg_all2[:,i])\n","                #x3_var[i] = stats.variance(sg_all2[:,i])     \n","            \n","            # [nos_beats,signal_len, avgd,vard, mean,median] signal_len/Basic_srate = duration\n","            rec_epi = np.array([ bepi,l_max,sdur_avg,sdur_var ])\n","            rec_epi = np.hstack((rec_epi,\n","                                    scsig.resample(x3_men,v_dimC),\n","                                    scsig.resample(x3_med,v_dimC) ))\n","            mega_epi = np.vstack((mega_epi, rec_epi ))\n","            \n","        #rst+= '\\t'+ str(len(mega_epi))\n","        if len(mega_epi) > 0:      \n","            sel_rec.save_data_temp(g_REP_II_POSTFIX, mega_epi, global_tempdir)\n","            rst+= '\\tSuccess'\n","        else:\n","            rst+= '\\tFailed [cont]'\n","        print(rst)\n","\n","\n","print('\\nDone')\n","timestamp_dur = datetime.datetime.now() - timestamp_start\n","print('Elapsed time = ' + str(timestamp_dur))\n","#------------------------------------------------------------------------\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["=================================================\n","Representative Normal\n","lim_delta_rri:0.04\n","lim_min_Nbeats_per_episode:10\n","lim_first_F_sec:1800\n","g_REP_II_POSTFIX:REP_1800_exp_V_clf\n","=================================================\n","DB_RECORD\t#query\t#epi\tResult\n","mitdb_116\t2056\t62\tSuccess\n","mitdb_205\t2478\t27\tSuccess\n","mitdb_215\t2669\t104\tSuccess\n","mitdb_103\t1639\t21\tSuccess\n","mitdb_203\t335\t0\tFailed\n","mitdb_122\t2388\t49\tSuccess\n","mitdb_209\t2049\t66\tSuccess\n","mitdb_220\t1669\t56\tSuccess\n","mitdb_221\t321\t0\tFailed\n","mitdb_113\t645\t1\tSuccess\n","mitdb_202\t913\t6\tSuccess\n","mitdb_123\t462\t0\tFailed\n","mitdb_119\t597\t8\tSuccess\n","mitdb_100\t1873\t71\tSuccess\n","mitdb_234\t2665\t17\tSuccess\n","mitdb_228\t548\t0\tFailed\n","mitdb_233\t886\t10\tSuccess\n","mitdb_210\t642\t0\tFailed\n","mitdb_208\t220\t2\tSuccess\n","mitdb_219\t411\t0\tFailed\n","mitdb_108\t828\t3\tSuccess\n","mitdb_200\t450\t1\tSuccess\n","mitdb_213\t1834\t40\tSuccess\n","mitdb_230\t1951\t61\tSuccess\n","mitdb_112\t2492\t27\tSuccess\n","mitdb_101\t1298\t11\tSuccess\n","mitdb_105\t2313\t78\tSuccess\n","mitdb_114\t1077\t2\tSuccess\n","mitdb_121\t1773\t39\tSuccess\n","mitdb_115\t858\t4\tSuccess\n","mitdb_117\t1105\t22\tSuccess\n","mitdb_106\t539\t4\tSuccess\n","svdb_862\t1901\t48\tSuccess\n","svdb_875\t1757\t33\tSuccess\n","svdb_885\t574\t3\tSuccess\n","svdb_846\t1477\t45\tSuccess\n","svdb_876\t931\t12\tSuccess\n","svdb_877\t989\t10\tSuccess\n","svdb_805\t1614\t55\tSuccess\n","svdb_873\t1353\t35\tSuccess\n","svdb_801\t1687\t36\tSuccess\n","svdb_853\t1560\t52\tSuccess\n","svdb_820\t1777\t65\tSuccess\n","svdb_847\t1401\t48\tSuccess\n","svdb_858\t2133\t22\tSuccess\n","svdb_882\t1738\t39\tSuccess\n","svdb_803\t1609\t66\tSuccess\n","svdb_886\t1976\t64\tSuccess\n","svdb_809\t2412\t11\tSuccess\n","svdb_845\t2324\t11\tSuccess\n","svdb_829\t1344\t40\tSuccess\n","svdb_859\t1431\t12\tSuccess\n","svdb_855\t660\t0\tFailed\n","svdb_844\t1211\t27\tSuccess\n","svdb_870\t442\t2\tSuccess\n","svdb_850\t1748\t32\tSuccess\n","svdb_880\t2278\t59\tSuccess\n","svdb_893\t618\t1\tSuccess\n","svdb_861\t558\t3\tSuccess\n","svdb_804\t665\t0\tFailed\n","svdb_848\t3891\t39\tSuccess\n","svdb_865\t594\t12\tSuccess\n","svdb_843\t2559\t20\tSuccess\n","svdb_856\t2747\t28\tSuccess\n","svdb_841\t746\t22\tSuccess\n","svdb_888\t1935\t58\tSuccess\n","svdb_802\t1159\t35\tSuccess\n","svdb_849\t1793\t43\tSuccess\n","svdb_828\t1274\t42\tSuccess\n","svdb_812\t1529\t38\tSuccess\n","svdb_823\t1781\t40\tSuccess\n","svdb_821\t1000\t0\tFailed\n","svdb_867\t1571\t36\tSuccess\n","svdb_887\t1713\t54\tSuccess\n","svdb_892\t199\t0\tFailed\n","svdb_852\t1103\t18\tSuccess\n","svdb_869\t375\t4\tSuccess\n","svdb_811\t753\t3\tSuccess\n","svdb_808\t1691\t29\tSuccess\n","svdb_810\t1662\t48\tSuccess\n","svdb_874\t2069\t32\tSuccess\n","svdb_864\t1534\t65\tSuccess\n","svdb_879\t557\t14\tSuccess\n","svdb_822\t905\t14\tSuccess\n","svdb_840\t2089\t51\tSuccess\n","svdb_863\t1441\t29\tSuccess\n","svdb_889\t790\t19\tSuccess\n","svdb_884\t1707\t32\tSuccess\n","svdb_842\t1726\t56\tSuccess\n","svdb_854\t303\t1\tSuccess\n","svdb_894\t1861\t64\tSuccess\n","svdb_872\t1681\t70\tSuccess\n","svdb_866\t809\t14\tSuccess\n","svdb_890\t1672\t44\tSuccess\n","svdb_891\t1232\t29\tSuccess\n","svdb_851\t1307\t18\tSuccess\n","svdb_857\t1981\t65\tSuccess\n","svdb_878\t837\t25\tSuccess\n","svdb_807\t1755\t43\tSuccess\n","svdb_826\t1248\t30\tSuccess\n","svdb_868\t770\t5\tSuccess\n","svdb_825\t2350\t62\tSuccess\n","svdb_881\t238\t5\tSuccess\n","svdb_824\t1634\t54\tSuccess\n","svdb_871\t1430\t49\tSuccess\n","svdb_860\t226\t2\tSuccess\n","svdb_827\t1607\t40\tSuccess\n","svdb_800\t1432\t40\tSuccess\n","svdb_883\t1611\t41\tSuccess\n","svdb_806\t2825\t48\tSuccess\n","\n","Done\n","Elapsed time = 0:01:37.959151\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jG7Q_NP1-ZOm","colab_type":"text"},"source":["# [ Plot_Rep_Normal_Set ]"]},{"cell_type":"code","metadata":{"id":"adlDk_q4dPBr","colab_type":"code","outputId":"b1a7e46d-b788-4c84-f301-3bd814827d37","executionInfo":{"status":"ok","timestamp":1590744538313,"user_tz":-330,"elapsed":1511,"user":{"displayName":"Nelson Sharma","photoUrl":"","userId":"05205859662695765719"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# select a database and a record within it\n","work_db = train_db1\n","#-----------------------------------------\n","idb = 'mitdb'\n","irec = '200'\n","#-----------------------------------------\n","sel_db = work_db[idb]\n","sel_rec = sel_db.get_record(irec)\n","print(sel_rec.name)\n","#-----------------------------------------"],"execution_count":0,"outputs":[{"output_type":"stream","text":["mitdb_200\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8YBJERA-dQ6N","colab_type":"text"},"source":["## [ Get REP NORM Set ]"]},{"cell_type":"code","metadata":{"id":"CErrFUrP-dy1","colab_type":"code","outputId":"15cec046-dd73-48da-9de7-1bf38a29a991","executionInfo":{"status":"ok","timestamp":1590744689738,"user_tz":-330,"elapsed":1689,"user":{"displayName":"Nelson Sharma","photoUrl":"","userId":"05205859662695765719"}},"colab":{"base_uri":"https://localhost:8080/","height":803}},"source":["# plot representative set\n","\n","#<<---------------------------------------------Select rep_norm set to be plotted\n","g_REP_II_POSTFIX = 'REP_1800_exp_V_clf'\n","#g_REP_II_POSTFIX = 'REP_300'\n","\n","\n","jx = sel_rec.load_data_temp(g_REP_II_POSTFIX,global_tempdir)\n","print (sel_rec.name+'\\t'+str(jx.shape))\n","print ('Total reps = '+ str(len(jx)))\n","\n","plt.figure(0,figsize=(10,8))\n","plt.ylabel('duration variance')\n","plt.xlabel('nos beats')\n","plt.ylim(-0.001, 0.01)\n","plt.xlim(0,max(jx[:,0])+1)\n","plt.scatter(jx[:,0], jx[:,3],marker='.', color='black')\n","for i in range(0,len(jx)):\n","    plt.annotate(str(i),xy=(jx[i,0], jx[i,3]))\n","\n","#[nos_beats,signal_len, avgd,vard, mean,median] signal_len/Basic_srate = duration\n","print('#epi\\t#beats\\tsig_len\\tavg_dur\\tvar_dur\\tmax_dur')\n","plt.figure(1,figsize=(5,4))\n","plt.ylim(-2,3.5)\n","plt.xlim(-10,v_dimC+10)\n","for cepi in range(0,len(jx)):\n","    iepi = jx[cepi]\n","    n0 = round(iepi[0])\n","    n1 = round(iepi[1])\n","    n2 = round(iepi[2],3)\n","    n3 = round(iepi[3],3)\n","    n4 = round(n1/(128),3)\n","    print(str(cepi)+'\\t'+str(n0)+'\\t'+str(n1)+'\\t'+str(n2)+'\\t'+str(n3)+'\\t'+str(n4))\n","    n_med = iepi[-v_dimC:]\n","    n_men = iepi[4:4+v_dimC]\n","    #<<---------------------------------------------Select Rep_N Median or Mean Beat to be plotted\n","    plt.plot(n_med, linewidth=0.3, color='tab:green') \n","    #plt.plot(n_men, linewidth=0.3, color='tab:blue')\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["mitdb_200\t(1, 772)\n","Total reps = 1\n","#epi\t#beats\tsig_len\tavg_dur\tvar_dur\tmax_dur\n","0\t11.0\t168.0\t1.238\t0.002\t1.312\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x576 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 360x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"wKV2n0Lh-wL0","colab_type":"text"},"source":["## [ Plot_Single_Rep_Normal ]"]},{"cell_type":"code","metadata":{"id":"5I8b4X4y-2oI","colab_type":"code","outputId":"4a93c72a-f39f-4d46-e63d-30eee8bf5ba7","executionInfo":{"status":"ok","timestamp":1590744172291,"user_tz":-330,"elapsed":2043,"user":{"displayName":"Nelson Sharma","photoUrl":"","userId":"05205859662695765719"}},"colab":{"base_uri":"https://localhost:8080/","height":400}},"source":["#<<---------------------------------------------Select index from Rep_Normal Set \n","sel_episode = 68\n","\n","print (sel_rec.name+'\\tepisode#'+str(sel_episode))\n","iepi = jx[sel_episode]\n","jx_men = iepi[4:4+v_dimC]\n","jx_med = iepi[-v_dimC:]\n","\n","n0 = round(iepi[0])\n","n1 = round(iepi[1])\n","n2 = round(iepi[2],3)\n","n3 = round(iepi[3],3)\n","n4 = round(n1/(128),3)\n","print('#beats = '+str(n0)+'\\nsig_len = '+str(n1)+'\\navg_dur = '+str(n2)+'\\nvar_dur = '+str(n3)+'\\nmax_dur = '+str(n4))\n","\n","plt.figure(sel_episode+2)\n","plt.ylim(-2,3.5)\n","plt.title('#epi '+str(sel_episode))\n","#plt.plot(jx_men,label='mean')\n","plt.plot(jx_med,label='median')\n","plt.legend()\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["mitdb_215\tepisode#68\n","#beats = 10.0\n","sig_len = 151.0\n","avg_dur = 1.086\n","var_dur = 0.003\n","max_dur = 1.18\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.legend.Legend at 0x7f458a2de860>"]},"metadata":{"tags":[]},"execution_count":41},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"tLsBe6if_4Ps","colab_type":"text"},"source":["# [ 6_GENRATE_DATASETS ]"]},{"cell_type":"code","metadata":{"id":"5p-FmelP__RU","colab_type":"code","colab":{}},"source":["# CELL 0\n","'''\n","1. Select train_db dict object [CELL 1]\n","2. Select g_CLASS_II_POSTFIX and limit values [CELL 2]\n","3. Select your query [CELL 3]\n","'''\n","#%% CELL 1\n","#------------------------------------------------------------------------\n","train_db = train_db1\n","\n","#%% CELL 2\n","#------------------------------------------------------------------------\n","g_CLASS_II_POSTFIX = 'CLASS'   ##<<<<---------------- [select your post fix]\n","lim_lower, lim_upper = 40, 100 ##<<<<---------------- [select your beat limits]\n","\n","# log file --------------------------------------------------------------------\n","log_file= os.path.join(global_datadir, g_CLASS_II_POSTFIX+'_db_build_log.txt') \n","def print_log(log_string):\n","    log_handle.write(log_string+'\\n')\n","\n","#%% CELL 3\n","#------------------------------------------------------------------------\n","\n","all_total_sveb = 0\n","log_handle = open(log_file,'w')\n","timestamp_start = datetime.datetime.now()\n","print('\\n Start Iteration for '+g_CLASS_II_POSTFIX+' \\n')\n","print_log(g_CLASS_II_POSTFIX+'_LOG_START ['+str(timestamp_start)+ ']')\n","print_log('nos_beat_limits[lower,upper] = ['+ str(lim_lower)+ ','+ str(lim_upper)+']')\n","for idb in train_db.keys():\n","    sel_db = train_db[idb]\n","    #if idb!='svdb':\n","    #    continue\n","    for irec in sel_db.recs:\n","    #    if irec!='865':\n","    #        continue\n","        rst = ''\n","        sel_rec = sel_db.get_record(irec)      \n","        sel_sig = sel_rec.read_data(g_SIG_II_POSTFIX)\n","        rst += str(sel_rec.name)+'\\t'\n","        \n","        #============================================================\n","        print_log('\\n\\n[Selected Record = '+str(sel_rec.name)+ ']')\n","        #============================================================\n","        \n","        if len(sel_sig)<1:\n","            rst+='\\tSignal doesnt exist, Skip this record'\n","            print(rst)\n","            \n","            #============================================================\n","            print_log(' >>Signal doesnt exist, Skip this record')\n","            #============================================================\n","                    \n","            continue\n","        \n","        sbi = sel_rec.read_binfo()      # load beat info\n","    \n","\n","    #----------------------------------------------------------------------------------\n","    #----------------------------------------------------------------------------------\n","        sveb_list = []\n","        sveb_query = () ##<<<<<<<<<<<<<<<<<<<<---------------[Select your query]\n","        sveb_list = np.where(sveb_query)[0]\n","    #----------------------------------------------------------------------------------\n","    #----------------------------------------------------------------------------------\n","    \n","    \n","        \n","        if len(sveb_list)<lim_lower:\n","            rst+='\\tNot enough CLASS beats, Skip this record'\n","            print(rst )\n","            #============================================================\n","            print_log(' >>Invalid query_count = '+str(len(sveb_list))+ ' - skip record')\n","            #============================================================\n","            continue\n","        else:\n","            \n","            #============================================================\n","            print_log(' >>Valid query_count = '+str(len(sveb_list)))\n","            #============================================================\n","            \n","            \n","            rst+='\\tquery:'+str(len(sveb_list))\n","            sveb_sel = np.zeros((0,v_dimC+2),dtype='float') # +2 for peak location and duration\n","            \n","            if len(sveb_list)<=lim_upper: \n","                #============================================================\n","                print_log('CASE_1::query_count <= upper_limit : Need to select all class beats, iterate ...')\n","                #============================================================\n","                rst+='\\tquery<=upperlimit'\n","                # is within selction limits, select all class beats\n","                for ibeat in sveb_list:\n","                    sg,pk = sbi.get_signal_data_var(ibeat)\n","                    \n","                    #============================================================\n","                    print_log('\\tbeat# '+str(ibeat) + '\\tLabel='+sbi.rr_labels[ibeat]+ '\\tTS='+str(round(sbi.rr_peaks_sec[ibeat],2))+'\\tDUR='+str(sbi.rri_dur[ibeat]))\n","                    #============================================================\n","                    \n","                    sg_resamp = scsig.resample(sg,v_dimC)\n","                    pk_resamp = round(pk*( len(sg_resamp)/(len(sg) )))\n","                    beat_duration = sbi.rri_dur[ibeat]\n","                    \n","                    #[ orignal_duration(secs), peak_location(samples),resampled_signal{array}]\n","                    a_resamp = np.hstack((beat_duration,pk_resamp,sg_resamp))\n","                    \n","                    #============================================================\n","                    #print_log('\\tMeta: ['+ str(len(a_resamp)) +']:'+str(a_resamp[0:3]))\n","                    #============================================================\n","                    \n","                    sveb_sel = np.vstack((sveb_sel, a_resamp)) # done now save it\n","                    \n","                #============================================================\n","                print_log('CASE_1::End of Selection, beats_selected = '+ str(sveb_sel.shape))\n","                #============================================================\n","                   \n","            else: # len(sveb_list)>lim_upper\n","                # more than upper_limit find episodes\n","                \n","                #============================================================\n","                print_log('CASE_2::query_count > upper_limit : Do not select all class beats. Find episodes...')\n","                #============================================================\n","                \n","                rst+='\\tquery>upperlimit'\n","                sveb_list1 = np.hstack((np.sort(sveb_list),np.array([-1])))\n","                \n","                sveb_epi = []\n","                # extract episodes from sveb_list\n","                s_s = sveb_list[0]\n","                delta = 1\n","                for i in range(1, len(sveb_list1)):\n","                    s_e = sveb_list1[i]\n","                    if s_e == s_s + delta:\n","                        delta+=1\n","                    else:\n","                        sveb_epi.append([s_s,s_s+delta])\n","                        s_s = s_e\n","                        delta = 1      \n","                        \n","                if len(sveb_epi)==0:\n","                    rst+='\\tImpossible::Not enough class episodes, Skip this record'#<<- this cannot happen\n","                    print(rst)\n","                    print_log('CASE_2::Impossible, no class episodes exist!!')\n","                    continue    \n","                else:\n","                    rst+='\\t'+ str(len(sveb_epi))    \n","                #============================================================\n","                print_log(' >>found episodes : '+ str(len(sveb_epi))+'\\n >>compare #episodes and upper selection limit..')\n","                #============================================================               \n","  \n","                if len(sveb_epi)<=lim_upper:\n","                    delta_ratio = lim_upper/len(sveb_list)\n","                    \n","                    #============================================================\n","                    print_log('CASE_2.1::Less episodes than upper limit : Selection ratio [upper_limit/total_beats] = '+str(round(delta_ratio,2)))\n","                    #============================================================                      \n","                    \n","                    rst+='\\t#epi<=upperlimit, delta_ratio='+ str(round(delta_ratio,2))\n","                    # take delta_ratio times beats from each episode\n","                    \n","                    #============================================================ \n","                    print_log(' >>Prepare rsel: take delta_ratio times beats from each episode, iterate...')\n","                    #============================================================ \n","                    \n","                    for iepi in range(0,len(sveb_epi)):\n","                        i_episode = sveb_epi[iepi]\n","\n","                        beats_in_epi = i_episode[1]-i_episode[0]\n","\n","                        beats_taken = int(int(beats_in_epi*delta_ratio))\n","                        if beats_taken==0:\n","                            beats_taken = 1 # atleast take one beat from each episode\n","                        \n","                        #============================================================ \n","                        print_log('\\tepisode# '+ str(iepi)+'='+str(i_episode)+\n","                              ' has '+ str(beats_in_epi)+ ' beats, randomly take '+\n","                              str(beats_taken)+ ' beats')                        \n","                        #============================================================ \n","\n","                        a = np.arange(i_episode[0],i_episode[1])\n","                        rsel = np.random.choice(a, size=beats_taken, replace=False, p=None)\n","                        \n","                        print_log('\\t >>Selected: '+ str(rsel)+' iterate...')\n","                        for ibeat in rsel:\n","                            sg,pk = sbi.get_signal_data_var(ibeat)\n","                            \n","                            #============================================================\n","                            print_log('\\t\\tbeat# '+str(ibeat) + '\\tL='+sbi.rr_labels[ibeat]+ '\\tTS='+str(round(sbi.rr_peaks_sec[ibeat],2))+'\\tDUR='+str(sbi.rri_dur[ibeat]))\n","                            #============================================================\n","                            \n","                            sg_resamp = scsig.resample(sg,v_dimC)\n","                            pk_resamp = round(pk*( len(sg_resamp)/(len(sg) )))\n","                            beat_duration = sbi.rri_dur[ibeat]\n","                            \n","                            #[ orignal_duration(secs), peak_location(samples),resampled_signal{array}]\n","                            a_resamp = np.hstack((beat_duration,pk_resamp,sg_resamp))\n","                            \n","                            #============================================================ \n","                            #print_log('\\tMeta: ['+ str(len(a_resamp)) +']:'+str(a_resamp[0:3]))\n","                            #============================================================ \n","                            \n","                            sveb_sel = np.vstack((sveb_sel, a_resamp))  # done now save it\n","                            \n","                        #============================================================\n","                        #print_log('\\tend of episode iteration sbeats_selected(this episode) = '+ str(sveb_sel.shape))\n","                        #============================================================\n","                        \n","                    #============================================================\n","                    print_log('end of all episode iteration beats_selected(overall) = '+ str(sveb_sel.shape))\n","                    #============================================================\n","                    \n","                else: # is in b/w upper and lower limit, select one from each episode\n","\n","                    delta_epi = int(len(sveb_epi) / lim_upper) #how many extra episodes\n","                    \n","                    #============================================================\n","                    print_log('CASE_2.2::More episodes than upper limit, index step = int[total_episodes / upperlimit] = '+str(round(delta_epi,2)))\n","                    #============================================================  \n","\n","                    rst+='\\t#epi>upperlimit delta_epi='+ str(round(delta_epi,2))\n","                    ist = 0\n","                    rsel=np.zeros(lim_upper,dtype='int')\n","                    \n","                    ##============================================================  \n","                    print_log(' >>Prepare rsel: step indices, select ONE beat randomly from each episode, iterate...')\n","                    #============================================================  \n","                    \n","                    for ix in range(0,lim_upper):\n","                        i_episode = sveb_epi[ist]\n","                        beats_in_epi = i_episode[1]-i_episode[0]\n","                        j_sel = i_episode[0]\n","                        \n","                        if beats_in_epi > 1:\n","                            j_sel = random.randint(i_episode[0],i_episode[1]-1)\n","                            \n","                        #============================================================  \n","                        print_log('\\tepisode# '+ str(ist)+'='+str(i_episode)+\n","                              ' has '+ str(beats_in_epi)+ ' beats, take random # '+\n","                              str(j_sel))                            \n","                        #============================================================  \n","                        \n","                        rsel[ix] = j_sel\n","                        ist+=delta_epi\n","                        \n","                    #============================================================  \n","                    print_log('Selected Striding: '+ str(rsel)+' iterate...')\n","                    #============================================================  \n","                    \n","                    for ibeat in rsel:\n","                        sg,pk = sbi.get_signal_data_var(ibeat)\n","                        \n","                        #============================================================\n","                        print_log('\\tbeat# '+str(ibeat) + '\\tL='+sbi.rr_labels[ibeat]+ '\\tTS='+str(round(sbi.rr_peaks_sec[ibeat],2))+'\\tDUR='+str(sbi.rri_dur[ibeat]))\n","                        #============================================================\n","                        \n","                        sg_resamp = scsig.resample(sg,v_dimC)\n","                        pk_resamp = round(pk*( len(sg_resamp)/(len(sg) )))\n","                        beat_duration = sbi.rri_dur[ibeat]\n","                        \n","                        #[ orignal_duration(secs), peak_location(samples),resampled_signal{array}]\n","                        a_resamp = np.hstack((beat_duration,pk_resamp,sg_resamp))\n","                        \n","                        #============================================================  \n","                        #print_log('\\tMeta: ['+ str(len(a_resamp)) +']:'+str(a_resamp[0:3]))\n","                        #============================================================  \n","                        \n","                        sveb_sel = np.vstack((sveb_sel, a_resamp))    \n","                        \n","                    #============================================================\n","                    print_log('end of iteration beats_selected = '+ str(sveb_sel.shape))\n","                    #============================================================\n","                    \n","            #============================================================\n","            print_log('end of record, total_beats_selected = '+ str(sveb_sel.shape))\n","            #============================================================\n","            \n","            rst+='\\ttotal_CLASS_BEATS:'+ str(len(sveb_sel))\n","            print(rst)   \n","            \n","            sel_rec.save_data_temp(g_CLASS_II_POSTFIX,sveb_sel)\n","            \n","            all_total_sveb+=len(sveb_sel)            \n","            \n","    # loop end record ----------------------------------------------------------------------------------\n","# loop end database ----------------------------------------------------------------------------------\n","\n","timestamp_dur = datetime.datetime.now() - timestamp_start\n","print('Elapsed time = ' + str(timestamp_dur))\n","print('\\nEnd of Procedure, grand_total_class_beats = '+ str(all_total_sveb))\n","print_log('\\nEnd of Procedure, grand_total_beats = '+ str(all_total_sveb))\n","print_log('\\n'+g_CLASS_II_POSTFIX+'_LOG_END, elapsed time = ['+str(timestamp_dur)+ ']')\n","log_handle.close()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ESMzET2bASSz","colab_type":"text"},"source":["## [ 6.1_S_CLASS_DS ]"]},{"cell_type":"code","metadata":{"id":"B5tsuK6MAbpV","colab_type":"code","colab":{}},"source":["# CELL 0\n","'''\n","1. Build train_db dict object [CELL 1]\n","2. Select g_CLASS_II_POSTFIX and limit values [CELL 2]\n","3. Select your query [CELL 3, line 65]\n","'''\n","#%% CELL 1\n","#------------------------------------------------------------------------\n","\n","train_db = train_db1\n","\n","#%% CELL 2\n","#------------------------------------------------------------------------\n","\n","g_CLASS_II_POSTFIX = 'S'   ##<<<<---------------- [select your post fix]\n","lim_lower, lim_upper = 80, 100 ##<<<<---------------- [select your beat limits]\n","\n","# log file --------------------------------------------------------------------\n","#log_file= os.path.join(global_datadir, g_CLASS_II_POSTFIX+'_db_build_log.txt') \n","#def print_log(log_string):\n","#    log_handle.write(log_string+'\\n')\n","\n","#%% CELL 3\n","#------------------------------------------------------------------------\n","\n","all_total_sveb = 0\n","#log_handle = open(log_file,'w')\n","timestamp_start = datetime.datetime.now()\n","print('\\n Start Iteration for '+g_CLASS_II_POSTFIX+' \\n')\n","#print_log(g_CLASS_II_POSTFIX+'_LOG_START ['+str(timestamp_start)+ ']')\n","print('nos_beat_limits[lower,upper] = ['+ str(lim_lower)+ ','+ str(lim_upper)+']')\n","#print_log('nos_beat_limits[lower,upper] = ['+ str(lim_lower)+ ','+ str(lim_upper)+']')\n","for idb in train_db.keys():\n","    sel_db = train_db[idb]\n","    #if idb!='svdb':\n","    #    continue\n","    for irec in sel_db.recs:\n","    #    if irec!='865':\n","    #        continue\n","        rst = ''\n","        sel_rec = sel_db.get_record(irec)      \n","        sel_sig = sel_rec.read_data(g_SIG_II_POSTFIX)\n","        rst += str(sel_rec.name)+'\\t'\n","        \n","        #============================================================\n","        #print_log('\\n\\n[Selected Record = '+str(sel_rec.name)+ ']')\n","        #============================================================\n","        \n","        if len(sel_sig)<1:\n","            rst+='\\tSignal doesnt exist, Skip this record'\n","            print(rst)\n","            \n","            #============================================================\n","            #print_log(' >>Signal doesnt exist, Skip this record')\n","            #============================================================\n","                    \n","            continue\n","        \n","        sbi = sel_rec.read_binfo()      # load beat info\n","    \n","\n","    #----------------------------------------------------------------------------------\n","    #----------------------------------------------------------------------------------\n","        sveb_list = []\n","        sveb_query = (\n","                    (sbi.rr_labels=='A')  |\n","                    (sbi.rr_labels=='a')  |\n","                    (sbi.rr_labels=='J')  |\n","                    (sbi.rr_labels=='S')  \n","                  )\n","        ##<<<<<<<<<<<<<<<<<<<<---------------[Select your query]\n","        sveb_list = np.where(sveb_query)[0]\n","    #----------------------------------------------------------------------------------\n","    #----------------------------------------------------------------------------------\n","    \n","    \n","        \n","        if len(sveb_list)<lim_lower:\n","            rst+='\\tNot enough CLASS beats, Skip this record'\n","            print(rst )\n","            #============================================================\n","            #print_log(' >>Invalid query_count = '+str(len(sveb_list))+ ' - skip record')\n","            #============================================================\n","            continue\n","        else:\n","            \n","            #============================================================\n","            #print_log(' >>Valid query_count = '+str(len(sveb_list)))\n","            #============================================================\n","            \n","            \n","            rst+='\\tquery:'+str(len(sveb_list))\n","            sveb_sel = np.zeros((0,v_dimC+2),dtype='float') # +2 for peak location and duration\n","            \n","            if len(sveb_list)<=lim_upper: \n","                #============================================================\n","                #print_log('CASE_1::query_count <= upper_limit : Need to select all class beats, iterate ...')\n","                #============================================================\n","                rst+='\\tquery<=upperlimit'\n","                # is within selction limits, select all class beats\n","                for ibeat in sveb_list:\n","                    sg,pk = sbi.get_signal_data_var(ibeat)\n","                    \n","                    #============================================================\n","                    #print_log('\\tbeat# '+str(ibeat) + '\\tLabel='+sbi.rr_labels[ibeat]+ '\\tTS='+str(round(sbi.rr_peaks_sec[ibeat],2))+'\\tDUR='+str(sbi.rri_dur[ibeat]))\n","                    #============================================================\n","                    \n","                    sg_resamp = scsig.resample(sg,v_dimC)\n","                    pk_resamp = round(pk*( len(sg_resamp)/(len(sg) )))\n","                    beat_duration = sbi.rri_dur[ibeat]\n","                    \n","                    #[ orignal_duration(secs), peak_location(samples),resampled_signal{array}]\n","                    a_resamp = np.hstack((beat_duration,pk_resamp,sg_resamp))\n","                    \n","                    #============================================================\n","                    #print_log('\\tMeta: ['+ str(len(a_resamp)) +']:'+str(a_resamp[0:3]))\n","                    #============================================================\n","                    \n","                    sveb_sel = np.vstack((sveb_sel, a_resamp)) # done now save it\n","                    \n","                #============================================================\n","                #print_log('CASE_1::End of Selection, beats_selected = '+ str(sveb_sel.shape))\n","                #============================================================\n","                   \n","            else: # len(sveb_list)>lim_upper\n","                # more than upper_limit find episodes\n","                \n","                #============================================================\n","                #print_log('CASE_2::query_count > upper_limit : Do not select all class beats. Find episodes...')\n","                #============================================================\n","                \n","                rst+='\\tquery>upperlimit'\n","                sveb_list1 = np.hstack((np.sort(sveb_list),np.array([-1])))\n","                \n","                sveb_epi = []\n","                # extract episodes from sveb_list\n","                s_s = sveb_list[0]\n","                delta = 1\n","                for i in range(1, len(sveb_list1)):\n","                    s_e = sveb_list1[i]\n","                    if s_e == s_s + delta:\n","                        delta+=1\n","                    else:\n","                        sveb_epi.append([s_s,s_s+delta])\n","                        s_s = s_e\n","                        delta = 1      \n","                        \n","                if len(sveb_epi)==0:\n","                    rst+='\\tImpossible::Not enough class episodes, Skip this record'#<<- this cannot happen\n","                    print(rst)\n","                    #print_log('CASE_2::Impossible, no class episodes exist!!')\n","                    continue    \n","                else:\n","                    rst+='\\t'+ str(len(sveb_epi))    \n","                #============================================================\n","                #print_log(' >>found episodes : '+ str(len(sveb_epi))+'\\n >>compare #episodes and upper selection limit..')\n","                #============================================================               \n","  \n","                if len(sveb_epi)<=lim_upper:\n","                    delta_ratio = lim_upper/len(sveb_list)\n","                    \n","                    #============================================================\n","                    #print_log('CASE_2.1::Less episodes than upper limit : Selection ratio [upper_limit/total_beats] = '+str(round(delta_ratio,2)))\n","                    #============================================================                      \n","                    \n","                    rst+='\\t#epi<=upperlimit, delta_ratio='+ str(round(delta_ratio,2))\n","                    # take delta_ratio times beats from each episode\n","                    \n","                    #============================================================ \n","                    #print_log(' >>Prepare rsel: take delta_ratio times beats from each episode, iterate...')\n","                    #============================================================ \n","                    \n","                    for iepi in range(0,len(sveb_epi)):\n","                        i_episode = sveb_epi[iepi]\n","\n","                        beats_in_epi = i_episode[1]-i_episode[0]\n","\n","                        beats_taken = int(int(beats_in_epi*delta_ratio))\n","                        if beats_taken==0:\n","                            beats_taken = 1 # atleast take one beat from each episode\n","                        \n","                        #============================================================ \n","                        #print_log('\\tepisode# '+ str(iepi)+'='+str(i_episode)+\n","                        #      ' has '+ str(beats_in_epi)+ ' beats, randomly take '+\n","                        #      str(beats_taken)+ ' beats')                        \n","                        #============================================================ \n","\n","                        a = np.arange(i_episode[0],i_episode[1])\n","                        rsel = np.random.choice(a, size=beats_taken, replace=False, p=None)\n","                        \n","                        #print_log('\\t >>Selected: '+ str(rsel)+' iterate...')\n","                        for ibeat in rsel:\n","                            sg,pk = sbi.get_signal_data_var(ibeat)\n","                            \n","                            #============================================================\n","                            #print_log('\\t\\tbeat# '+str(ibeat) + '\\tL='+sbi.rr_labels[ibeat]+ '\\tTS='+str(round(sbi.rr_peaks_sec[ibeat],2))+'\\tDUR='+str(sbi.rri_dur[ibeat]))\n","                            #============================================================\n","                            \n","                            sg_resamp = scsig.resample(sg,v_dimC)\n","                            pk_resamp = round(pk*( len(sg_resamp)/(len(sg) )))\n","                            beat_duration = sbi.rri_dur[ibeat]\n","                            \n","                            #[ orignal_duration(secs), peak_location(samples),resampled_signal{array}]\n","                            a_resamp = np.hstack((beat_duration,pk_resamp,sg_resamp))\n","                            \n","                            #============================================================ \n","                            #print_log('\\tMeta: ['+ str(len(a_resamp)) +']:'+str(a_resamp[0:3]))\n","                            #============================================================ \n","                            \n","                            sveb_sel = np.vstack((sveb_sel, a_resamp))  # done now save it\n","                            \n","                        #============================================================\n","                        #print_log('\\tend of episode iteration sbeats_selected(this episode) = '+ str(sveb_sel.shape))\n","                        #============================================================\n","                        \n","                    #============================================================\n","                    #print_log('end of all episode iteration beats_selected(overall) = '+ str(sveb_sel.shape))\n","                    #============================================================\n","                    \n","                else: # is in b/w upper and lower limit, select one from each episode\n","\n","                    delta_epi = int(len(sveb_epi) / lim_upper) #how many extra episodes\n","                    \n","                    #============================================================\n","                    #print_log('CASE_2.2::More episodes than upper limit, index step = int[total_episodes / upperlimit] = '+str(round(delta_epi,2)))\n","                    #============================================================  \n","\n","                    rst+='\\t#epi>upperlimit delta_epi='+ str(round(delta_epi,2))\n","                    ist = 0\n","                    rsel=np.zeros(lim_upper,dtype='int')\n","                    \n","                    ##============================================================  \n","                    #print_log(' >>Prepare rsel: step indices, select ONE beat randomly from each episode, iterate...')\n","                    #============================================================  \n","                    \n","                    for ix in range(0,lim_upper):\n","                        i_episode = sveb_epi[ist]\n","                        beats_in_epi = i_episode[1]-i_episode[0]\n","                        j_sel = i_episode[0]\n","                        \n","                        if beats_in_epi > 1:\n","                            j_sel = random.randint(i_episode[0],i_episode[1]-1)\n","                            \n","                        #============================================================  \n","                        #print_log('\\tepisode# '+ str(ist)+'='+str(i_episode)+\n","                        #      ' has '+ str(beats_in_epi)+ ' beats, take random # '+\n","                        #      str(j_sel))                            \n","                        #============================================================  \n","                        \n","                        rsel[ix] = j_sel\n","                        ist+=delta_epi\n","                        \n","                    #============================================================  \n","                    #print_log('Selected Striding: '+ str(rsel)+' iterate...')\n","                    #============================================================  \n","                    \n","                    for ibeat in rsel:\n","                        sg,pk = sbi.get_signal_data_var(ibeat)\n","                        \n","                        #============================================================\n","                        #print_log('\\tbeat# '+str(ibeat) + '\\tL='+sbi.rr_labels[ibeat]+ '\\tTS='+str(round(sbi.rr_peaks_sec[ibeat],2))+'\\tDUR='+str(sbi.rri_dur[ibeat]))\n","                        #============================================================\n","                        \n","                        sg_resamp = scsig.resample(sg,v_dimC)\n","                        pk_resamp = round(pk*( len(sg_resamp)/(len(sg) )))\n","                        beat_duration = sbi.rri_dur[ibeat]\n","                        \n","                        #[ orignal_duration(secs), peak_location(samples),resampled_signal{array}]\n","                        a_resamp = np.hstack((beat_duration,pk_resamp,sg_resamp))\n","                        \n","                        #============================================================  \n","                        #print_log('\\tMeta: ['+ str(len(a_resamp)) +']:'+str(a_resamp[0:3]))\n","                        #============================================================  \n","                        \n","                        sveb_sel = np.vstack((sveb_sel, a_resamp))    \n","                        \n","                    #============================================================\n","                    #print_log('end of iteration beats_selected = '+ str(sveb_sel.shape))\n","                    #============================================================\n","                    \n","            #============================================================\n","            #print_log('end of record, total_beats_selected = '+ str(sveb_sel.shape))\n","            #============================================================\n","            \n","            rst+='\\ttotal_CLASS_BEATS:'+ str(len(sveb_sel))\n","            print(rst)   \n","            \n","            sel_rec.save_data_temp(g_CLASS_II_POSTFIX,sveb_sel)\n","            \n","            all_total_sveb+=len(sveb_sel)            \n","            \n","    # loop end record ----------------------------------------------------------------------------------\n","# loop end database ----------------------------------------------------------------------------------\n","\n","timestamp_dur = datetime.datetime.now() - timestamp_start\n","print('Elapsed time = ' + str(timestamp_dur))\n","print('\\nEnd of Procedure, grand_total_class_beats = '+ str(all_total_sveb))\n","#print_log('\\nEnd of Procedure, grand_total_beats = '+ str(all_total_sveb))\n","#print_log('\\n'+g_CLASS_II_POSTFIX+'_LOG_END, elapsed time = ['+str(timestamp_dur)+ ']')\n","#log_handle.close()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1R_BAOiyAklo","colab_type":"text"},"source":["## [ 6.2_V_CLASS_DS ]"]},{"cell_type":"code","metadata":{"id":"acWTpXB2Ao2O","colab_type":"code","colab":{}},"source":["# CELL 0\n","'''\n","1. Build train_db dict object [CELL 1]\n","2. Select g_CLASS_II_POSTFIX and limit values [CELL 2]\n","3. Select your query [CELL 3, line 65]\n","'''\n","#%% CELL 1\n","#------------------------------------------------------------------------\n","\n","train_db = train_db1\n","\n","#%% CELL 2\n","#------------------------------------------------------------------------\n","\n","g_CLASS_II_POSTFIX = 'V'   ##<<<<---------------- [select your post fix]\n","lim_lower, lim_upper = 80, 100 ##<<<<---------------- [select your beat limits]\n","\n","# log file --------------------------------------------------------------------\n","#log_file= os.path.join(global_datadir, g_CLASS_II_POSTFIX+'_db_build_log.txt') \n","#def print_log(log_string):\n","#    log_handle.write(log_string+'\\n')\n","\n","#%% CELL 3\n","#------------------------------------------------------------------------\n","\n","all_total_sveb = 0\n","#log_handle = open(log_file,'w')\n","timestamp_start = datetime.datetime.now()\n","print('\\n Start Iteration for '+g_CLASS_II_POSTFIX+' \\n')\n","#print_log(g_CLASS_II_POSTFIX+'_LOG_START ['+str(timestamp_start)+ ']')\n","print('nos_beat_limits[lower,upper] = ['+ str(lim_lower)+ ','+ str(lim_upper)+']')\n","#print_log('nos_beat_limits[lower,upper] = ['+ str(lim_lower)+ ','+ str(lim_upper)+']')\n","for idb in train_db.keys():\n","    sel_db = train_db[idb]\n","    #if idb!='svdb':\n","    #    continue\n","    for irec in sel_db.recs:\n","    #    if irec!='865':\n","    #        continue\n","        rst = ''\n","        sel_rec = sel_db.get_record(irec)      \n","        sel_sig = sel_rec.read_data(g_SIG_II_POSTFIX)\n","        rst += str(sel_rec.name)+'\\t'\n","        \n","        #============================================================\n","        #print_log('\\n\\n[Selected Record = '+str(sel_rec.name)+ ']')\n","        #============================================================\n","        \n","        if len(sel_sig)<1:\n","            rst+='\\tSignal doesnt exist, Skip this record'\n","            print(rst)\n","            \n","            #============================================================\n","            #print_log(' >>Signal doesnt exist, Skip this record')\n","            #============================================================\n","                    \n","            continue\n","        \n","        sbi = sel_rec.read_binfo()      # load beat info\n","    \n","\n","    #----------------------------------------------------------------------------------\n","    #----------------------------------------------------------------------------------\n","        sveb_list = []\n","        sveb_query = (\n","                    (sbi.rr_labels=='V')  \n","                  )\n","        ##<<<<<<<<<<<<<<<<<<<<---------------[Select your query]\n","        sveb_list = np.where(sveb_query)[0]\n","    #----------------------------------------------------------------------------------\n","    #----------------------------------------------------------------------------------\n","    \n","    \n","        \n","        if len(sveb_list)<lim_lower:\n","            rst+='\\tNot enough CLASS beats, Skip this record'\n","            print(rst )\n","            #============================================================\n","            #print_log(' >>Invalid query_count = '+str(len(sveb_list))+ ' - skip record')\n","            #============================================================\n","            continue\n","        else:\n","            \n","            #============================================================\n","            #print_log(' >>Valid query_count = '+str(len(sveb_list)))\n","            #============================================================\n","            \n","            \n","            rst+='\\tquery:'+str(len(sveb_list))\n","            sveb_sel = np.zeros((0,v_dimC+2),dtype='float') # +2 for peak location and duration\n","            \n","            if len(sveb_list)<=lim_upper: \n","                #============================================================\n","                #print_log('CASE_1::query_count <= upper_limit : Need to select all class beats, iterate ...')\n","                #============================================================\n","                rst+='\\tquery<=upperlimit'\n","                # is within selction limits, select all class beats\n","                for ibeat in sveb_list:\n","                    sg,pk = sbi.get_signal_data_var(ibeat)\n","                    \n","                    #============================================================\n","                    #print_log('\\tbeat# '+str(ibeat) + '\\tLabel='+sbi.rr_labels[ibeat]+ '\\tTS='+str(round(sbi.rr_peaks_sec[ibeat],2))+'\\tDUR='+str(sbi.rri_dur[ibeat]))\n","                    #============================================================\n","                    \n","                    sg_resamp = scsig.resample(sg,v_dimC)\n","                    pk_resamp = round(pk*( len(sg_resamp)/(len(sg) )))\n","                    beat_duration = sbi.rri_dur[ibeat]\n","                    \n","                    #[ orignal_duration(secs), peak_location(samples),resampled_signal{array}]\n","                    a_resamp = np.hstack((beat_duration,pk_resamp,sg_resamp))\n","                    \n","                    #============================================================\n","                    #print_log('\\tMeta: ['+ str(len(a_resamp)) +']:'+str(a_resamp[0:3]))\n","                    #============================================================\n","                    \n","                    sveb_sel = np.vstack((sveb_sel, a_resamp)) # done now save it\n","                    \n","                #============================================================\n","                #print_log('CASE_1::End of Selection, beats_selected = '+ str(sveb_sel.shape))\n","                #============================================================\n","                   \n","            else: # len(sveb_list)>lim_upper\n","                # more than upper_limit find episodes\n","                \n","                #============================================================\n","                #print_log('CASE_2::query_count > upper_limit : Do not select all class beats. Find episodes...')\n","                #============================================================\n","                \n","                rst+='\\tquery>upperlimit'\n","                sveb_list1 = np.hstack((np.sort(sveb_list),np.array([-1])))\n","                \n","                sveb_epi = []\n","                # extract episodes from sveb_list\n","                s_s = sveb_list[0]\n","                delta = 1\n","                for i in range(1, len(sveb_list1)):\n","                    s_e = sveb_list1[i]\n","                    if s_e == s_s + delta:\n","                        delta+=1\n","                    else:\n","                        sveb_epi.append([s_s,s_s+delta])\n","                        s_s = s_e\n","                        delta = 1      \n","                        \n","                if len(sveb_epi)==0:\n","                    rst+='\\tImpossible::Not enough class episodes, Skip this record'#<<- this cannot happen\n","                    print(rst)\n","                    #print_log('CASE_2::Impossible, no class episodes exist!!')\n","                    continue    \n","                else:\n","                    rst+='\\t'+ str(len(sveb_epi))    \n","                #============================================================\n","                #print_log(' >>found episodes : '+ str(len(sveb_epi))+'\\n >>compare #episodes and upper selection limit..')\n","                #============================================================               \n","  \n","                if len(sveb_epi)<=lim_upper:\n","                    delta_ratio = lim_upper/len(sveb_list)\n","                    \n","                    #============================================================\n","                    #print_log('CASE_2.1::Less episodes than upper limit : Selection ratio [upper_limit/total_beats] = '+str(round(delta_ratio,2)))\n","                    #============================================================                      \n","                    \n","                    rst+='\\t#epi<=upperlimit, delta_ratio='+ str(round(delta_ratio,2))\n","                    # take delta_ratio times beats from each episode\n","                    \n","                    #============================================================ \n","                    #print_log(' >>Prepare rsel: take delta_ratio times beats from each episode, iterate...')\n","                    #============================================================ \n","                    \n","                    for iepi in range(0,len(sveb_epi)):\n","                        i_episode = sveb_epi[iepi]\n","\n","                        beats_in_epi = i_episode[1]-i_episode[0]\n","\n","                        beats_taken = int(int(beats_in_epi*delta_ratio))\n","                        if beats_taken==0:\n","                            beats_taken = 1 # atleast take one beat from each episode\n","                        \n","                        #============================================================ \n","                        #print_log('\\tepisode# '+ str(iepi)+'='+str(i_episode)+\n","                        #      ' has '+ str(beats_in_epi)+ ' beats, randomly take '+\n","                        #      str(beats_taken)+ ' beats')                        \n","                        #============================================================ \n","\n","                        a = np.arange(i_episode[0],i_episode[1])\n","                        rsel = np.random.choice(a, size=beats_taken, replace=False, p=None)\n","                        \n","                        #print_log('\\t >>Selected: '+ str(rsel)+' iterate...')\n","                        for ibeat in rsel:\n","                            sg,pk = sbi.get_signal_data_var(ibeat)\n","                            \n","                            #============================================================\n","                            #print_log('\\t\\tbeat# '+str(ibeat) + '\\tL='+sbi.rr_labels[ibeat]+ '\\tTS='+str(round(sbi.rr_peaks_sec[ibeat],2))+'\\tDUR='+str(sbi.rri_dur[ibeat]))\n","                            #============================================================\n","                            \n","                            sg_resamp = scsig.resample(sg,v_dimC)\n","                            pk_resamp = round(pk*( len(sg_resamp)/(len(sg) )))\n","                            beat_duration = sbi.rri_dur[ibeat]\n","                            \n","                            #[ orignal_duration(secs), peak_location(samples),resampled_signal{array}]\n","                            a_resamp = np.hstack((beat_duration,pk_resamp,sg_resamp))\n","                            \n","                            #============================================================ \n","                            #print_log('\\tMeta: ['+ str(len(a_resamp)) +']:'+str(a_resamp[0:3]))\n","                            #============================================================ \n","                            \n","                            sveb_sel = np.vstack((sveb_sel, a_resamp))  # done now save it\n","                            \n","                        #============================================================\n","                        #print_log('\\tend of episode iteration sbeats_selected(this episode) = '+ str(sveb_sel.shape))\n","                        #============================================================\n","                        \n","                    #============================================================\n","                    #print_log('end of all episode iteration beats_selected(overall) = '+ str(sveb_sel.shape))\n","                    #============================================================\n","                    \n","                else: # is in b/w upper and lower limit, select one from each episode\n","\n","                    delta_epi = int(len(sveb_epi) / lim_upper) #how many extra episodes\n","                    \n","                    #============================================================\n","                    #print_log('CASE_2.2::More episodes than upper limit, index step = int[total_episodes / upperlimit] = '+str(round(delta_epi,2)))\n","                    #============================================================  \n","\n","                    rst+='\\t#epi>upperlimit delta_epi='+ str(round(delta_epi,2))\n","                    ist = 0\n","                    rsel=np.zeros(lim_upper,dtype='int')\n","                    \n","                    ##============================================================  \n","                    #print_log(' >>Prepare rsel: step indices, select ONE beat randomly from each episode, iterate...')\n","                    #============================================================  \n","                    \n","                    for ix in range(0,lim_upper):\n","                        i_episode = sveb_epi[ist]\n","                        beats_in_epi = i_episode[1]-i_episode[0]\n","                        j_sel = i_episode[0]\n","                        \n","                        if beats_in_epi > 1:\n","                            j_sel = random.randint(i_episode[0],i_episode[1]-1)\n","                            \n","                        #============================================================  \n","                        #print_log('\\tepisode# '+ str(ist)+'='+str(i_episode)+\n","                        #      ' has '+ str(beats_in_epi)+ ' beats, take random # '+\n","                        #      str(j_sel))                            \n","                        #============================================================  \n","                        \n","                        rsel[ix] = j_sel\n","                        ist+=delta_epi\n","                        \n","                    #============================================================  \n","                    #print_log('Selected Striding: '+ str(rsel)+' iterate...')\n","                    #============================================================  \n","                    \n","                    for ibeat in rsel:\n","                        sg,pk = sbi.get_signal_data_var(ibeat)\n","                        \n","                        #============================================================\n","                        #print_log('\\tbeat# '+str(ibeat) + '\\tL='+sbi.rr_labels[ibeat]+ '\\tTS='+str(round(sbi.rr_peaks_sec[ibeat],2))+'\\tDUR='+str(sbi.rri_dur[ibeat]))\n","                        #============================================================\n","                        \n","                        sg_resamp = scsig.resample(sg,v_dimC)\n","                        pk_resamp = round(pk*( len(sg_resamp)/(len(sg) )))\n","                        beat_duration = sbi.rri_dur[ibeat]\n","                        \n","                        #[ orignal_duration(secs), peak_location(samples),resampled_signal{array}]\n","                        a_resamp = np.hstack((beat_duration,pk_resamp,sg_resamp))\n","                        \n","                        #============================================================  \n","                        #print_log('\\tMeta: ['+ str(len(a_resamp)) +']:'+str(a_resamp[0:3]))\n","                        #============================================================  \n","                        \n","                        sveb_sel = np.vstack((sveb_sel, a_resamp))    \n","                        \n","                    #============================================================\n","                    #print_log('end of iteration beats_selected = '+ str(sveb_sel.shape))\n","                    #============================================================\n","                    \n","            #============================================================\n","            #print_log('end of record, total_beats_selected = '+ str(sveb_sel.shape))\n","            #============================================================\n","            \n","            rst+='\\ttotal_CLASS_BEATS:'+ str(len(sveb_sel))\n","            print(rst)   \n","            \n","            sel_rec.save_data_temp(g_CLASS_II_POSTFIX,sveb_sel)\n","            \n","            all_total_sveb+=len(sveb_sel)            \n","            \n","    # loop end record ----------------------------------------------------------------------------------\n","# loop end database ----------------------------------------------------------------------------------\n","\n","timestamp_dur = datetime.datetime.now() - timestamp_start\n","print('Elapsed time = ' + str(timestamp_dur))\n","print('\\nEnd of Procedure, grand_total_class_beats = '+ str(all_total_sveb))\n","#print_log('\\nEnd of Procedure, grand_total_beats = '+ str(all_total_sveb))\n","#print_log('\\n'+g_CLASS_II_POSTFIX+'_LOG_END, elapsed time = ['+str(timestamp_dur)+ ']')\n","#log_handle.close()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zipy-TzoAt9M","colab_type":"text"},"source":["## [ 6.3_F_CLASS_DS ]"]},{"cell_type":"code","metadata":{"id":"K7VSuV07AxRB","colab_type":"code","colab":{}},"source":["# CELL 0\n","'''\n","1. Build train_db dict object [CELL 1]\n","2. Select g_CLASS_II_POSTFIX and limit values [CELL 2]\n","3. Select your query [CELL 3, line 65]\n","'''\n","#%% CELL 1\n","#------------------------------------------------------------------------\n","\n","train_db = train_db1\n","\n","#%% CELL 2\n","#------------------------------------------------------------------------\n","\n","g_CLASS_II_POSTFIX = 'F'   ##<<<<---------------- [select your post fix]\n","lim_lower, lim_upper = 30, 100 ##<<<<---------------- [select your beat limits]\n","\n","# log file --------------------------------------------------------------------\n","#log_file= os.path.join(global_datadir, g_CLASS_II_POSTFIX+'_db_build_log.txt') \n","#def print_log(log_string):\n","#    log_handle.write(log_string+'\\n')\n","\n","#%% CELL 3\n","#------------------------------------------------------------------------\n","\n","all_total_sveb = 0\n","#log_handle = open(log_file,'w')\n","timestamp_start = datetime.datetime.now()\n","print('\\n Start Iteration for '+g_CLASS_II_POSTFIX+' \\n')\n","#print_log(g_CLASS_II_POSTFIX+'_LOG_START ['+str(timestamp_start)+ ']')\n","print('nos_beat_limits[lower,upper] = ['+ str(lim_lower)+ ','+ str(lim_upper)+']')\n","#print_log('nos_beat_limits[lower,upper] = ['+ str(lim_lower)+ ','+ str(lim_upper)+']')\n","for idb in train_db.keys():\n","    sel_db = train_db[idb]\n","    #if idb!='svdb':\n","    #    continue\n","    for irec in sel_db.recs:\n","    #    if irec!='865':\n","    #        continue\n","        rst = ''\n","        sel_rec = sel_db.get_record(irec)      \n","        sel_sig = sel_rec.read_data(g_SIG_II_POSTFIX)\n","        rst += str(sel_rec.name)+'\\t'\n","        \n","        #============================================================\n","        #print_log('\\n\\n[Selected Record = '+str(sel_rec.name)+ ']')\n","        #============================================================\n","        \n","        if len(sel_sig)<1:\n","            rst+='\\tSignal doesnt exist, Skip this record'\n","            print(rst)\n","            \n","            #============================================================\n","            #print_log(' >>Signal doesnt exist, Skip this record')\n","            #============================================================\n","                    \n","            continue\n","        \n","        sbi = sel_rec.read_binfo()      # load beat info\n","    \n","\n","    #----------------------------------------------------------------------------------\n","    #----------------------------------------------------------------------------------\n","        sveb_list = []\n","        sveb_query = (\n","                    (sbi.rr_labels=='F')  |\n","                    (sbi.rr_labels=='e')  |\n","                    (sbi.rr_labels=='j')  |\n","                    (sbi.rr_labels=='n')  \n","                  )\n","        ##<<<<<<<<<<<<<<<<<<<<---------------[Select your query]\n","        sveb_list = np.where(sveb_query)[0]\n","    #----------------------------------------------------------------------------------\n","    #----------------------------------------------------------------------------------\n","    \n","    \n","        \n","        if len(sveb_list)<lim_lower:\n","            rst+='\\tNot enough CLASS beats, Skip this record'\n","            print(rst )\n","            #============================================================\n","            #print_log(' >>Invalid query_count = '+str(len(sveb_list))+ ' - skip record')\n","            #============================================================\n","            continue\n","        else:\n","            \n","            #============================================================\n","            #print_log(' >>Valid query_count = '+str(len(sveb_list)))\n","            #============================================================\n","            \n","            \n","            rst+='\\tquery:'+str(len(sveb_list))\n","            sveb_sel = np.zeros((0,v_dimC+2),dtype='float') # +2 for peak location and duration\n","            \n","            if len(sveb_list)<=lim_upper: \n","                #============================================================\n","                #print_log('CASE_1::query_count <= upper_limit : Need to select all class beats, iterate ...')\n","                #============================================================\n","                rst+='\\tquery<=upperlimit'\n","                # is within selction limits, select all class beats\n","                for ibeat in sveb_list:\n","                    sg,pk = sbi.get_signal_data_var(ibeat)\n","                    \n","                    #============================================================\n","                    #print_log('\\tbeat# '+str(ibeat) + '\\tLabel='+sbi.rr_labels[ibeat]+ '\\tTS='+str(round(sbi.rr_peaks_sec[ibeat],2))+'\\tDUR='+str(sbi.rri_dur[ibeat]))\n","                    #============================================================\n","                    \n","                    sg_resamp = scsig.resample(sg,v_dimC)\n","                    pk_resamp = round(pk*( len(sg_resamp)/(len(sg) )))\n","                    beat_duration = sbi.rri_dur[ibeat]\n","                    \n","                    #[ orignal_duration(secs), peak_location(samples),resampled_signal{array}]\n","                    a_resamp = np.hstack((beat_duration,pk_resamp,sg_resamp))\n","                    \n","                    #============================================================\n","                    #print_log('\\tMeta: ['+ str(len(a_resamp)) +']:'+str(a_resamp[0:3]))\n","                    #============================================================\n","                    \n","                    sveb_sel = np.vstack((sveb_sel, a_resamp)) # done now save it\n","                    \n","                #============================================================\n","                #print_log('CASE_1::End of Selection, beats_selected = '+ str(sveb_sel.shape))\n","                #============================================================\n","                   \n","            else: # len(sveb_list)>lim_upper\n","                # more than upper_limit find episodes\n","                \n","                #============================================================\n","                #print_log('CASE_2::query_count > upper_limit : Do not select all class beats. Find episodes...')\n","                #============================================================\n","                \n","                rst+='\\tquery>upperlimit'\n","                sveb_list1 = np.hstack((np.sort(sveb_list),np.array([-1])))\n","                \n","                sveb_epi = []\n","                # extract episodes from sveb_list\n","                s_s = sveb_list[0]\n","                delta = 1\n","                for i in range(1, len(sveb_list1)):\n","                    s_e = sveb_list1[i]\n","                    if s_e == s_s + delta:\n","                        delta+=1\n","                    else:\n","                        sveb_epi.append([s_s,s_s+delta])\n","                        s_s = s_e\n","                        delta = 1      \n","                        \n","                if len(sveb_epi)==0:\n","                    rst+='\\tImpossible::Not enough class episodes, Skip this record'#<<- this cannot happen\n","                    print(rst)\n","                    #print_log('CASE_2::Impossible, no class episodes exist!!')\n","                    continue    \n","                else:\n","                    rst+='\\t'+ str(len(sveb_epi))    \n","                #============================================================\n","                #print_log(' >>found episodes : '+ str(len(sveb_epi))+'\\n >>compare #episodes and upper selection limit..')\n","                #============================================================               \n","  \n","                if len(sveb_epi)<=lim_upper:\n","                    delta_ratio = lim_upper/len(sveb_list)\n","                    \n","                    #============================================================\n","                    #print_log('CASE_2.1::Less episodes than upper limit : Selection ratio [upper_limit/total_beats] = '+str(round(delta_ratio,2)))\n","                    #============================================================                      \n","                    \n","                    rst+='\\t#epi<=upperlimit, delta_ratio='+ str(round(delta_ratio,2))\n","                    # take delta_ratio times beats from each episode\n","                    \n","                    #============================================================ \n","                    #print_log(' >>Prepare rsel: take delta_ratio times beats from each episode, iterate...')\n","                    #============================================================ \n","                    \n","                    for iepi in range(0,len(sveb_epi)):\n","                        i_episode = sveb_epi[iepi]\n","\n","                        beats_in_epi = i_episode[1]-i_episode[0]\n","\n","                        beats_taken = int(int(beats_in_epi*delta_ratio))\n","                        if beats_taken==0:\n","                            beats_taken = 1 # atleast take one beat from each episode\n","                        \n","                        #============================================================ \n","                        #print_log('\\tepisode# '+ str(iepi)+'='+str(i_episode)+\n","                        #      ' has '+ str(beats_in_epi)+ ' beats, randomly take '+\n","                        #      str(beats_taken)+ ' beats')                        \n","                        #============================================================ \n","\n","                        a = np.arange(i_episode[0],i_episode[1])\n","                        rsel = np.random.choice(a, size=beats_taken, replace=False, p=None)\n","                        \n","                        #print_log('\\t >>Selected: '+ str(rsel)+' iterate...')\n","                        for ibeat in rsel:\n","                            sg,pk = sbi.get_signal_data_var(ibeat)\n","                            \n","                            #============================================================\n","                            #print_log('\\t\\tbeat# '+str(ibeat) + '\\tL='+sbi.rr_labels[ibeat]+ '\\tTS='+str(round(sbi.rr_peaks_sec[ibeat],2))+'\\tDUR='+str(sbi.rri_dur[ibeat]))\n","                            #============================================================\n","                            \n","                            sg_resamp = scsig.resample(sg,v_dimC)\n","                            pk_resamp = round(pk*( len(sg_resamp)/(len(sg) )))\n","                            beat_duration = sbi.rri_dur[ibeat]\n","                            \n","                            #[ orignal_duration(secs), peak_location(samples),resampled_signal{array}]\n","                            a_resamp = np.hstack((beat_duration,pk_resamp,sg_resamp))\n","                            \n","                            #============================================================ \n","                            #print_log('\\tMeta: ['+ str(len(a_resamp)) +']:'+str(a_resamp[0:3]))\n","                            #============================================================ \n","                            \n","                            sveb_sel = np.vstack((sveb_sel, a_resamp))  # done now save it\n","                            \n","                        #============================================================\n","                        #print_log('\\tend of episode iteration sbeats_selected(this episode) = '+ str(sveb_sel.shape))\n","                        #============================================================\n","                        \n","                    #============================================================\n","                    #print_log('end of all episode iteration beats_selected(overall) = '+ str(sveb_sel.shape))\n","                    #============================================================\n","                    \n","                else: # is in b/w upper and lower limit, select one from each episode\n","\n","                    delta_epi = int(len(sveb_epi) / lim_upper) #how many extra episodes\n","                    \n","                    #============================================================\n","                    #print_log('CASE_2.2::More episodes than upper limit, index step = int[total_episodes / upperlimit] = '+str(round(delta_epi,2)))\n","                    #============================================================  \n","\n","                    rst+='\\t#epi>upperlimit delta_epi='+ str(round(delta_epi,2))\n","                    ist = 0\n","                    rsel=np.zeros(lim_upper,dtype='int')\n","                    \n","                    ##============================================================  \n","                    #print_log(' >>Prepare rsel: step indices, select ONE beat randomly from each episode, iterate...')\n","                    #============================================================  \n","                    \n","                    for ix in range(0,lim_upper):\n","                        i_episode = sveb_epi[ist]\n","                        beats_in_epi = i_episode[1]-i_episode[0]\n","                        j_sel = i_episode[0]\n","                        \n","                        if beats_in_epi > 1:\n","                            j_sel = random.randint(i_episode[0],i_episode[1]-1)\n","                            \n","                        #============================================================  \n","                        #print_log('\\tepisode# '+ str(ist)+'='+str(i_episode)+\n","                        #      ' has '+ str(beats_in_epi)+ ' beats, take random # '+\n","                        #      str(j_sel))                            \n","                        #============================================================  \n","                        \n","                        rsel[ix] = j_sel\n","                        ist+=delta_epi\n","                        \n","                    #============================================================  \n","                    #print_log('Selected Striding: '+ str(rsel)+' iterate...')\n","                    #============================================================  \n","                    \n","                    for ibeat in rsel:\n","                        sg,pk = sbi.get_signal_data_var(ibeat)\n","                        \n","                        #============================================================\n","                        #print_log('\\tbeat# '+str(ibeat) + '\\tL='+sbi.rr_labels[ibeat]+ '\\tTS='+str(round(sbi.rr_peaks_sec[ibeat],2))+'\\tDUR='+str(sbi.rri_dur[ibeat]))\n","                        #============================================================\n","                        \n","                        sg_resamp = scsig.resample(sg,v_dimC)\n","                        pk_resamp = round(pk*( len(sg_resamp)/(len(sg) )))\n","                        beat_duration = sbi.rri_dur[ibeat]\n","                        \n","                        #[ orignal_duration(secs), peak_location(samples),resampled_signal{array}]\n","                        a_resamp = np.hstack((beat_duration,pk_resamp,sg_resamp))\n","                        \n","                        #============================================================  \n","                        #print_log('\\tMeta: ['+ str(len(a_resamp)) +']:'+str(a_resamp[0:3]))\n","                        #============================================================  \n","                        \n","                        sveb_sel = np.vstack((sveb_sel, a_resamp))    \n","                        \n","                    #============================================================\n","                    #print_log('end of iteration beats_selected = '+ str(sveb_sel.shape))\n","                    #============================================================\n","                    \n","            #============================================================\n","            #print_log('end of record, total_beats_selected = '+ str(sveb_sel.shape))\n","            #============================================================\n","            \n","            rst+='\\ttotal_CLASS_BEATS:'+ str(len(sveb_sel))\n","            print(rst)   \n","            \n","            sel_rec.save_data_temp(g_CLASS_II_POSTFIX,sveb_sel)\n","            \n","            all_total_sveb+=len(sveb_sel)            \n","            \n","    # loop end record ----------------------------------------------------------------------------------\n","# loop end database ----------------------------------------------------------------------------------\n","\n","timestamp_dur = datetime.datetime.now() - timestamp_start\n","print('Elapsed time = ' + str(timestamp_dur))\n","print('\\nEnd of Procedure, grand_total_class_beats = '+ str(all_total_sveb))\n","#print_log('\\nEnd of Procedure, grand_total_beats = '+ str(all_total_sveb))\n","#print_log('\\n'+g_CLASS_II_POSTFIX+'_LOG_END, elapsed time = ['+str(timestamp_dur)+ ']')\n","#log_handle.close()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nwt8Ln-6A0oH","colab_type":"text"},"source":["## [ 6.4_N_CLASS_DS ]"]},{"cell_type":"code","metadata":{"id":"8jPlQqXze2q1","colab_type":"code","colab":{}},"source":["# CELL 0\n","'''\n","1. Build train_db dict object [CELL 1]\n","2. Select g_CLASS_II_POSTFIX and limit values [CELL 2]\n","3. Select your query [CELL 3, line 65]\n","'''\n","#%% CELL 1\n","#------------------------------------------------------------------------\n","\n","train_db = train_db1\n","\n","#%% CELL 2\n","#------------------------------------------------------------------------\n","\n","g_CLASS_II_POSTFIX = 'N'   ##<<<<---------------- [select your post fix]\n","lim_lower, lim_upper = 50, 60 ##<<<<---------------- [select your beat limits]\n","\n","# log file --------------------------------------------------------------------\n","#log_file= os.path.join(global_datadir, g_CLASS_II_POSTFIX+'_db_build_log.txt') \n","#def print_log(log_string):\n","#    log_handle.write(log_string+'\\n')\n","\n","#%% CELL 3\n","#------------------------------------------------------------------------\n","\n","all_total_sveb = 0\n","#log_handle = open(log_file,'w')\n","timestamp_start = datetime.datetime.now()\n","print('\\n Start Iteration for '+g_CLASS_II_POSTFIX+' \\n')\n","#print_log(g_CLASS_II_POSTFIX+'_LOG_START ['+str(timestamp_start)+ ']')\n","print('nos_beat_limits[lower,upper] = ['+ str(lim_lower)+ ','+ str(lim_upper)+']')\n","#print_log('nos_beat_limits[lower,upper] = ['+ str(lim_lower)+ ','+ str(lim_upper)+']')\n","for idb in train_db.keys():\n","    sel_db = train_db[idb]\n","    #if idb!='svdb':\n","    #    continue\n","    for irec in sel_db.recs:\n","    #    if irec!='865':\n","    #        continue\n","        rst = ''\n","        sel_rec = sel_db.get_record(irec)      \n","        sel_sig = sel_rec.read_data(g_SIG_II_POSTFIX)\n","        rst += str(sel_rec.name)+'\\t'\n","        \n","        #============================================================\n","        #print_log('\\n\\n[Selected Record = '+str(sel_rec.name)+ ']')\n","        #============================================================\n","        \n","        if len(sel_sig)<1:\n","            rst+='\\tSignal doesnt exist, Skip this record'\n","            print(rst)\n","            \n","            #============================================================\n","            #print_log(' >>Signal doesnt exist, Skip this record')\n","            #============================================================\n","                    \n","            continue\n","        \n","        sbi = sel_rec.read_binfo()      # load beat info\n","    \n","\n","    #----------------------------------------------------------------------------------\n","    #----------------------------------------------------------------------------------\n","        sveb_list = []\n","        sveb_query = (\n","                    #(np.absolute(sbi.rri_delta)<=lim_delta_rri) & \n","                    (sbi.rr_int_labels==0)  &\n","                    (sbi.rr_int_plabels==0)  &\n","                    (sbi.rr_int_nlabels==0)\n","            ) \n","        ##<<<<<<<<<<<<<<<<<<<<---------------[Select your query]\n","        sveb_list = np.where(sveb_query)[0]\n","    #----------------------------------------------------------------------------------\n","    #----------------------------------------------------------------------------------\n","    \n","    \n","        \n","        if len(sveb_list)<lim_lower:\n","            rst+='\\tNot enough CLASS beats, Skip this record'\n","            print(rst )\n","            #============================================================\n","            #print_log(' >>Invalid query_count = '+str(len(sveb_list))+ ' - skip record')\n","            #============================================================\n","            continue\n","        else:\n","            \n","            #============================================================\n","            #print_log(' >>Valid query_count = '+str(len(sveb_list)))\n","            #============================================================\n","            \n","            \n","            rst+='\\tquery:'+str(len(sveb_list))\n","            sveb_sel = np.zeros((0,v_dimC+2),dtype='float') # +2 for peak location and duration\n","            \n","            if len(sveb_list)<=lim_upper: \n","                #============================================================\n","                #print_log('CASE_1::query_count <= upper_limit : Need to select all class beats, iterate ...')\n","                #============================================================\n","                rst+='\\tquery<=upperlimit'\n","                # is within selction limits, select all class beats\n","                for ibeat in sveb_list:\n","                    sg,pk = sbi.get_signal_data_var(ibeat)\n","                    \n","                    #============================================================\n","                    #print_log('\\tbeat# '+str(ibeat) + '\\tLabel='+sbi.rr_labels[ibeat]+ '\\tTS='+str(round(sbi.rr_peaks_sec[ibeat],2))+'\\tDUR='+str(sbi.rri_dur[ibeat]))\n","                    #============================================================\n","                    \n","                    sg_resamp = scsig.resample(sg,v_dimC)\n","                    pk_resamp = round(pk*( len(sg_resamp)/(len(sg) )))\n","                    beat_duration = sbi.rri_dur[ibeat]\n","                    \n","                    #[ orignal_duration(secs), peak_location(samples),resampled_signal{array}]\n","                    a_resamp = np.hstack((beat_duration,pk_resamp,sg_resamp))\n","                    \n","                    #============================================================\n","                    #print_log('\\tMeta: ['+ str(len(a_resamp)) +']:'+str(a_resamp[0:3]))\n","                    #============================================================\n","                    \n","                    sveb_sel = np.vstack((sveb_sel, a_resamp)) # done now save it\n","                    \n","                #============================================================\n","                #print_log('CASE_1::End of Selection, beats_selected = '+ str(sveb_sel.shape))\n","                #============================================================\n","                   \n","            else: # len(sveb_list)>lim_upper\n","                # more than upper_limit find episodes\n","                \n","                #============================================================\n","                #print_log('CASE_2::query_count > upper_limit : Do not select all class beats. Find episodes...')\n","                #============================================================\n","                \n","                rst+='\\tquery>upperlimit'\n","                sveb_list1 = np.hstack((np.sort(sveb_list),np.array([-1])))\n","                \n","                sveb_epi = []\n","                # extract episodes from sveb_list\n","                s_s = sveb_list[0]\n","                delta = 1\n","                for i in range(1, len(sveb_list1)):\n","                    s_e = sveb_list1[i]\n","                    if s_e == s_s + delta:\n","                        delta+=1\n","                    else:\n","                        sveb_epi.append([s_s,s_s+delta])\n","                        s_s = s_e\n","                        delta = 1      \n","                        \n","                if len(sveb_epi)==0:\n","                    rst+='\\tImpossible::Not enough class episodes, Skip this record'#<<- this cannot happen\n","                    print(rst)\n","                    #print_log('CASE_2::Impossible, no class episodes exist!!')\n","                    continue    \n","                else:\n","                    rst+='\\t'+ str(len(sveb_epi))    \n","                #============================================================\n","                #print_log(' >>found episodes : '+ str(len(sveb_epi))+'\\n >>compare #episodes and upper selection limit..')\n","                #============================================================               \n","  \n","                if len(sveb_epi)<=lim_upper:\n","                    delta_ratio = lim_upper/len(sveb_list)\n","                    \n","                    #============================================================\n","                    #print_log('CASE_2.1::Less episodes than upper limit : Selection ratio [upper_limit/total_beats] = '+str(round(delta_ratio,2)))\n","                    #============================================================                      \n","                    \n","                    rst+='\\t#epi<=upperlimit, delta_ratio='+ str(round(delta_ratio,2))\n","                    # take delta_ratio times beats from each episode\n","                    \n","                    #============================================================ \n","                    #print_log(' >>Prepare rsel: take delta_ratio times beats from each episode, iterate...')\n","                    #============================================================ \n","                    \n","                    for iepi in range(0,len(sveb_epi)):\n","                        i_episode = sveb_epi[iepi]\n","\n","                        beats_in_epi = i_episode[1]-i_episode[0]\n","\n","                        beats_taken = int(int(beats_in_epi*delta_ratio))\n","                        if beats_taken==0:\n","                            beats_taken = 1 # atleast take one beat from each episode\n","                        \n","                        #============================================================ \n","                        #print_log('\\tepisode# '+ str(iepi)+'='+str(i_episode)+\n","                        #      ' has '+ str(beats_in_epi)+ ' beats, randomly take '+\n","                        #      str(beats_taken)+ ' beats')                        \n","                        #============================================================ \n","\n","                        a = np.arange(i_episode[0],i_episode[1])\n","                        rsel = np.random.choice(a, size=beats_taken, replace=False, p=None)\n","                        \n","                        #print_log('\\t >>Selected: '+ str(rsel)+' iterate...')\n","                        for ibeat in rsel:\n","                            sg,pk = sbi.get_signal_data_var(ibeat)\n","                            \n","                            #============================================================\n","                            #print_log('\\t\\tbeat# '+str(ibeat) + '\\tL='+sbi.rr_labels[ibeat]+ '\\tTS='+str(round(sbi.rr_peaks_sec[ibeat],2))+'\\tDUR='+str(sbi.rri_dur[ibeat]))\n","                            #============================================================\n","                            \n","                            sg_resamp = scsig.resample(sg,v_dimC)\n","                            pk_resamp = round(pk*( len(sg_resamp)/(len(sg) )))\n","                            beat_duration = sbi.rri_dur[ibeat]\n","                            \n","                            #[ orignal_duration(secs), peak_location(samples),resampled_signal{array}]\n","                            a_resamp = np.hstack((beat_duration,pk_resamp,sg_resamp))\n","                            \n","                            #============================================================ \n","                            #print_log('\\tMeta: ['+ str(len(a_resamp)) +']:'+str(a_resamp[0:3]))\n","                            #============================================================ \n","                            \n","                            sveb_sel = np.vstack((sveb_sel, a_resamp))  # done now save it\n","                            \n","                        #============================================================\n","                        #print_log('\\tend of episode iteration sbeats_selected(this episode) = '+ str(sveb_sel.shape))\n","                        #============================================================\n","                        \n","                    #============================================================\n","                    #print_log('end of all episode iteration beats_selected(overall) = '+ str(sveb_sel.shape))\n","                    #============================================================\n","                    \n","                else: # is in b/w upper and lower limit, select one from each episode\n","\n","                    delta_epi = int(len(sveb_epi) / lim_upper) #how many extra episodes\n","                    \n","                    #============================================================\n","                    #print_log('CASE_2.2::More episodes than upper limit, index step = int[total_episodes / upperlimit] = '+str(round(delta_epi,2)))\n","                    #============================================================  \n","\n","                    rst+='\\t#epi>upperlimit delta_epi='+ str(round(delta_epi,2))\n","                    ist = 0\n","                    rsel=np.zeros(lim_upper,dtype='int')\n","                    \n","                    ##============================================================  \n","                    #print_log(' >>Prepare rsel: step indices, select ONE beat randomly from each episode, iterate...')\n","                    #============================================================  \n","                    \n","                    for ix in range(0,lim_upper):\n","                        i_episode = sveb_epi[ist]\n","                        beats_in_epi = i_episode[1]-i_episode[0]\n","                        j_sel = i_episode[0]\n","                        \n","                        if beats_in_epi > 1:\n","                            j_sel = random.randint(i_episode[0],i_episode[1]-1)\n","                            \n","                        #============================================================  \n","                        #print_log('\\tepisode# '+ str(ist)+'='+str(i_episode)+\n","                        #      ' has '+ str(beats_in_epi)+ ' beats, take random # '+\n","                        #      str(j_sel))                            \n","                        #============================================================  \n","                        \n","                        rsel[ix] = j_sel\n","                        ist+=delta_epi\n","                        \n","                    #============================================================  \n","                    #print_log('Selected Striding: '+ str(rsel)+' iterate...')\n","                    #============================================================  \n","                    \n","                    for ibeat in rsel:\n","                        sg,pk = sbi.get_signal_data_var(ibeat)\n","                        \n","                        #============================================================\n","                        #print_log('\\tbeat# '+str(ibeat) + '\\tL='+sbi.rr_labels[ibeat]+ '\\tTS='+str(round(sbi.rr_peaks_sec[ibeat],2))+'\\tDUR='+str(sbi.rri_dur[ibeat]))\n","                        #============================================================\n","                        \n","                        sg_resamp = scsig.resample(sg,v_dimC)\n","                        pk_resamp = round(pk*( len(sg_resamp)/(len(sg) )))\n","                        beat_duration = sbi.rri_dur[ibeat]\n","                        \n","                        #[ orignal_duration(secs), peak_location(samples),resampled_signal{array}]\n","                        a_resamp = np.hstack((beat_duration,pk_resamp,sg_resamp))\n","                        \n","                        #============================================================  \n","                        #print_log('\\tMeta: ['+ str(len(a_resamp)) +']:'+str(a_resamp[0:3]))\n","                        #============================================================  \n","                        \n","                        sveb_sel = np.vstack((sveb_sel, a_resamp))    \n","                        \n","                    #============================================================\n","                    #print_log('end of iteration beats_selected = '+ str(sveb_sel.shape))\n","                    #============================================================\n","                    \n","            #============================================================\n","            #print_log('end of record, total_beats_selected = '+ str(sveb_sel.shape))\n","            #============================================================\n","            \n","            rst+='\\ttotal_CLASS_BEATS:'+ str(len(sveb_sel))\n","            print(rst)   \n","            \n","            sel_rec.save_data_temp(g_CLASS_II_POSTFIX,sveb_sel)\n","            \n","            all_total_sveb+=len(sveb_sel)            \n","            \n","    # loop end record ----------------------------------------------------------------------------------\n","# loop end database ----------------------------------------------------------------------------------\n","\n","timestamp_dur = datetime.datetime.now() - timestamp_start\n","print('Elapsed time = ' + str(timestamp_dur))\n","print('\\nEnd of Procedure, grand_total_class_beats = '+ str(all_total_sveb))\n","#print_log('\\nEnd of Procedure, grand_total_beats = '+ str(all_total_sveb))\n","#print_log('\\n'+g_CLASS_II_POSTFIX+'_LOG_END, elapsed time = ['+str(timestamp_dur)+ ']')\n","#log_handle.close()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5JRCWFYdBMjb","colab_type":"text"},"source":["# [ 7_COMPILE_DATASETS ]"]},{"cell_type":"code","metadata":{"id":"_BxM_CY0fXjc","colab_type":"code","colab":{}},"source":["# list avaialble datasets\n","ls_datasets = os.listdir(global_customdir)\n","print('Available Datasets:')\n","for ds_i in ls_datasets:\n","    print(ds_i)\n","print('--------------------------')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i0_eFdU9c3xY","colab_type":"text"},"source":["## [ 7.1_Compile_Training_Set ]"]},{"cell_type":"code","metadata":{"id":"_KgxSgWpBXVu","colab_type":"code","colab":{}},"source":["#<<---------------------------------- Select save name of this dataset\n","ds_name = 'custom_set_3'\n","ds_path = os.path.join(global_customdir, ds_name+'.npy') \n","\n","#<<---------------------------------- Select which working db to compile from\n","train_db = train_db1    \n","\n","#<<---------------------------------- SELCT PARAMS\n","g_REP_NORM_POSTFIX = 'REP_1800' # for taining use rep norm from full record\n","g_CLASS_N_POSTFIX = 'N'\n","g_CLASS_S_POSTFIX = 'S'\n","g_CLASS_V_POSTFIX = 'V'\n","g_CLASS_F_POSTFIX = 'F'\n","lim_min_rep_norms = 10 # at least this many rep norms must exist\n","#lim_lower, lim_upper = 40, 100 ##<<<<---------------- [select your beat limits]\n","#------------------------------------------------------------------------\n","\n","g_SUPRESS_DATA_WARNING=True # supress 'file not found' warnings from ecg_record class\n","\n","timestamp_start = datetime.datetime.now()\n","print('\\n Start Iteration for train_db \\n')\n","print('DB_REC\\t#r\\t#n\\t#s\\t#v\\t#f\\t#a\\tN~A\\tselN\\tselA\\tselNA\\trec_input')\n","mega_input = np.zeros((0,1+v_dimC+1+v_dimC+1))\n","for idb in train_db.keys():\n","    sel_db = train_db[idb]\n","    #if idb!='svdb':\n","     #   continue\n","    for irec in sel_db.recs:\n","        #if irec!='865':\n","         #   continue\n","        sel_rec = sel_db.get_record(irec)   \n","        \n","        #============================================================\n","        # print_log('\\n\\n[Selected Record = '+str(sel_rec.name)+ ']')\n","        #============================================================\n","        rst=sel_rec.name+'\\t'\n","        \n","        # first laod representative normal file\n","        npy_rep = sel_rec.read_data_temp(g_REP_NORM_POSTFIX)\n","        nos_rep = len(npy_rep)\n","        \n","        # check if enough normal episodes\n","        if nos_rep<lim_min_rep_norms:\n","            #============================================================\n","            # print_log(' >> Not enough Representative Normals, skip record')\n","            #============================================================ \n","            rst+=' >> Not enough Representative Normals, skip record\\t'\n","            print(rst)\n","            continue\n","        else:\n","            #============================================================\n","            # print_log(' >> Nos Representative Normals = '+str(nos_rep))\n","            #============================================================           \n","            rst+=str(nos_rep)+'\\t'\n","        \n","        # Now load S,V,F beats, returns blank array if file doesn't exist\n","        npy_N = sel_rec.read_data_temp(g_CLASS_N_POSTFIX)\n","        npy_S = sel_rec.read_data_temp(g_CLASS_S_POSTFIX)\n","        npy_V = sel_rec.read_data_temp(g_CLASS_V_POSTFIX)\n","        npy_F = sel_rec.read_data_temp(g_CLASS_F_POSTFIX)\n","        \n","        nos_N, nos_S, nos_V, nos_F = len(npy_N), len(npy_S), len(npy_V), len(npy_F)\n","        nos_A = nos_S + nos_V + nos_F\n","        \n","        #============================================================\n","        # print_log(' >> Nos [N] = ['+str(nos_N)+']')\n","        # print_log(' >> Nos [S,V,F] = ['+str(nos_S)+','+str(nos_V)+','+str(nos_F)+'] = '+str(nos_A))\n","        #============================================================         \n","        rst+=str(nos_N)+'\\t'+str(nos_S)+'\\t'+str(nos_V)+'\\t'+str(nos_F)+'\\t'+str(nos_A)+'\\t'\n","        \n","        if nos_N == 0 or nos_A==0:\n","            #============================================================\n","            # print_log(' >> Cannot continue with zero beats, skip record')\n","            #============================================================\n","            rst+=' >> Cannot continue with zero beats, skip record\\t'\n","            print(rst)\n","            continue\n","        \n","        if nos_S == 0:\n","            npy_S = np.zeros((0,v_dimC+2))\n","            \n","        if nos_V == 0:\n","            npy_V = np.zeros((0,v_dimC+2))\n","            \n","        if nos_F == 0:\n","            npy_F = np.zeros((0,v_dimC+2))\n","        \n","\n","        \n","        # need to select as many as nos_A beats..and concatenate label = 1 (for abnormal)\n","        #label_A = np.ones((nos_A,1))\n","        sel_A = np.hstack((  \n","                        np.ones((nos_A,1)),             #<<----label\n","                        np.vstack((npy_S,npy_V,npy_F))  #<<----data\n","                        ))\n","        sel_N = []\n","        a = np.arange(0,nos_N)\n","        if nos_N>=nos_A:\n","            # random choice from nos_N \n","            #============================================================\n","            # print_log('CASE_1:: nos_N>=nos_A')\n","            #============================================================  \n","            rst+= ' N>=A\\t'\n","            sel_N = np.hstack((\n","                np.zeros((nos_A,1)),\n","                npy_N[ np.random.choice( a, size=nos_A, replace=False, p=None ) ]\n","                            ))\n","        else:\n","            # repeate N beats - how many to repeat ?\n","            #============================================================\n","            # print_log('CASE_2:: nos_N<nos_A')\n","            #============================================================  \n","            rst+= ' N<A\\t'\n","            nos_repeat = nos_A%nos_N\n","            times_repeat = int(nos_A/nos_N)\n","            \n","            npy_NT = np.zeros((0,v_dimC+2))\n","            for nr in range(0,times_repeat):\n","                npy_NT = np.vstack((npy_NT,npy_N))\n","            \n","            sel_N = np.hstack((\n","                        np.zeros((nos_A,1)),            \n","                        np.vstack((\n","                            npy_NT,    \n","                            npy_N[ np.random.choice( a, size=nos_repeat, replace=False, p=None ) ]\n","                                ))\n","                            ))\n","        #----- endof selection\n","        #============================================================\n","        # print_log('End of Selection :: N = '+ str(len(sel_N))+ ' A = '+str(len(sel_A)))\n","        #============================================================ \n","        rst+= str(len(sel_N))+ '\\t'+str(len(sel_A))+'\\t'\n","        \n","        sel_data = np.vstack((sel_A,sel_N))\n","        \n","        #============================================================ \n","        # print_log('Total beats :: '+ str(len(sel_data)))\n","        #============================================================ \n","        rst+= str(len(sel_data))+'\\t'\n","        \n","        \n","        # now select rep_normals to be used for training with data\n","        # >> sort by nos_beats and select high count episodes\n","        # col 0 contains nos_beats in that episode \n","        npy_rep_sort = npy_rep[np.argsort(npy_rep[:, 0])][0:lim_min_rep_norms]\n","        # structure of npy_rep is \n","        #               0 nos_beats, \n","        #               1 l_max(resampled length in samples), \n","        #               2 avg_dur(sec), \n","        #               3 var_dur, \n","        #               4:4+v_dimC mean_signal(array of len v_dimC), \n","        #               -v_dimC: median_signal(array of len v_dimC)\n","        \n","        # now total samples would be (nos_A + nos_N) * lim_min_rep_norms\n","        # inputs=[input_N, input_N_dur,input_C, input_C_dur],\n","        rec_input = np.zeros((0,1+v_dimC+1+v_dimC+1))\n","        for rr in npy_rep_sort:\n","\n","            #input_N = rr[4:4+v_dimC]  #<<------- mean representaion\n","            input_N = rr[-v_dimC:]  #<<------- median representaion\n","            \n","            #input_N_dur = rr[1]/BASIC_SRATE  #<<----------- max_duration of episode\n","            input_N_dur = rr[2]  #<<----------- avg_duration of episode\n","            \n","            for ss in sel_data: \n","            # NOTE : int lable has been stacked in front of array, shift index by 1\n","                input_label = ss[0] #<<----- label\n","                \n","                input_C = ss[-v_dimC:] #<<----- resampled signal\n","                \n","                input_C_dur = ss[1] #<<----- orginal duration of beat in seconds\n","                \n","                \n","                final_input = np.hstack((\n","                                        input_label,\n","                                        input_N,\n","                                        input_N_dur,\n","                                        input_C,\n","                                        input_C_dur\n","                                        ))\n","                \n","                rec_input = np.vstack((rec_input,final_input))\n","                \n","        #============================================================ \n","        # print_log('Record selection :: '+ str(rec_input.shape))\n","        #============================================================\n","        rst+= str(len(rec_input))\n","        print(rst)\n","\n","        mega_input = np.vstack((mega_input,rec_input))\n","\n","#============================================================ \n","# print_log('Total selection :: '+ str(mega_input.shape))\n","#============================================================\n","#rst+= str(len(mega_input))+'\\t'\n","print('\\nDone! Total beats = '+ str(len(mega_input)))\n","timestamp_dur = datetime.datetime.now() - timestamp_start\n","print('Elapsed time = ' + str(timestamp_dur))\n","\n","#%%\n","# save mega_input\n","np.save(ds_path,mega_input)\n","print('saved at '+ str(ds_path))\n","\n","#%%\n","g_SUPRESS_DATA_WARNING=False # resume 'file not found' warnings\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UeFD7TwZcn1d","colab_type":"text"},"source":["## [ 7.2_Compile_Testing_Set ]"]},{"cell_type":"code","metadata":{"id":"c-GZ99BQcwsY","colab_type":"code","colab":{}},"source":["#<<---------------------------------- Select save name of this dataset\n","ds_name = 'custom_set_test_1'\n","ds_path = os.path.join(global_customdir, ds_name+'.npy') \n","\n","#<<---------------------------------- Select which working db to compile from\n","g_REP_NORM_POSTFIX = 'REP_300'\n","lim_min_rep_norms = 1\n","#<<---------------------------------- Select which working db to compile from\n","test_db = test_db1\n","\n","g_SUPRESS_DATA_WARNING=True # supress 'file not found' warnings from ecg_record class\n","print('db_rec\\t#beats\\t#r\\t#stacked')\n","timestamp_start = datetime.datetime.now()\n","mega_input = np.zeros((0,1+v_dimC+1+v_dimC+1))\n","for idb in test_db.keys():\n","    #if idb!='svdb':\n","     #   continue\n","    sel_db = test_db[idb]\n","    for irec in sel_db.recs:\n","        #if irec!='865':\n","         #   continue\n","        #------------------------------------------------------------------------\n","        sel_rec = sel_db.get_record(irec)\n","        #print(sel_rec.name)\n","        #------------------------------------------------------------------------\n","        # load signal\n","        sel_sig = sel_rec.read_data(g_SIG_II_POSTFIX)\n","        rst=sel_rec.name+'\\t'\n","        #print('signal shape = ' + str(sel_sig.shape))\n","        if len(sel_sig)<1:\n","            rst+=' >>Signal cannot be loaded\\t'\n","            print(rst)\n","            continue\n","        #else:\n","        #    print(' >>Signal loaded succesfully')\n","\n","        # load beat info\n","        sbi = sel_rec.read_binfo()\n","        rst+=str(sbi.nos_rr_peaks)+'\\t'\n","\n","\n","        # first laod representative normal file\n","        \n","        npy_rep = sel_rec.read_data_temp(g_REP_NORM_POSTFIX)\n","        nos_rep = len(npy_rep)\n","\n","        # check if enough normal episodes\n","        if nos_rep<lim_min_rep_norms:\n","            rst+=' >> Not enough Representative Normals\\t'\n","            print(rst)\n","            continue\n","        else:\n","            rst+=str(nos_rep)+'\\t'\n","\n","        all_beats = np.zeros((0,v_dimC+1+1))\n","        for ibeat in range(0,sbi.nos_rr_peaks):\n","            sg,pk = sbi.get_signal_data_var(ibeat)\n","            #============================================================\n","            #print_log('\\tbeat# '+str(ibeat) + '\\tLabel='+sbi.rr_labels[ibeat]+ '\\tTS='+str(round(sbi.rr_peaks_sec[ibeat],2))+'\\tDUR='+str(sbi.rri_dur[ibeat]))\n","            #============================================================\n","            sg_resamp = scsig.resample(sg,v_dimC)\n","            #pk_resamp = round(pk*( len(sg_resamp)/(len(sg) ))) #<<------ peak value not required now\n","            beat_duration = sbi.rri_dur[ibeat]\n","            beat_label = sbi.rr_int_labels[ibeat]\n","\n","            a_resamp = np.hstack((beat_label,beat_duration,sg_resamp)) \n","            all_beats = np.vstack((all_beats, a_resamp)) # done now save it   \n","\n","\n","        sel_replace = False\n","        if nos_rep<len(all_beats):\n","            sel_replace=True\n","\n","        a = np.arange(0,nos_rep) \n","        npy_rep_sel = npy_rep[np.random.choice( a, size=len(all_beats), replace=sel_replace, p=None )]\n","\n","        rec_input = np.zeros((0,1+v_dimC+1+v_dimC+1))\n","        for rs in range(0,len(all_beats)):\n","            rr = npy_rep_sel[rs]\n","            ss = all_beats[rs]\n","\n","            #input_N = rr[4:4+v_dimC]  #<<------- mean representaion\n","            input_N = rr[-v_dimC:]  #<<------- median representaion\n","            \n","            #input_N_dur = rr[1]/BASIC_SRATE  #<<----------- max_duration of episode\n","            input_N_dur = rr[2]  #<<----------- avg_duration of episode\n","        \n","            input_label = ss[0] #<<----- label\n","            \n","            input_C = ss[-v_dimC:] #<<----- resampled signal\n","            \n","            input_C_dur = ss[1] #<<----- orginal duration of beat in seconds\n","            \n","            \n","            final_input = np.hstack((\n","                                    input_label,\n","                                    input_N,\n","                                    input_N_dur,\n","                                    input_C,\n","                                    input_C_dur\n","                                    ))\n","            \n","            rec_input = np.vstack((rec_input,final_input))\n","        \n","        rst+=str(len(rec_input))\n","        print(rst)\n","        mega_input = np.vstack((mega_input,rec_input))\n","\n","np.save(ds_path,mega_input)\n","print('saved at '+ str(ds_path))\n","print('Done! Final Input shape:'+ str(mega_input.shape))\n","timestamp_dur = datetime.datetime.now() - timestamp_start\n","print('Elapsed time = ' + str(timestamp_dur))\n","g_SUPRESS_DATA_WARNING=False # supress 'file not found' warnings from ecg_record class"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7t_J-PRBT3TL","colab_type":"text"},"source":["## [ 7.3_Compile_Testing_Set_Class ]"]},{"cell_type":"code","metadata":{"id":"BeHBuVCzT9qs","colab_type":"code","colab":{}},"source":["#<<---------------------------------- Select save name of this dataset\n","ds_name = 'custom_set_test_1_Class_V'\n","ds_path = os.path.join(global_customdir, ds_name+'.npy') \n","\n","#<<---------------------------------- Select which working db to compile from\n","g_REP_NORM_POSTFIX = 'REP_300'\n","lim_min_rep_norms = 1\n","#<<---------------------------------- Select which working db to compile from\n","test_db = all_db\n","\n","g_SUPRESS_DATA_WARNING=True # supress 'file not found' warnings from ecg_record class\n","print('db_rec\\t#beats\\t#r\\t#stacked')\n","timestamp_start = datetime.datetime.now()\n","mega_input = np.zeros((0,1+v_dimC+1+v_dimC+1))\n","for idb in test_db.keys():\n","    #if idb!='svdb':\n","     #   continue\n","    sel_db = test_db[idb]\n","    for irec in sel_db.recs:\n","        #if irec!='865':\n","         #   continue\n","        #------------------------------------------------------------------------\n","        sel_rec = sel_db.get_record(irec)\n","        #print(sel_rec.name)\n","        #------------------------------------------------------------------------\n","        # load signal\n","        sel_sig = sel_rec.read_data(g_SIG_II_POSTFIX)\n","        rst=sel_rec.name+'\\t'\n","        #print('signal shape = ' + str(sel_sig.shape))\n","        if len(sel_sig)<1:\n","            rst+=' >>Signal cannot be loaded\\t'\n","            print(rst)\n","            continue\n","        #else:\n","        #    print(' >>Signal loaded succesfully')\n","\n","        # load beat info\n","        sbi = sel_rec.read_binfo()\n","        rst+=str(sbi.nos_rr_peaks)+'\\t'\n","\n","\n","        # first laod representative normal file\n","        \n","        npy_rep = sel_rec.read_data_temp(g_REP_NORM_POSTFIX)\n","        nos_rep = len(npy_rep)\n","\n","        # check if enough normal episodes\n","        if nos_rep<lim_min_rep_norms:\n","            rst+=' >> Not enough Representative Normals\\t'\n","            print(rst)\n","            continue\n","        else:\n","            rst+=str(nos_rep)+'\\t'\n","\n","    #----------------------------------------------------------------------------------\n","    # S = [A,a,J,S]\n","    # V = [V]\n","    # F = [F,e,j,n]\n","    # N = [N,L,R] \n","    #----------------------------------------------------------------------------------\n","        class_list = []\n","        class_query = (\n","                    #(sbi.rr_labels=='A')  |\n","                    #(sbi.rr_labels=='a')  |\n","                    #(sbi.rr_labels=='J')  |\n","                    (sbi.rr_labels=='V')  \n","                  )\n","        ##<<<<<<<<<<<<<<<<<<<<---------------[Select your query]\n","        class_list = np.where(class_query)[0]\n","    #----------------------------------------------------------------------------------\n","    #----------------------------------------------------------------------------------\n","\n","        if len(class_list)==0:\n","            rst+=' >> Not enough class beats'\n","            print(rst)\n","            continue\n","            \n","        all_beats = np.zeros((0,v_dimC+1+1))\n","        for ibeat in class_list:\n","            sg,pk = sbi.get_signal_data_var(ibeat)\n","            #============================================================\n","            #print_log('\\tbeat# '+str(ibeat) + '\\tLabel='+sbi.rr_labels[ibeat]+ '\\tTS='+str(round(sbi.rr_peaks_sec[ibeat],2))+'\\tDUR='+str(sbi.rri_dur[ibeat]))\n","            #============================================================\n","            sg_resamp = scsig.resample(sg,v_dimC)\n","            #pk_resamp = round(pk*( len(sg_resamp)/(len(sg) ))) #<<------ peak value not required now\n","            beat_duration = sbi.rri_dur[ibeat]\n","            beat_label = sbi.rr_int_labels[ibeat]\n","            #if beat_label!=1:\n","            #    print('WARNING check beat type')\n","            a_resamp = np.hstack((beat_label,beat_duration,sg_resamp)) \n","            all_beats = np.vstack((all_beats, a_resamp)) # done now save it   \n","\n","\n","        sel_replace = False\n","        if nos_rep<len(all_beats):\n","            sel_replace=True\n","\n","        a = np.arange(0,nos_rep) \n","        npy_rep_sel = npy_rep[np.random.choice( a, size=len(all_beats), replace=sel_replace, p=None )]\n","\n","        rec_input = np.zeros((0,1+v_dimC+1+v_dimC+1))\n","        for rs in range(0,len(all_beats)):\n","            rr = npy_rep_sel[rs]\n","            ss = all_beats[rs]\n","\n","            #input_N = rr[4:4+v_dimC]  #<<------- mean representaion\n","            input_N = rr[-v_dimC:]  #<<------- median representaion\n","            \n","            #input_N_dur = rr[1]/BASIC_SRATE  #<<----------- max_duration of episode\n","            input_N_dur = rr[2]  #<<----------- avg_duration of episode\n","        \n","            input_label = ss[0] #<<----- label\n","            \n","            input_C = ss[-v_dimC:] #<<----- resampled signal\n","            \n","            input_C_dur = ss[1] #<<----- orginal duration of beat in seconds\n","            \n","            \n","            final_input = np.hstack((\n","                                    input_label,\n","                                    input_N,\n","                                    input_N_dur,\n","                                    input_C,\n","                                    input_C_dur\n","                                    ))\n","            \n","            rec_input = np.vstack((rec_input,final_input))\n","        \n","        rst+=str(len(rec_input))\n","        print(rst)\n","        mega_input = np.vstack((mega_input,rec_input))\n","\n","np.save(ds_path,mega_input)\n","print('saved at '+ str(ds_path))\n","print('Done! Final Input shape:'+ str(mega_input.shape))\n","timestamp_dur = datetime.datetime.now() - timestamp_start\n","print('Elapsed time = ' + str(timestamp_dur))\n","g_SUPRESS_DATA_WARNING=False # supress 'file not found' warnings from ecg_record class"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0p69mkglC6SI","colab_type":"text"},"source":["# [ 8_MODEL_DEFINITIONS ]"]},{"cell_type":"code","metadata":{"id":"gTwyzAsLC_EN","colab_type":"code","colab":{}},"source":["'''\n","Imports\n","'''\n","import tensorflow as tf\n","from tensorflow.keras.layers import Dense, Input, LSTM, Conv1D, MaxPooling1D, Flatten\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow import keras\n","from tensorflow.keras.utils import to_categorical\n","import tensorflow.keras.backend as kbend\n","\n","'''\n","Callbacks\n","'''\n","cb_esr = tf.keras.callbacks.EarlyStopping(\n","        monitor='accuracy', \n","        min_delta=0.00001, \n","        patience=2, \n","        verbose=0, \n","        mode='auto', \n","        baseline=None, \n","        restore_best_weights=False)\n","cb_listr=[cb_esr] \n","\n","\"\"\"\n","MODEL\n","\n","\"\"\"\n","m_cost = 'sparse_categorical_crossentropy'\n","m_opt = 'rmsprop'\n","\n","def model_01(print_summary, input_shape_N, input_shape_C, fl_filters, nos_output):\n","    \n","    # NORMAL Input  +++++++++++++++++++++++++++++++++++++++++++++++++++++\n","    \n","    input_N = Input( shape=input_shape_N, name = \"input_N\" )\n","    input_N_dur = Input( shape=(1,), name = \"input_N_dur\" ) \n","    # NORMAL Feature extract +++++++++++++++++++++++++++++++++++++++++++++++++++++\n","    \n","    conv_N_1 =           Conv1D(30,                #filters, \n","                          fl_filters,          #kernel_size, \n","                          strides=1, \n","                          padding='valid', \n","                          data_format='channels_last', \n","                          dilation_rate=1, \n","                          activation=tf.nn.leaky_relu, \n","                          use_bias=True, \n","                          kernel_initializer='glorot_uniform', \n","                          bias_initializer='zeros', \n","                          kernel_regularizer=None, \n","                          bias_regularizer=None, \n","                          activity_regularizer=None, \n","                          kernel_constraint=None, \n","                          bias_constraint=None,\n","                          name = 'conv_N_1') (input_N) \n","    \n","    pool_N_2 =          MaxPooling1D(pool_size=2, \n","                                  strides=None, \n","                                  padding='valid', \n","                                  data_format='channels_last',\n","                                  name = 'pool_N_2') (conv_N_1)\n","    \n","    conv_N_3 =           Conv1D(20,                #filters, \n","                          3,                  #kernel_size, \n","                          strides=1, \n","                          padding='valid', \n","                          data_format='channels_last', \n","                          dilation_rate=1, \n","                          activation=tf.nn.leaky_relu, \n","                          use_bias=True, \n","                          kernel_initializer='glorot_uniform', \n","                          bias_initializer='zeros', \n","                          kernel_regularizer=None, \n","                          bias_regularizer=None, \n","                          activity_regularizer=None, \n","                          kernel_constraint=None, \n","                          bias_constraint=None,\n","                          name = 'conv_N_3')(pool_N_2)\n","    \n","    pool_N_4 =          MaxPooling1D(pool_size=2, \n","                                  strides=None, \n","                                  padding='valid', \n","                                  data_format='channels_last',\n","                                  name = 'pool_N_4') (conv_N_3)\n","    \n","    conv_N_5 =          Conv1D(10,                #filters, \n","                          3,                  #kernel_size, \n","                          strides=1, \n","                          padding='valid', \n","                          data_format='channels_last', \n","                          dilation_rate=1, \n","                          activation=tf.nn.leaky_relu, \n","                          use_bias=True, \n","                          kernel_initializer='glorot_uniform', \n","                          bias_initializer='zeros', \n","                          kernel_regularizer=None, \n","                          bias_regularizer=None, \n","                          activity_regularizer=None, \n","                          kernel_constraint=None, \n","                          bias_constraint=None,\n","                          name = 'conv_N_5') (pool_N_4)\n","    \n","    pool_N_6 =          MaxPooling1D(pool_size=2, \n","                                  strides=None, \n","                                  padding='valid', \n","                                  data_format='channels_last',\n","                                  name = 'pool_N_6') (conv_N_5)\n","    \n","    # NORMAL Resgression  +++++++++++++++++++++++++++++++++++++++++++++++++++++\n","    \n","    flat_N_7 = Flatten(data_format=None,name = 'flat_N_7') (pool_N_6)\n","    \n","    den_Ndur_concat =  tf.concat([flat_N_7, input_N_dur],axis=1, name = \"den_Ndur_concat\")\n","\n","    #den_N_8 =       Dense(20, \n","    #                activation=tf.nn.leaky_relu, \n","    #                name = \"dense_N\") (den_Ndur_concat)\n","\n","    \n","\n","    # DENSE Regression +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","\n","    #denN_01 = Dense(20, activation=tf.nn.relu, name = \"DENSE_N_01\")(den_N_8)\n","    \n","    #denN_02 = Dense(10, activation=tf.nn.relu, name = \"DENSE_N_02\")(denN_01)\n","\n","#------------------------------------------------------------------------------\n","\n","    # COMPAR Input  +++++++++++++++++++++++++++++++++++++++++++++++++++++\n","    \n","    input_C = Input( shape=input_shape_C, name = \"input_C\" )\n","    input_C_dur = Input( shape=(1,), name = \"input_C_dur\" ) \n","    # NORMAL Feature extract +++++++++++++++++++++++++++++++++++++++++++++++++++++\n","    \n","    conv_C_1 =           Conv1D(30,                #filters, \n","                          fl_filters,          #kernel_size, \n","                          strides=1, \n","                          padding='valid', \n","                          data_format='channels_last', \n","                          dilation_rate=1, \n","                          activation=tf.nn.leaky_relu, \n","                          use_bias=True, \n","                          kernel_initializer='glorot_uniform', \n","                          bias_initializer='zeros', \n","                          kernel_regularizer=None, \n","                          bias_regularizer=None, \n","                          activity_regularizer=None, \n","                          kernel_constraint=None, \n","                          bias_constraint=None,\n","                          name = 'conv_C_1') (input_C) \n","    \n","    pool_C_2 =          MaxPooling1D(pool_size=2, \n","                                  strides=None, \n","                                  padding='valid', \n","                                  data_format='channels_last',\n","                                  name = 'pool_C_2') (conv_C_1)\n","    \n","    conv_C_3 =           Conv1D(20,                #filters, \n","                          3,                  #kernel_size, \n","                          strides=1, \n","                          padding='valid', \n","                          data_format='channels_last', \n","                          dilation_rate=1, \n","                          activation=tf.nn.leaky_relu, \n","                          use_bias=True, \n","                          kernel_initializer='glorot_uniform', \n","                          bias_initializer='zeros', \n","                          kernel_regularizer=None, \n","                          bias_regularizer=None, \n","                          activity_regularizer=None, \n","                          kernel_constraint=None, \n","                          bias_constraint=None,\n","                          name = 'conv_C_3')(pool_C_2)\n","    \n","    pool_C_4 =          MaxPooling1D(pool_size=2, \n","                                  strides=None, \n","                                  padding='valid', \n","                                  data_format='channels_last',\n","                                  name = 'pool_C_4') (conv_C_3)\n","    \n","    conv_C_5 =          Conv1D(10,                #filters, \n","                          3,                  #kernel_size, \n","                          strides=1, \n","                          padding='valid', \n","                          data_format='channels_last', \n","                          dilation_rate=1, \n","                          activation=tf.nn.leaky_relu, \n","                          use_bias=True, \n","                          kernel_initializer='glorot_uniform', \n","                          bias_initializer='zeros', \n","                          kernel_regularizer=None, \n","                          bias_regularizer=None, \n","                          activity_regularizer=None, \n","                          kernel_constraint=None, \n","                          bias_constraint=None,\n","                          name = 'conv_C_5') (pool_C_4)\n","    \n","    pool_C_6 =          MaxPooling1D(pool_size=2, \n","                                  strides=None, \n","                                  padding='valid', \n","                                  data_format='channels_last',\n","                                  name = 'pool_C_6') (conv_C_5)\n","    \n","    # NORMAL Resgression  +++++++++++++++++++++++++++++++++++++++++++++++++++++\n","    \n","    flat_C_7 = Flatten(data_format=None,name = 'flat_C_7') (pool_C_6)\n","    \n","    den_Cdur_concat =  tf.concat([flat_C_7, input_C_dur],axis=1, name = \"den_Cdur_concat\")\n","\n","    #den_C_8 =       Dense(20, \n","    #                activation=tf.nn.leaky_relu, \n","    #                name = \"dense_C\") (den_Cdur_concat)\n","\n","    \n","\n","    # DENSE Regression +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","\n","    #denC_01 = Dense(20, activation=tf.nn.relu, name = \"DENSE_C_01\")(den_C_8)\n","    \n","    #denC_02 = Dense(10, activation=tf.nn.relu, name = \"DENSE_C_02\")(denC_01)\n","\n","#------------------------------------------------------------------------------\n","# N C Concat +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","\n","    den_NC_concat =  tf.concat([den_Ndur_concat, den_Cdur_concat],axis=1, name = \"den_NC_concat\")\n","#------------------------------------------------------------------------------\n","    # DENSE Regression +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","\n","    den_NC_01 = Dense(20, activation=tf.nn.relu, name = \"den_NC_01\")(den_NC_concat)\n","    \n","    den_NC_02 = Dense(10, activation=tf.nn.relu, name = \"den_NC_02\")(den_NC_01)  \n","    \n","# OUTPUT  +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","\n","    den_out = Dense(nos_output, activation=tf.nn.softmax, name = \"den_out\")(den_NC_02)\n","\n","# =============================================================================\n","    \n","    model=Model(inputs=[input_N, input_N_dur,input_C, input_C_dur], outputs=den_out)\n","\n","    model.compile(\n","                  loss=m_cost, \n","                  optimizer=m_opt, \n","                  metrics=['accuracy']\n","                  )\n","    \n","    if print_summary:\n","        print(model.summary())\n","    return model\n","#==============================================================================\n","\n","#=========================================================================================================================\n","#======================= NEURAL NETWORK PERFORMANCE MEASURES\n","#=========================================================================================================================\n","# 3.3 :: define performance evaluation functions\n","\n","def get_performance(conf_matrix):\n","    #how many classes? = len of conf_matril\n","    nos_class = len(conf_matrix[0,:]) # len of 0th row\n","    res = np.zeros((0,8),dtype ='float64')\n","    for i in range(0,nos_class):\n","        # for each class calculate 4 performance measure - ACC, PRE, SEN, SPF, \n","        # first compute TP, TN, FP, FN\n","        TP = conf_matrix[i,i]\n","        FP = np.sum(conf_matrix[:,i]) - TP\n","        FN = np.sum(conf_matrix[i,:]) - TP\n","        TN = np.sum(conf_matrix) - FN - FP - TP\n","\n","        ACC = (TP+TN)   /   (TP+FP+FN+TN)\n","        PRE = (TP)      /   (TP+FP)\n","        SEN = (TP)      /   (TP+FN)\n","        SPF = (TN)      /   (TN+FP)\n","\n","        res_i = np.array([TP, FN, FP, TN, ACC, PRE, SEN, SPF])\n","        res = np.vstack((res,res_i))\n","    return res\n","\n","\n","#------------------------------------------------------------------PRINTING\n","\n","def print_lstr(class_labels):\n","    g_LSTR=''   # HEADER ROW for printing confusing matrix\n","    for i in range(0,len(class_labels)):\n","        g_LSTR+='\\t'+str(class_labels[i])\n","    return  g_LSTR\n","\n","def print_cf_row(cf_row,nos_labels):\n","    res = ''\n","    for j in range(0,nos_labels):\n","        res += '\\t'+ str(cf_row[j])\n","    return res\n","def print_conf_matrix(conf_matrix, suffix, class_labels):\n","    res=(suffix+'A\\\\P' + print_lstr(class_labels)+'\\n')\n","    nos_l=len(class_labels)\n","    for i in range(0,nos_l):\n","        res+=(suffix+str(class_labels[i]) + print_cf_row(conf_matrix[i],nos_l )+'\\n')\n","    return res\n","def print_performance(perf_measures, class_labels):\n","    nos_class = len(perf_measures[:,0])\n","    print('Performance for '+str(nos_class)+' classes')\n","    print ('Class\\tACC\\tPRE\\tSEN\\tSPF')\n","    for i in range(0, nos_class):\n","        perf_i = np.round(perf_measures [i,:],2)\n","        #print('\\tT.P : '+str(perf_i[0])+'\\tF.N : '+str(perf_i[1]))\n","        #print('\\tF.P : '+str(perf_i[2])+'\\tT.N : '+str(perf_i[3]))\n","        print(str(class_labels[i])+'\\t'+str(perf_i[4])+'\\t'+str(perf_i[5])+'\\t'+str(perf_i[6])+'\\t'+str(perf_i[7]))\n","    return\n","#------------------------------------------------------------------\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G0hh1UMkDHV4","colab_type":"text"},"source":["# [ 9_EXPERIMENT ]"]},{"cell_type":"code","metadata":{"id":"m43lXiJ2DaNr","colab_type":"code","colab":{}},"source":["# list avaialble datasets\n","ls_datasets = os.listdir(global_customdir)\n","print('Available Datasets:')\n","for ds_i in ls_datasets:\n","    print(ds_i)\n","print('--------------------------')\n","\n","# list available models\n","ls_models = os.listdir(global_modeldir)\n","print('Available Models:')\n","for ms_i in ls_models:\n","    print(ms_i)\n","print('--------------------------')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J_tvzyc0DPGi","colab_type":"text"},"source":["## [ 9.1_TRAINING ]"]},{"cell_type":"code","metadata":{"id":"yQqZiuL4DLEt","colab_type":"code","colab":{}},"source":["# Training\n","##<---------------------------------------------- \n","ds_name = 'custom_set_3'    # SELECT DATASET FOR LOADING TRAINING DATA FROM\n","ds_model = 'model_3'       # SELECT NAME FOR SAVING MODEL WEIGHTS\n","##<----------------------------------------------\n","\n","\n","ds_path = os.path.join(global_customdir, ds_name+'.npy') \n","megaset = np.load(ds_path)    \n","print('Loaded data from '+ str(ds_path)+'\\nShape='+str(megaset.shape))\n","\n","\n","\n","# Training data structure\n","    # input_label,      0 \n","    # input_N,          1:1+v_dimC\n","    # input_N_dur,      1+v_dimC:1+v_dimC+1\n","    # input_C,          1+v_dimC+1:1+v_dimC+1+v_dimC\n","    # input_C_dur       1+v_dimC+1+v_dimC:1+v_dimC+1+v_dimC+1\n","    \n","x_labels = megaset[:,0]\n","x_norm = np.expand_dims(megaset[:,1:1+v_dimC], axis=2) \n","x_norm_dur = megaset[:,1+v_dimC:1+v_dimC+1] #np.expand_dims(, axis=2) \n","x_comp = np.expand_dims(megaset[:,1+v_dimC+1:1+v_dimC+1+v_dimC], axis=2) \n","x_comp_dur = megaset[:,1+v_dimC+1+v_dimC:1+v_dimC+1+v_dimC+1] #np.expand_dims(, axis=2) \n","\n","data_x = [x_norm, x_norm_dur, x_comp,x_comp_dur]\n","data_y = x_labels\n","\n","# Get Model #def model_01(print_summary, input_shape_N, fl_filters, nos_output):\n","model = model_01(True, (v_dimC,1), (v_dimC,1), 7, 2)\n","\n","# Start Training---------------------------------------------------------\n","timestamp_start = datetime.datetime.now()\n","\n","history = model.fit(\n","                    data_x, data_y,\n","                    batch_size=1000,\n","                    epochs=300,\n","                    callbacks=cb_listr,\n","                    #validation_data=([alle_m.reshape((elen,timesteps,1)),alle_t],alle_l),\n","                    shuffle=True,\n","                    verbose=1)\n","\n","timestamp_dur = datetime.datetime.now() - timestamp_start\n","print('Elapsed time = ' + str(timestamp_dur))\n","# End Training---------------------------------------------------------\n","\n","ff=0\n","plt.figure(ff)\n","ff+=1\n","plt.title('ACC: '+ds_name)\n","plt.plot(history.history['accuracy'],color='green')\n","plt.show()\n","\n","plt.figure(ff)\n","ff+=1\n","plt.title('LOSS: '+ds_name)\n","plt.plot(history.history['loss'],color='red')\n","plt.show()\n","\n","\n","# save this model\n","save_model_name = ds_model +'.h5'        # save model weights to this file\n","svmpth = os.path.join(global_modeldir, save_model_name)\n","model.save_weights(svmpth)\n","print('Saved Model Weights at : '+ str(svmpth))\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8C8ll-k7FPXK","colab_type":"text"},"source":["## [ 9.2_TESTING ]"]},{"cell_type":"code","metadata":{"id":"ALKb9XlJFVCz","colab_type":"code","colab":{}},"source":["# Testing\n","##<---------------------------------------------- \n","ds_name = 'custom_set_test_1'    # SELECT DATASET FOR LOADING TESTING DATA FROM\n","ds_model = 'model_1'       # SELECT MODEL WEIGHTS TO TEST UPON\n","##<----------------------------------------------\n","\n","ds_path = os.path.join(global_customdir, ds_name+'.npy') \n","megaset = np.load(ds_path)    \n","print('Loaded data from '+ str(ds_path)+'\\nShape='+str(megaset.shape))\n","\n","# Testing data structure\n","    # input_label,      0 \n","    # input_N,          1:1+v_dimC\n","    # input_N_dur,      1+v_dimC:1+v_dimC+1\n","    # input_C,          1+v_dimC+1:1+v_dimC+1+v_dimC\n","    # input_C_dur       1+v_dimC+1+v_dimC:1+v_dimC+1+v_dimC+1\n","    \n","x_labels = megaset[:,0]\n","x_norm = np.expand_dims(megaset[:,1:1+v_dimC], axis=2) \n","x_norm_dur = megaset[:,1+v_dimC:1+v_dimC+1] #np.expand_dims(, axis=2) \n","x_comp = np.expand_dims(megaset[:,1+v_dimC+1:1+v_dimC+1+v_dimC], axis=2) \n","x_comp_dur = megaset[:,1+v_dimC+1+v_dimC:1+v_dimC+1+v_dimC+1] #np.expand_dims(, axis=2) \n","\n","data_x = [x_norm, x_norm_dur, x_comp,x_comp_dur]\n","data_y = x_labels\n","\n","# Get Model #def model_01(print_summary, input_shape_N, fl_filters, nos_output):\n","model = model_01(False, (v_dimC,1), (v_dimC,1), 7, 2)\n","load_model_name = ds_model+ '.h5'     # model used for testing\n","load_model_path = os.path.join(global_modeldir, load_model_name)\n","model.load_weights(load_model_path)\n","print('Loaded Model weights '+ str(load_model_path))\n","#-------------------------------------------------------------------------------------------------------\n","# #evla = model.evaluate( data_x, data_y ) data_med med_rep\n","# #print(evla)\n","#-------------------------------------------------------------------------------------------------------\n","\n","# manual prediction\n","print('Manual Prediction on : ' + ds_name)\n","predx = model.predict( data_x ) # array of  samples x classes(4) - each row is a prediction of sample\n","cmx_global = np.zeros((len(g_LABELS),len(g_LABELS)),dtype='int32')\n","cmx2_global = predx.argmax(axis=1)\n","for i in range(0,len(cmx2_global)):\n","    alabel = int(data_y[i])\n","    plabel = cmx2_global[i]\n","    cmx_global[alabel,plabel]+=1\n","print('\\tConfusion Matrix')\n","print(print_conf_matrix( cmx_global,'', g_LABELS)) #logit('\\t'+str(cmx))\n","print_performance( get_performance(cmx_global) ,g_LABELS ) \n","#------------------------------------------------------------"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nqqVTqwK3v74","colab_type":"text"},"source":["## [ 9.3_RECORD_TESTING ]"]},{"cell_type":"code","metadata":{"id":"BNhE5W4W5xAb","colab_type":"code","colab":{}},"source":["test_db = all_db        #<<---- db dict to read ecg data\n","\n","idb = 'incartdb'           #<<---- ecg_db\n","irec = 'I33'            #<<---- ecg_record\n","\n","sel_db = test_db[idb]\n","sel_rec = sel_db.get_record(irec)\n","\n","# load beat info\n","sbi = sel_rec.read_binfo()\n","print('Total beats = '+str(sbi.nos_rr_peaks))\n","\n","# load signal\n","sel_sig = sel_rec.read_data(g_SIG_II_POSTFIX)\n","if len(sel_sig)<1:\n","    print('Signal cannot be loaded')\n","else:\n","    print('Signal loaded succesfully')\n","\n","#<<---------------------------------- Select save name of this dataset\n","ds_name = 'rec_test_'+idb+'_'+irec\n","ds_path = os.path.join(global_customdir, ds_name+'.npy') "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nJY18S_K7esh","colab_type":"text"},"source":["### [ 9.3.1_Compile_Test_Set ]"]},{"cell_type":"code","metadata":{"id":"VtWdu0BT31K0","colab_type":"code","colab":{}},"source":["\n","#<<---------------------------------- Select which representative normal to use\n","g_REP_NORM_POSTFIX = 'REP_300'\n","lim_min_rep_norms = 1\n","\n","\n","timestamp_start = datetime.datetime.now()\n","print('db_rec\\t#beats\\t#r\\t#stacked')\n","\n","rst=sel_rec.name+'\\t'\n","if len(sel_sig)<1:\n","    rst+=' >>Signal cannot be loaded\\t'\n","    print(rst)\n","else:\n","    rst+=str(sbi.nos_rr_peaks)+'\\t'\n","\n","    # first laod representative normal file\n","    npy_rep = sel_rec.read_data_temp(g_REP_NORM_POSTFIX)\n","    nos_rep = len(npy_rep)\n","\n","    # check if enough normal episodes\n","    if nos_rep<lim_min_rep_norms:\n","        rst+=' >> Not enough Representative Normals\\t'\n","        print(rst)\n","    else:\n","        rst+=str(nos_rep)+'\\t'\n","\n","        all_beats = np.zeros((0,1+v_dimC+1))\n","        for ibeat in range(0,sbi.nos_rr_peaks):\n","            sg,pk = sbi.get_signal_data_var(ibeat)\n","            #============================================================\n","            #print('\\tbeat# '+str(ibeat) + '\\tLabel='+sbi.rr_labels[ibeat]+ '\\tTS='+str(round(sbi.rr_peaks_sec[ibeat],2))+'\\tDUR='+str(sbi.rri_dur[ibeat]))\n","            #============================================================\n","            sg_resamp = scsig.resample(sg,v_dimC)\n","            #pk_resamp = round(pk*( len(sg_resamp)/(len(sg) ))) #<<------ peak value not required now\n","            beat_duration = sbi.rri_dur[ibeat]\n","            beat_label = sbi.rr_int_labels[ibeat]\n","\n","            #beat_index = ibeat              #<<----- for identifying beat later on <<--- NO NEED FOR THIS\n","\n","            a_resamp = np.hstack((beat_label,beat_duration,sg_resamp)) \n","            all_beats = np.vstack((all_beats, a_resamp)) # done now save it   \n","\n","\n","        sel_replace = False\n","        if nos_rep<len(all_beats):\n","            sel_replace=True\n","\n","        a = np.arange(0,nos_rep) \n","        npy_rep_sel = npy_rep[np.random.choice( a, size=len(all_beats), replace=sel_replace, p=None )]\n","\n","        rec_input = np.zeros((0,1+v_dimC+1+v_dimC+1))\n","        for rs in range(0,len(all_beats)): \n","            \n","            rr = npy_rep_sel[rs]\n","            ss = all_beats[rs]\n","            # NOTE:beat_identifier has been stacked at the begin, shift index in ss by +1 <<--- NO NEED FOR THIS\n","\n","            #input_N = rr[4:4+v_dimC]  #<<------- mean representaion\n","            input_N = rr[-v_dimC:]  #<<------- median representaion\n","            \n","            #input_N_dur = rr[1]/BASIC_SRATE  #<<----------- max_duration of episode\n","            input_N_dur = rr[2]  #<<----------- avg_duration of episode\n","\n","            input_label = ss[0] #<<----- label\n","            \n","            input_C = ss[-v_dimC:] #<<----- resampled signal\n","            \n","            input_C_dur = ss[1] #<<----- orginal duration of beat in seconds\n","            \n","            #input_beat_id = ss[0]   #<<----------- identifier for beat in binfo class <<-- NO NEED FOR THIS\n","            \n","            final_input = np.hstack((\n","                                    input_label,\n","                                    input_N,\n","                                    input_N_dur,\n","                                    input_C,\n","                                    input_C_dur,\n","                                    #input_beat_id  # <<-- NO NEED FOR THIS\n","                                    ))\n","            \n","            rec_input = np.vstack((rec_input,final_input))\n","\n","        rst+=str(len(rec_input))\n","        print(rst)\n","        \n","\n","        np.save(ds_path,rec_input)\n","        print('saved at '+ str(ds_path))\n","        print('Done! Final Input shape:'+ str(rec_input.shape))\n","\n","timestamp_dur = datetime.datetime.now() - timestamp_start\n","print('Elapsed time = ' + str(timestamp_dur))\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"za_5p0jY-AGy","colab_type":"text"},"source":["### [ 9.4.2_Test_Record ]"]},{"cell_type":"code","metadata":{"id":"yTVNzK1m-FD6","colab_type":"code","colab":{}},"source":["# Testing\n","##<---------------------------------------------- \n","ds_model = 'model_1'       # SELECT MODEL WEIGHTS TO TEST UPON\n","##<----------------------------------------------\n","\n","megaset = np.load(ds_path)    \n","print('Loaded data from '+ str(ds_path)+'\\nShape='+str(megaset.shape))\n","\n","# Testing data structure\n","    # input_label,      0 \n","    # input_N,          1:1+v_dimC\n","    # input_N_dur,      1+v_dimC:1+v_dimC+1\n","    # input_C,          1+v_dimC+1:1+v_dimC+1+v_dimC\n","    # input_C_dur       1+v_dimC+1+v_dimC:1+v_dimC+1+v_dimC+1\n","    \n","x_labels = megaset[:,0]\n","x_norm = np.expand_dims(megaset[:,1:1+v_dimC], axis=2) \n","x_norm_dur = megaset[:,1+v_dimC:1+v_dimC+1] #np.expand_dims(, axis=2) \n","x_comp = np.expand_dims(megaset[:,1+v_dimC+1:1+v_dimC+1+v_dimC], axis=2) \n","x_comp_dur = megaset[:,1+v_dimC+1+v_dimC:1+v_dimC+1+v_dimC+1] #np.expand_dims(, axis=2) \n","\n","data_x = [x_norm, x_norm_dur, x_comp,x_comp_dur]\n","data_y = x_labels\n","\n","# Get Model #def model_01(print_summary, input_shape_N, fl_filters, nos_output):\n","model = model_01(False, (v_dimC,1), (v_dimC,1), 7, 2)\n","load_model_name = ds_model+ '.h5'     # model used for testing\n","load_model_path = os.path.join(global_modeldir, load_model_name)\n","model.load_weights(load_model_path)\n","print('Loaded Model weights '+ str(load_model_path))\n","#-------------------------------------------------------------------------------------------------------\n","# #evla = model.evaluate( data_x, data_y ) data_med med_rep\n","# #print(evla)\n","#-------------------------------------------------------------------------------------------------------\n","\n","# manual prediction\n","print('Manual Prediction on : ' + ds_name)\n","predx = model.predict( data_x ) # array of  samples x classes(4) - each row is a prediction of sample\n","cmx_global = np.zeros((len(g_LABELS),len(g_LABELS)),dtype='int32')\n","cmx2_global = predx.argmax(axis=1)\n","for i in range(0,len(cmx2_global)):\n","    alabel = int(data_y[i])\n","    plabel = cmx2_global[i]\n","    cmx_global[alabel,plabel]+=1\n","print('\\tConfusion Matrix')\n","print(print_conf_matrix( cmx_global,'', g_LABELS)) #logit('\\t'+str(cmx))\n","print_performance( get_performance(cmx_global) ,g_LABELS ) \n","#------------------------------------------------------------\n","\n","cmx_false_N = np.zeros(len(cmx2_global))\n","cmx_false_N[np.where(\n","                    (cmx2_global==0) &      #<<--- predicted Normal\n","                    (data_y==1)           #<<--- actually Abnormal\n","                    )[0]]=-1\n","\n","cmx_false_A = np.zeros(len(cmx2_global))\n","cmx_false_A[np.where(\n","                    (cmx2_global==1)   &    #<<--- predicted abnorm\n","                    (data_y==0)           #<<--- actually norm\n","                    )[0]]=-1\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vcMPde5K-3nr","colab_type":"text"},"source":["### [ 9.4.3_Plot_Test_Results ]"]},{"cell_type":"code","metadata":{"id":"Xb43sUjE-2xm","colab_type":"code","colab":{}},"source":["# plot signal segments\n","\n","#<<---------------------------------------------Select Paper Resolution\n","x_scale = 25 * 0.0393701 # mm/sec -> inches/sec\n","y_scale = 10 * 0.0393701 # mm/mV -> inches/sec\n","y_low = -2.5\n","y_high = 3.5\n","#<<--------------------------------------------------------------------\n","\n","#<<---------------------------------------------Select ECG Segment\n","fsec = 10+90*2\n","tsec = fsec+(90)\n","dsec = tsec - fsec\n","#<<--------------------------------------------------------------------\n","\n","\n","ff = fsec * BASIC_SRATE\n","tt = tsec * BASIC_SRATE\n","dd = tt - ff\n","\n","bps = sel_sig[ff:tt]\n","\n","dticks = sbi.rr_peaks[(sbi.rr_peaks_sec >= fsec) & (sbi.rr_peaks_sec < tsec)]\n","dlabels = sbi.rr_labels[(sbi.rr_peaks_sec >= fsec) & (sbi.rr_peaks_sec < tsec)]\n","dticks = (dticks / sel_rec.db.srate)*BASIC_SRATE - ff\n","\n","plt.figure(2, figsize = (dsec*x_scale ,(y_high-y_low) * y_scale) )\n","plt.xlim(0, len(bps))\n","plt.ylim(y_low,y_high)\n","plt.xticks(dticks,dlabels)\n","#x_grid = np.arange(0,tt-ff, 1*BASIC_SRATE)\n","#plt.xticks(x_grid)\n","plt.grid(axis='x')\n","\n","#drris = sbi.rri_delta[(sbi.rr_peaks_sec >= fsec) & (sbi.rr_peaks_sec < tsec)]\n","#drrid = sbi.rri_dur[(sbi.rr_peaks_sec >= fsec) & (sbi.rr_peaks_sec < tsec)]\n","# RED: rri_delta\n","#plt.scatter(dticks,drris, marker='s',color='tab:red')\n","# GREEN = Duration\n","#plt.scatter(dticks,drrid, marker='s',color='tab:green')\n","\n","dcmx2 = cmx2_global[(sbi.rr_peaks_sec >= fsec) & (sbi.rr_peaks_sec < tsec)] \n","dfalseN = cmx_false_N[(sbi.rr_peaks_sec >= fsec) & (sbi.rr_peaks_sec < tsec)] \n","dfalseA = cmx_false_A[(sbi.rr_peaks_sec >= fsec) & (sbi.rr_peaks_sec < tsec)] \n","# RED: Abnormal\n","plt.scatter(dticks[dcmx2==1],dcmx2[dcmx2==1], marker='s',color='tab:red')\n","# GREEN: Normal\n","plt.scatter(dticks[dcmx2==0],dcmx2[dcmx2==0], marker='s',color='tab:green')\n","\n","# falsely prdicted as Normals, actually abnormal\n","plt.scatter(dticks[dfalseN==-1],dfalseN[dfalseN==-1], marker='x',color='tab:red')\n","\n","# falsely predicted as Abnormals, actually normal\n","plt.scatter(dticks[dfalseA==-1],dfalseA[dfalseA==-1], marker='x',color='tab:green')\n","\n","plt.plot(bps, linewidth=0.5, color='black')\n","plt.hlines(0,0,len(bps), linewidth=0.3)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"epuvg6vya4NN","colab_type":"text"},"source":["# [FINAL_LOG]"]},{"cell_type":"markdown","metadata":{"id":"tbIdUK-wbYMQ","colab_type":"text"},"source":["## Rep_normal_30min"]},{"cell_type":"code","metadata":{"id":"8o23Js0Va7rv","colab_type":"code","colab":{}},"source":["'''\n","=================================================\n","Representative Normal\n","lim_delta_rri:0.04\n","lim_min_Nbeats_per_episode:3\n","lim_first_F_sec:1800\n","g_REP_II_POSTFIX:REP_1800\n","=================================================\n","REC\ttotal_beats_in_n_query\ttotal_n_episodes\tvalid_n_episodes\tResult\n","mitdb_223\t1465\t149\t114\t Success\n","mitdb_234\t2665\t20\t20\t Success\n","mitdb_113\t645\t389\t63\t Success\n","mitdb_209\t2049\t301\t216\t Success\n","mitdb_115\t858\t431\t91\t Success\n","mitdb_221\t321\t257\t10\t Success\n","mitdb_215\t2669\t318\t246\t Success\n","mitdb_114\t1077\t445\t167\t Success\n","mitdb_205\t2478\t42\t41\t Success\n","mitdb_116\t2056\t118\t105\t Success\n","mitdb_210\t642\t440\t49\t Success\n","mitdb_105\t2313\t139\t125\t Success\n","mitdb_111\t1658\t404\t261\t Success\n","mitdb_232\t4\t3\t0\t Failed\n","mitdb_122\t2388\t70\t63\t Success\n","mitdb_118\t1856\t152\t120\t Success\n","mitdb_233\t886\t459\t104\t Success\n","mitdb_124\t954\t251\t131\t Success\n","mitdb_220\t1669\t167\t113\t Success\n","mitdb_106\t539\t246\t70\t Success\n","mitdb_208\t220\t87\t31\t Success\n","mitdb_214\t1019\t431\t152\t Success\n","mitdb_219\t411\t293\t17\t Success\n","mitdb_201\t239\t180\t11\t Success\n","mitdb_103\t1639\t361\t244\t Success\n","mitdb_202\t913\t398\t87\t Success\n","mitdb_222\t581\t323\t59\t Success\n","mitdb_228\t548\t328\t51\t Success\n","mitdb_230\t1951\t246\t155\t Success\n","mitdb_213\t1834\t190\t140\t Success\n","mitdb_117\t1105\t226\t154\t Success\n","mitdb_100\t1873\t286\t196\t Success\n","mitdb_200\t450\t229\t45\t Success\n","mitdb_112\t2492\t30\t29\t Success\n","mitdb_119\t597\t222\t73\t Success\n","mitdb_109\t2180\t236\t207\t Success\n","mitdb_123\t462\t343\t28\t Success\n","mitdb_121\t1773\t75\t58\t Success\n","mitdb_203\t335\t275\t11\t Success\n","mitdb_101\t1298\t410\t188\t Success\n","mitdb_108\t828\t401\t99\t Success\n","svdb_885\t574\t265\t72\t Success\n","svdb_856\t2747\t32\t30\t Success\n","svdb_828\t1274\t224\t104\t Success\n","svdb_865\t594\t165\t64\t Success\n","svdb_874\t2069\t53\t45\t Success\n","svdb_861\t558\t281\t74\t Success\n","svdb_847\t1401\t151\t111\t Success\n","svdb_893\t618\t395\t65\t Success\n","svdb_844\t1211\t270\t147\t Success\n","svdb_822\t905\t54\t35\t Success\n","svdb_892\t199\t115\t23\t Success\n","svdb_811\t753\t328\t95\t Success\n","svdb_855\t660\t357\t93\t Success\n","svdb_867\t1571\t274\t99\t Success\n","svdb_866\t809\t129\t40\t Success\n","svdb_846\t1477\t144\t114\t Success\n","svdb_821\t1000\t442\t191\t Success\n","svdb_869\t375\t144\t45\t Success\n","svdb_879\t557\t115\t56\t Success\n","svdb_888\t1935\t119\t100\t Success\n","svdb_891\t1232\t274\t180\t Success\n","svdb_805\t1614\t210\t140\t Success\n","svdb_802\t1159\t247\t124\t Success\n","svdb_852\t1103\t361\t149\t Success\n","svdb_848\t3891\t108\t64\t Success\n","svdb_887\t1713\t215\t142\t Success\n","svdb_889\t790\t187\t91\t Success\n","svdb_801\t1687\t103\t80\t Success\n","svdb_864\t1534\t105\t95\t Success\n","svdb_873\t1353\t160\t88\t Success\n","svdb_812\t1529\t92\t73\t Success\n","svdb_859\t1431\t516\t161\t Success\n","svdb_890\t1672\t141\t103\t Success\n","svdb_804\t665\t467\t46\t Success\n","svdb_870\t442\t157\t79\t Success\n","svdb_876\t931\t290\t135\t Success\n","svdb_884\t1707\t355\t192\t Success\n","svdb_803\t1609\t155\t141\t Success\n","svdb_820\t1777\t188\t174\t Success\n","svdb_823\t1781\t155\t96\t Success\n","svdb_878\t837\t129\t73\t Success\n","svdb_858\t2133\t30\t26\t Success\n","svdb_827\t1607\t134\t78\t Success\n","svdb_875\t1757\t72\t49\t Success\n","svdb_886\t1976\t102\t90\t Success\n","svdb_868\t771\t305\t106\t Success\n","svdb_854\t303\t127\t42\t Success\n","svdb_800\t1432\t202\t100\t Success\n","svdb_877\t989\t320\t140\t Success\n","svdb_871\t1430\t227\t141\t Success\n","svdb_841\t746\t126\t58\t Success\n","svdb_851\t1307\t338\t163\t Success\n","svdb_883\t1611\t92\t71\t Success\n","svdb_809\t2412\t12\t12\t Success\n","svdb_882\t1738\t88\t53\t Success\n","svdb_810\t1662\t96\t77\t Success\n","svdb_881\t238\t66\t31\t Success\n","svdb_829\t1344\t248\t164\t Success\n","svdb_857\t1981\t142\t118\t Success\n","svdb_894\t1861\t180\t134\t Success\n","svdb_860\t226\t174\t3\t Success\n","svdb_849\t1793\t89\t56\t Success\n","svdb_824\t1634\t157\t114\t Success\n","svdb_863\t1441\t330\t194\t Success\n","svdb_862\t1904\t105\t83\t Success\n","svdb_842\t1726\t222\t140\t Success\n","svdb_806\t2825\t59\t58\t Success\n","svdb_807\t1755\t97\t66\t Success\n","svdb_880\t2278\t229\t190\t Success\n","svdb_872\t1681\t115\t107\t Success\n","svdb_843\t2559\t30\t24\t Success\n","svdb_845\t2324\t147\t43\t Success\n","svdb_853\t1560\t200\t142\t Success\n","svdb_850\t1748\t52\t41\t Success\n","svdb_840\t2089\t139\t88\t Success\n","svdb_825\t2350\t143\t122\t Success\n","svdb_808\t1691\t40\t37\t Success\n","svdb_826\t1248\t237\t146\t Success\n","incartdb_I14\t1286\t256\t122\t Success\n","incartdb_I46\t1337\t412\t153\t Success\n","incartdb_I02\t1927\t233\t136\t Success\n","incartdb_I23\t2003\t155\t120\t Success\n","incartdb_I22\t2089\t285\t175\t Success\n","incartdb_I53\t21\t5\t2\t Success\n","incartdb_I36\t2659\t253\t197\t Success\n","incartdb_I09\t2460\t204\t156\t Success\n","incartdb_I40\t2430\t23\t20\t Success\n","incartdb_I41\t554\t213\t67\t Success\n","incartdb_I55\t2098\t32\t30\t Success\n","incartdb_I39\t746\t239\t74\t Success\n","incartdb_I72\t1096\t328\t189\t Success\n","incartdb_I66\t1630\t158\t134\t Success\n","incartdb_I25\t1390\t196\t94\t Success\n","incartdb_I52\t959\t235\t93\t Success\n","incartdb_I03\t2004\t136\t110\t Success\n","incartdb_I74\t1397\t226\t125\t Success\n","incartdb_I10\t3425\t84\t71\t Success\n","incartdb_I64\t1752\t106\t94\t Success\n","incartdb_I38\t1234\t214\t162\t Success\n","incartdb_I27\t453\t168\t26\t Success\n","incartdb_I44\t434\t133\t68\t Success\n","incartdb_I68\t2148\t166\t165\t Success\n","incartdb_I19\t32\t26\t1\t Success\n","incartdb_I70\t1255\t126\t43\t Success\n","incartdb_I63\t1559\t150\t110\t Success\n","incartdb_I06\t1967\t186\t149\t Success\n","incartdb_I43\tNot enough N beats within rri limits, Skip this record\n","incartdb_I07\t2253\t159\t131\t Success\n","incartdb_I75\t324\t136\t65\t Success\n","incartdb_I67\t1265\t371\t151\t Success\n","incartdb_I28\t697\t378\t64\t Success\n","incartdb_I48\t979\t426\t120\t Success\n","incartdb_I05\t1189\t150\t103\t Success\n","incartdb_I31\t427\t201\t55\t Success\n","incartdb_I62\t1125\t175\t110\t Success\n","incartdb_I08\t1228\t115\t74\t Success\n","incartdb_I29\t720\t230\t51\t Success\n","incartdb_I49\t1143\t323\t145\t Success\n","incartdb_I33\t118\t67\t10\t Success\n","incartdb_I61\t505\t329\t37\t Success\n","incartdb_I18\t1726\t341\t108\t Success\n","incartdb_I30\t585\t218\t54\t Success\n","incartdb_I45\t368\t111\t62\t Success\n","incartdb_I42\t87\t62\t7\t Success\n","incartdb_I37\t1225\t291\t111\t Success\n","incartdb_I20\t1704\t223\t157\t Success\n","incartdb_I24\t2411\t122\t102\t Success\n","incartdb_I21\t1592\t165\t122\t Success\n","incartdb_I60\t2173\t124\t75\t Success\n","incartdb_I04\t1900\t165\t82\t Success\n","incartdb_I12\t2742\t47\t43\t Success\n","incartdb_I15\t2534\t72\t61\t Success\n","incartdb_I73\t1682\t79\t62\t Success\n","incartdb_I13\t1021\t207\t100\t Success\n","incartdb_I47\t687\t329\t82\t Success\n","incartdb_I01\t1706\t289\t157\t Success\n","incartdb_I51\t1020\t46\t32\t Success\n","incartdb_I58\t2270\t27\t25\t Success\n","incartdb_I17\t1427\t143\t116\t Success\n","incartdb_I71\t1100\t186\t79\t Success\n","incartdb_I34\t334\t106\t38\t Success\n","incartdb_I59\t1327\t219\t37\t Success\n","incartdb_I57\t2777\t33\t30\t Success\n","incartdb_I69\t1653\t174\t147\t Success\n","incartdb_I11\t1254\t236\t136\t Success\n","incartdb_I56\t1301\t235\t94\t Success\n","incartdb_I16\t1032\t300\t116\t Success\n","incartdb_I65\t1406\t245\t137\t Success\n","incartdb_I54\t2247\t58\t54\t Success\n","incartdb_I26\t1055\t288\t111\t Success\n","incartdb_I50\t1531\t453\t168\t Success\n","incartdb_I32\t871\t277\t80\t Success\n","incartdb_I35\t2333\t247\t206\t Success\n","\n","Done\n","Elapsed time = 0:05:10.778194\n","'''"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"93da-P9SbeVv","colab_type":"text"},"source":["## Rep_normal_5min"]},{"cell_type":"code","metadata":{"id":"TxuabGcgbigV","colab_type":"code","colab":{}},"source":["'''\n","=================================================\n","Representative Normal\n","lim_delta_rri:0.04\n","lim_min_Nbeats_per_episode:3\n","lim_first_F_sec:300\n","g_REP_II_POSTFIX:REP_300\n","=================================================\n","REC\ttotal_beats_in_n_query\ttotal_n_episodes\tvalid_n_episodes\tResult\n","mitdb_223\t298\t32\t21\t Success\n","mitdb_234\t458\t4\t4\t Success\n","mitdb_113\t107\t68\t11\t Success\n","mitdb_209\t413\t40\t33\t Success\n","mitdb_115\t126\t82\t12\t Success\n","mitdb_221\t38\t36\t0\t Failed\n","mitdb_215\t451\t49\t42\t Success\n","mitdb_114\t142\t74\t19\t Success\n","mitdb_205\t443\t2\t2\t Success\n","mitdb_116\t362\t8\t7\t Success\n","mitdb_210\t104\t76\t8\t Success\n","mitdb_105\t359\t31\t25\t Success\n","mitdb_111\t264\t76\t47\t Success\n","mitdb_232\tNot enough N beats within rri limits, Skip this record\n","mitdb_122\t399\t19\t15\t Success\n","mitdb_118\t301\t24\t20\t Success\n","mitdb_233\t153\t50\t25\t Success\n","mitdb_124\t147\t44\t23\t Success\n","mitdb_220\t339\t12\t10\t Success\n","mitdb_106\t113\t54\t14\t Success\n","mitdb_208\t42\t24\t7\t Success\n","mitdb_214\t182\t73\t27\t Success\n","mitdb_219\t57\t50\t0\t Failed\n","mitdb_201\t81\t60\t4\t Success\n","mitdb_103\t292\t51\t37\t Success\n","mitdb_202\t148\t75\t14\t Success\n","mitdb_222\t135\t65\t15\t Success\n","mitdb_228\t97\t66\t8\t Success\n","mitdb_230\t357\t31\t24\t Success\n","mitdb_213\t287\t22\t17\t Success\n","mitdb_117\t169\t39\t24\t Success\n","mitdb_100\t314\t41\t30\t Success\n","mitdb_200\t106\t45\t13\t Success\n","mitdb_112\t421\t5\t5\t Success\n","mitdb_119\t78\t33\t11\t Success\n","mitdb_109\t373\t37\t34\t Success\n","mitdb_123\t72\t54\t2\t Success\n","mitdb_121\t290\t13\t10\t Success\n","mitdb_203\t62\t52\t1\t Success\n","mitdb_101\t274\t61\t30\t Success\n","mitdb_108\t130\t66\t13\t Success\n","svdb_885\t149\t52\t17\t Success\n","svdb_856\t437\t8\t8\t Success\n","svdb_828\t81\t57\t5\t Success\n","svdb_865\t239\t33\t23\t Success\n","svdb_874\t292\t17\t15\t Success\n","svdb_861\t95\t57\t10\t Success\n","svdb_847\t275\t33\t24\t Success\n","svdb_893\t84\t67\t5\t Success\n","svdb_844\t223\t36\t25\t Success\n","svdb_822\tNot enough N beats within rri limits, Skip this record\n","svdb_892\t26\t20\t0\t Failed\n","svdb_811\t126\t60\t18\t Success\n","svdb_855\t125\t56\t14\t Success\n","svdb_867\t85\t37\t10\t Success\n","svdb_866\t286\t10\t9\t Success\n","svdb_846\t265\t20\t14\t Success\n","svdb_821\t210\t85\t37\t Success\n","svdb_869\t64\t21\t9\t Success\n","svdb_879\t41\t18\t2\t Success\n","svdb_888\t315\t22\t16\t Success\n","svdb_891\t202\t43\t28\t Success\n","svdb_805\t317\t23\t22\t Success\n","svdb_802\t257\t32\t27\t Success\n","svdb_852\t202\t85\t20\t Success\n","svdb_848\t751\t11\t7\t Success\n","svdb_887\t261\t38\t24\t Success\n","svdb_889\t208\t20\t14\t Success\n","svdb_801\t77\t20\t10\t Success\n","svdb_864\t241\t21\t17\t Success\n","svdb_873\t285\t7\t6\t Success\n","svdb_812\t182\t19\t15\t Success\n","svdb_859\t350\t96\t47\t Success\n","svdb_890\t293\t24\t22\t Success\n","svdb_804\t102\t72\t6\t Success\n","svdb_870\t109\t34\t26\t Success\n","svdb_876\t143\t50\t25\t Success\n","svdb_884\t380\t31\t23\t Success\n","svdb_803\t277\t24\t23\t Success\n","svdb_820\t287\t32\t30\t Success\n","svdb_823\t318\t24\t15\t Success\n","svdb_878\t52\t13\t6\t Success\n","svdb_858\t364\t1\t1\t Success\n","svdb_827\t277\t34\t21\t Success\n","svdb_875\t225\t29\t13\t Success\n","svdb_886\t343\t15\t13\t Success\n","svdb_868\t131\t51\t18\t Success\n","svdb_854\t19\t11\t1\t Success\n","svdb_800\t229\t32\t22\t Success\n","svdb_877\t166\t55\t25\t Success\n","svdb_871\t281\t36\t27\t Success\n","svdb_841\t264\t20\t17\t Success\n","svdb_851\t206\t76\t26\t Success\n","svdb_883\t265\t18\t10\t Success\n","svdb_809\t400\t3\t3\t Success\n","svdb_882\t307\t15\t9\t Success\n","svdb_810\t279\t14\t11\t Success\n","svdb_881\t58\t16\t7\t Success\n","svdb_829\t215\t44\t25\t Success\n","svdb_857\t300\t33\t25\t Success\n","svdb_894\t262\t44\t27\t Success\n","svdb_860\t51\t50\t0\t Failed\n","svdb_849\t326\t6\t6\t Success\n","svdb_824\t239\t29\t22\t Success\n","svdb_863\t247\t52\t32\t Success\n","svdb_862\t295\t13\t11\t Success\n","svdb_842\t317\t27\t16\t Success\n","svdb_806\t472\t9\t9\t Success\n","svdb_807\t341\t7\t7\t Success\n","svdb_880\t268\t62\t43\t Success\n","svdb_872\t283\t21\t18\t Success\n","svdb_843\t466\t3\t3\t Success\n","svdb_845\t431\t8\t7\t Success\n","svdb_853\t281\t26\t20\t Success\n","svdb_850\t317\t6\t5\t Success\n","svdb_840\t342\t24\t13\t Success\n","svdb_825\t327\t47\t39\t Success\n","svdb_808\t302\t7\t7\t Success\n","svdb_826\t200\t45\t30\t Success\n","incartdb_I14\t148\t55\t17\t Success\n","incartdb_I46\t145\t58\t33\t Success\n","incartdb_I02\t339\t40\t35\t Success\n","incartdb_I23\t283\t35\t23\t Success\n","incartdb_I22\t345\t29\t26\t Success\n","incartdb_I53\tNot enough N beats within rri limits, Skip this record\n","incartdb_I36\t678\t25\t22\t Success\n","incartdb_I09\t363\t31\t27\t Success\n","incartdb_I40\t381\t6\t5\t Success\n","incartdb_I41\t38\t24\t2\t Success\n","incartdb_I55\t371\t4\t4\t Success\n","incartdb_I39\t216\t27\t16\t Success\n","incartdb_I72\t200\t61\t45\t Success\n","incartdb_I66\t203\t34\t32\t Success\n","incartdb_I25\t254\t32\t19\t Success\n","incartdb_I52\t78\t36\t9\t Success\n","incartdb_I03\t368\t12\t12\t Success\n","incartdb_I74\t303\t35\t19\t Success\n","incartdb_I10\t608\t6\t5\t Success\n","incartdb_I64\t302\t16\t15\t Success\n","incartdb_I38\t186\t34\t27\t Success\n","incartdb_I27\t84\t29\t6\t Success\n","incartdb_I44\t25\t10\t4\t Success\n","incartdb_I68\t363\t22\t22\t Success\n","incartdb_I19\t10\t7\t1\t Success\n","incartdb_I70\t121\t50\t15\t Success\n","incartdb_I63\t255\t35\t24\t Success\n","incartdb_I06\t313\t32\t26\t Success\n","incartdb_I43\tNot enough N beats within rri limits, Skip this record\n","incartdb_I07\t322\t33\t27\t Success\n","incartdb_I75\t46\t15\t13\t Success\n","incartdb_I67\t182\t58\t22\t Success\n","incartdb_I28\t121\t62\t9\t Success\n","incartdb_I48\t183\t54\t22\t Success\n","incartdb_I05\t200\t29\t19\t Success\n","incartdb_I31\t187\t68\t27\t Success\n","incartdb_I62\t211\t38\t23\t Success\n","incartdb_I08\t225\t16\t11\t Success\n","incartdb_I29\t51\t24\t7\t Success\n","incartdb_I49\t182\t54\t24\t Success\n","incartdb_I33\t22\t9\t2\t Success\n","incartdb_I61\t95\t60\t7\t Success\n","incartdb_I18\t211\t79\t18\t Success\n","incartdb_I30\t76\t27\t7\t Success\n","incartdb_I45\t40\t11\t8\t Success\n","incartdb_I42\tNot enough N beats within rri limits, Skip this record\n","incartdb_I37\t208\t41\t18\t Success\n","incartdb_I20\t178\t30\t16\t Success\n","incartdb_I24\t474\t15\t11\t Success\n","incartdb_I21\t249\t27\t20\t Success\n","incartdb_I60\t219\t49\t27\t Success\n","incartdb_I04\t175\t42\t22\t Success\n","incartdb_I12\t382\t20\t18\t Success\n","incartdb_I15\t408\t8\t8\t Success\n","incartdb_I73\t282\t16\t10\t Success\n","incartdb_I13\t120\t43\t16\t Success\n","incartdb_I47\t159\t66\t25\t Success\n","incartdb_I01\t227\t48\t19\t Success\n","incartdb_I51\tNot enough N beats within rri limits, Skip this record\n","incartdb_I58\t354\t6\t6\t Success\n","incartdb_I17\t225\t26\t21\t Success\n","incartdb_I71\t240\t7\t7\t Success\n","incartdb_I34\t173\t40\t19\t Success\n","incartdb_I59\t64\t58\t1\t Success\n","incartdb_I57\t460\t10\t8\t Success\n","incartdb_I69\t268\t34\t28\t Success\n","incartdb_I11\t114\t38\t11\t Success\n","incartdb_I56\t237\t57\t24\t Success\n","incartdb_I16\t144\t42\t14\t Success\n","incartdb_I65\t166\t50\t22\t Success\n","incartdb_I54\t345\t5\t4\t Success\n","incartdb_I26\t162\t51\t18\t Success\n","incartdb_I50\t280\t68\t25\t Success\n","incartdb_I32\t110\t51\t12\t Success\n","incartdb_I35\t346\t30\t21\t Success\n","\n","Done\n","Elapsed time = 0:00:54.177747\n","'''"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t_8RvQ9D8lfg","colab_type":"text"},"source":["##test on set1"]},{"cell_type":"code","metadata":{"id":"xdmQebkN8rXK","colab_type":"code","colab":{}},"source":["'''\n","Loaded data from /content/drive/My Drive/Masters/workdir/ecg_data/db_dataset/custom_ds/custom_set_test_1.npy\n","Shape=(165394, 771)\n","Loaded Model weights /content/drive/My Drive/Masters/workdir/ecg_data/db_model/model_3.h5\n","Manual Prediction on : custom_set_test_1\n","\tConfusion Matrix\n","A\\P\tN\tX\n","N\t123115\t24579\n","X\t841\t16859\n","\n","Performance for 2 classes\n","Class\tACC\tPRE\tSEN\tSPF\n","N\t0.85\t0.99\t0.83\t0.95\n","X\t0.85\t0.41\t0.95\t0.83\n","\n","Loaded Model weights /content/drive/My Drive/Masters/workdir/ecg_data/db_model/model_2.h5\n","Manual Prediction on : custom_set_test_1\n","\tConfusion Matrix\n","A\\P\tN\tX\n","N\t119042\t28652\n","X\t527\t17173\n","\n","Performance for 2 classes\n","Class\tACC\tPRE\tSEN\tSPF\n","N\t0.82\t1.0\t0.81\t0.97\n","X\t0.82\t0.37\t0.97\t0.81\n","\n","Loaded data from /content/drive/My Drive/Masters/workdir/ecg_data/db_dataset/custom_ds/custom_set_test_1.npy\n","Shape=(165394, 771)\n","Loaded Model weights /content/drive/My Drive/Masters/workdir/ecg_data/db_model/model_1.h5\n","Manual Prediction on : custom_set_test_1\n","\tConfusion Matrix\n","A\\P\tN\tX\n","N\t124186\t23508\n","X\t733\t16967\n","\n","Performance for 2 classes\n","Class\tACC\tPRE\tSEN\tSPF\n","N\t0.85\t0.99\t0.84\t0.96\n","X\t0.85\t0.42\t0.96\t0.84\n","'''"],"execution_count":0,"outputs":[]}]}