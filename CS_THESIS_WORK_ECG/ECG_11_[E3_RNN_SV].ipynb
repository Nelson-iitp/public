{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ECG_11_[E3_RNN_SV].ipynb","provenance":[{"file_id":"1EB-vEdLXAcY4QdbZVHnA9i1qqFoGICKm","timestamp":1594709247635},{"file_id":"1uyBPQI7509ZMFDKxRcbR2pjDICKKFRNW","timestamp":1594708123336},{"file_id":"1NPn1buO9nRw5f06i9D6sT31tBv-BH5yF","timestamp":1594707889731}],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1mBgksgV3LRunVM2rdVtaQRj8TYDdDVFx","authorship_tag":"ABX9TyPJTvZo+TeMmJqVQ/3fIN0r"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"1E3Tiafl76ql","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594701395566,"user_tz":-330,"elapsed":5241,"user":{"displayName":"Nelson Sharma","photoUrl":"","userId":"05205859662695765719"}},"outputId":"9a5ba9d1-b6b2-4f6c-dc53-d5375b8447d3"},"source":["%reset"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1t6rI31rN2dE","colab_type":"text"},"source":["snippet for duration reporting"]},{"cell_type":"code","metadata":{"id":"by1lKhKHN04V","colab_type":"code","colab":{}},"source":["timestamp_start = datetime.datetime.now()\n","\n","timestamp_dur = datetime.datetime.now() - timestamp_start\n","print('Elapsed time = ' + str(timestamp_dur))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PE9d4UKb9Eol","colab_type":"text"},"source":["# [ IMPORTS ]"]},{"cell_type":"code","metadata":{"id":"bhdMqCv29DhV","colab_type":"code","colab":{}},"source":["import datetime\n","import os\n","import random\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","\n","import statistics as stats\n","import scipy.signal as scsig\n","\n","import tensorflow as tf\n","import keras\n","from tensorflow.keras.layers import Dense, Input, LSTM, Conv1D, MaxPooling1D, Flatten, BatchNormalization\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras.utils import to_categorical\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"REoerXn29JEu","colab_type":"text"},"source":["# [ GLOBAL ]"]},{"cell_type":"code","metadata":{"id":"j5e5t6zq9K7p","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"executionInfo":{"status":"ok","timestamp":1594701764603,"user_tz":-330,"elapsed":1174,"user":{"displayName":"Nelson Sharma","photoUrl":"","userId":"05205859662695765719"}},"outputId":"ca79952b-ee20-4873-cd57-8628b47bd69a"},"source":["# Resample every signal to this rate for consistency\n","BASIC_SRATE = 128 #Hz\n","print('Basic sampling rate(Hz): '+str(BASIC_SRATE))\n","\n","\n","#=================================================\n","# working directories\n","#=================================================\n","\n","# > _ base working directory\n","global_dir = '/content/drive/My Drive/Masters/workdir/ecg_data'\n","print('GLOBAL DIR :: '+global_dir)\n","\n","# >> global MAT directory, contains signal data in matlab (.mat) format\n","global_matdir = os.path.join(global_dir, 'db_mat') \n","print('GLOBAL MAT DIR :: '+global_matdir)\n","\n","# >> global NPY directory, contains signal and meta data in numpy (.npy) format\n","global_npydir = os.path.join(global_dir, 'db_npy') \n","print('GLOBAL NPY DIR :: '+global_npydir)\n","\n","# >> global datasets directory, contains manually generated datasets\n","global_dsdir = os.path.join(global_dir, 'db_dataset') \n","print('GLOBAL DATSET DIR :: '+global_dsdir)\n","\n","# >> model directory, contains model weights and test results use load_weights(), save_weights() \n","global_modeldir = os.path.join(global_dir, 'db_model')\n","print('GLOBAL MODEL DIR :: ' + global_modeldir)\n","\n","#>>----------------------------------------------- \n","\n","\n","#=================================================\n","# Annotations\n","#=================================================\n","# >> annotation directory, contains annotation mapping files to be used for experiments\n","global_antdir = os.path.join(global_dir, 'db_ant') \n","print('GLOBAL ANNOTATION DIR :: ' + global_antdir)\n","#>>----------------------------------------------- \n","\n","\n","#=================================================\n","# File Identifiers\n","#=================================================\n","# beat and non-beat annotations, signal data types to be used to save data in npy format\n","g_BA = 'BA'                     #<<--- beat annotations (@orignal Sampling rate)\n","g_NBA = 'NBA'                   #<<--- non-beat annotations (@orignal Sampling rate)\n","g_RAW2 = 'RAW2'                 #<<--- Raw lead2 signal from mat file\n","g_BLF2 = 'BLF2'                 #<<--- Baseline fitted signal\n","g_RES2 = 'RES2'                 #<<--- Resampled to BASIC_SRATE\n","\n","g_SIG2 = 'SIG2'     #<<--- Removed manual gain\n","g_RPEAK = 'RRP'     #<<--- Resampled R-peaks\n","#>>----------------------------------------------- "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Basic sampling rate(Hz): 128\n","GLOBAL DIR :: /content/drive/My Drive/Masters/workdir/ecg_data\n","GLOBAL MAT DIR :: /content/drive/My Drive/Masters/workdir/ecg_data/db_mat\n","GLOBAL NPY DIR :: /content/drive/My Drive/Masters/workdir/ecg_data/db_npy\n","GLOBAL DATSET DIR :: /content/drive/My Drive/Masters/workdir/ecg_data/db_dataset\n","GLOBAL MODEL DIR :: /content/drive/My Drive/Masters/workdir/ecg_data/db_model\n","GLOBAL ANNOTATION DIR :: /content/drive/My Drive/Masters/workdir/ecg_data/db_ant\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"44nZq8KZOqQZ","colab_type":"text"},"source":["# [ CLASS DEFINITIONS ]"]},{"cell_type":"code","metadata":{"id":"Mjh8fc9lO2nV","colab_type":"code","colab":{}},"source":["#---------------------------------------------------------------------------------------------------------------------------------------------\n","# CLASS ecg_db : represents one ECG database\n","#---------------------------------------------------------------------------------------------------------------------------------------------\n","class ecg_db:\n","    def __init__(self, dbname,  tag_recs):\n","        print('\\nInitailze new ecg database ... ')\n","        self.name = dbname  #str\n","        self.dir_npy = os.path.join(global_npydir , dbname+'_npy') #str\n","        self.recs = set(np.loadtxt(os.path.join(self.dir_npy,'RECORDS'), dtype='str',delimiter=\"\\n\")) #set\n","        self.recs_tag = set(tag_recs)\n","        self.recs_dict = {} # initially empty, will be loaded on demand using function 'get_record'\n","        self.info()\n","\n","    def info(self):\n","        print( 'DB NAME :: '+ self.name)\n","        print( 'DATA DIR :: ' + self.dir_npy )\n","        print( 'RECORDS :: [' +str(len(self.recs))+'] ' + str(self.recs) )\n","        print( 'TAG RECORDS :: [' +str(len(self.recs_tag))+'] ' + str(self.recs_tag))\n","        return 0\n","\n","    def get_record(self,rec):\n","        if not (rec in self.recs_dict.keys()):\n","            self.recs_dict[rec] = ecg_record(self,rec)\n","        return self.recs_dict[rec]\n","    \n","    def get_random_record(self, recset):\n","        rec = random.choice(list(recset))\n","        if not (rec in self.recs_dict.keys()):\n","            self.recs_dict[rec] = ecg_record(self,rec)\n","        return self.recs_dict[rec]\n","\n","#---------------------------------------------------------------------------------------------------------------------------------------------\n","\n","#---------------------------------------------------------------------------------------------------------------------------------------------\n","# CLASS ecg_record : represents one ECG Record in any database\n","#---------------------------------------------------------------------------------------------------------------------------------------------\n","g_SUPRESS_DATA_WARNING=False\n","class ecg_record:\n","\n","    def __init__(self, db, recname):\n","        self.db = db                                # class:{ecg_db}    object this record belongs to\n","        self.rec = recname                          # string            name of this record\n","        self.name = db.name + '_'+ recname          # string            full name including db.name\n","        if not recname in db.recs:\n","            print('WARNING:: Record \"'+ recname +'\" not found in database '+ db.name )\n","        self.data_npy = {}                          # dict dict of data file content used in self.read_data_npy('key')\n","        self.data_temp = {}                          # dict dict of data file content used in self.read_data_temp('key')\n","        self.binfo = None                           # class binfo       \n","\n","##<------------------------------------------------- get instance of binfo class\n","    def read_binfo(self):\n","        if self.binfo == None:\n","            self.binfo = ecg_binfo(self)\n","        return self.binfo\n","\n","    def refresh_binfo(self):\n","        self.binfo = ecg_binfo(self)\n","        return self.binfo\n","\n","##<------------------------------------------------- data reading for npydir\n","    def load_data(self, data_type):\n","        ipath = os.path.join(self.db.dir_npy, self.rec + '_'+data_type+'.npy')\n","        try: # try to load this data\n","            self.data_npy[data_type] = np.load(ipath) # adds this to dictionary so next time it can read\n","            return self.data_npy[data_type] #= np.load(self.dirs[s])\n","        except:\n","            if g_SUPRESS_DATA_WARNING == False:\n","                print('WARNING:: Cant load \"'+data_type+ '\" file at '+ str(ipath) )\n","            return np.array([])\n","        \n","    def read_data(self, data_type):\n","        if data_type in self.data_npy.keys():\n","            return self.data_npy[data_type] #= np.load(self.dirs[s])\n","        else:\n","            return self.load_data(data_type)\n","\n","##<------------------------------------------------- for tempdir\n","    def load_data_temp(self, data_type, dir_path):\n","        ipath = os.path.join(dir_path, self.rec + '_'+data_type+'.npy')\n","        try: # try to load this data\n","            self.data_temp[data_type] = np.load(ipath) # adds this to dictionary so next time it can read\n","            return self.data_temp[data_type] #= np.load(self.dirs[s])\n","        except:\n","            if g_SUPRESS_DATA_WARNING == False:\n","                print('WARNING:: Cant load \"'+data_type+ '\" file at '+ str(ipath) )\n","            return np.array([])\n","        \n","    def read_data_temp(self, data_type, dir_path):\n","        if data_type in self.data_temp.keys():\n","            return self.data_temp[data_type] #= np.load(self.dirs[s])\n","        else:\n","            return self.load_data_temp(data_type, dir_path)\n","\n","    def save_data_temp(self, data_type, data_array, dir_path):\n","        ipath = os.path.join(dir_path, self.rec + '_'+data_type+'.npy')\n","        np.save(ipath, data_array)\n","        return ipath\n","\n","    def del_data_temp(self, data_type, dir_path, vb):\n","        ipath = os.path.join(dir_path, self.rec + '_'+data_type+'.npy')\n","        if os.path.exists(ipath):\n","            if vb:\n","                print('Removing: '+str(ipath))\n","            os.remove(ipath)\n","            return 1\n","        else:\n","            return 0\n","#------------------------------------------------------------------------------------------------\n","\n","#---------------------------------------------------------------------------------------------------------------------------------------------\n","# CLASS ecg_binfo : information about beats in a record\n","#---------------------------------------------------------------------------------------------------------------------------------------------\n","class ecg_binfo:\n","    def __init__(self, rec):\n","         \n","        # the record object\n","        self.rec = rec\n","        \n","        # read orignal annotations\n","        r_peaks_ants = rec.read_data(g_RPEAK)       # resampled ant file\n","        \n","        # calculate count of R peaks (excluding first and last)\n","        self.rp_count = len(r_peaks_ants) - 2\n","        \n","        # Extract Location and Labels of Peaks (exclude first and last beat)\n","        r_peaks_int = r_peaks_ants[:,0].astype('int')\n","        r_ants_str = r_peaks_ants[:,1]\n","        \n","        #self.rp_first = r_peaks_int_raw[0] # = self.rp_prev[0]\n","        #self.rp_last = r_peaks_int_raw[-1] # = self.rp_next[-1]\n","        \n","        # Location\n","        self.rp_curr = r_peaks_int[1:-1]    # current R peak\n","        self.rp_prev = r_peaks_int[0:-2]    # previous R peak (in samples)\n","        self.rp_next = r_peaks_int[2:]      # next R peak (in samples)\n","        \n","        # Label\n","        self.rl_curr = r_ants_str[1:-1]\n","        self.rl_prev = r_ants_str[0:-2]\n","        self.rl_next = r_ants_str[2:]\n","\n","        # mapped Label\n","        self.rli_prev = []\n","        self.rli_curr = []\n","        self.rli_next = []\n","\n","        # calculate temporal info\n","        self.rp_sec = self.rp_curr / BASIC_SRATE                 # peak location (in sec)\n","        self.rri_prev = (self.rp_curr - self.rp_prev) / BASIC_SRATE   # prev RRI (in sec) \n","        self.rri_next = (self.rp_next - self.rp_curr) / BASIC_SRATE   # next RRI (in sec) \n","        self.rri_delta = (self.rri_next - self.rri_prev)              # difference b/w prev and next RRI (in sec) \n","        self.rri_dur = (self.rri_next + self.rri_prev)                # total duration from prev to next R-peak\n","        \n","\n","    def get_signal_data_var(self, ith_peak): # data_type = g_SIG_II_POSTFIX\n","        # prev peak to next peak\n","        sel_sig = self.rec.read_data(g_SIG2) \n","        ff = self.rp_prev[ith_peak]\n","        tt = self.rp_next[ith_peak]\n","        pp = self.rp_curr[ith_peak]\n","        return sel_sig[ff:tt+1], (pp-ff), (tt+1-ff) #<- also return position of peak\n","    \n","    def get_signal_data_fix(self, ith_peak, v_left_sec, v_right_sec): # data_type = g_SIG_II_POSTFIX\n","        return self.get_signal_data_fix_samples(ith_peak,int(v_left_sec*BASIC_SRATE),int(v_right_sec*BASIC_SRATE))\n","\n","    def get_signal_data_fix_samples(self, ith_peak, v_left, v_right): # data_type = g_SIG_II_POSTFIX\n","        sel_sig = self.rec.read_data(g_SIG2) \n","        ff = self.rp_curr[ith_peak]-v_left\n","        tt = self.rp_curr[ith_peak]+v_right\n","        pp = self.rp_curr[ith_peak]\n","\n","        f_pad,t_pad=0,0\n","        if ff<0:\n","            f_pad=0-ff\n","            ff=0\n","\n","        if tt>len(sel_sig):\n","            tpad=tt-len(sel_sig)\n","            tt=len(sel_sig)\n","\n","        sel_part = np.hstack((\n","            np.zeros(f_pad),\n","            sel_sig[ff:tt],\n","            np.zeros(t_pad),\n","            ))\n","\n","        pl = pp+f_pad\n","        return sel_part, pl #<- also return position of peak\n","\n","    def get_local_hrT(self,local_window_start,local_window_end): # within a time duration\n","        lws = local_window_start*BASIC_SRATE # in samples        \n","        lwe = local_window_end*BASIC_SRATE # in samples        \n","        #ff and tt should be within signal limits\n","        # if not in limits then take shortest : means truncate lw duration\n","        ff = max( lws ,self.rp_prev[0])\n","        tt = min( lwe ,self.rp_next[-1])\n","        dd = (tt-ff)/BASIC_SRATE\n","        qq = np.where((self.rp_curr>=ff) & (self.rp_curr<=tt))[0] #  these many peaks in dd sec\n","        nq = len(qq)# qq must be at least 2 peaks\n","        # if qq peaks in dd secs then heart rate = (qq/dd) bps =  (qq/dd)*60 bpm\n","        if nq<2:  \n","             dd=0\n","             local_bps = 0\n","        else:\n","             ff = self.rp_curr[qq[0]]\n","             tt = self.rp_curr[qq[-1]]\n","             dd = (tt-ff)/BASIC_SRATE\n","             local_bps = (nq-1)/dd #bps\n","        \n","        return local_bps, dd\n","   \n","     \n","    def get_local_hr(self,ith_peak, local_window_left,local_window_right): # within local duration of ith peak\n","        lwl = local_window_left*BASIC_SRATE # in samples        \n","        lwr = local_window_right*BASIC_SRATE # in samples        \n","        #ff and tt should be within signal limits\n","        # if not in limits then take shortest : means truncate lw duration\n","        ff = max(self.rp_curr[ith_peak] - lwl ,self.rp_prev[0])\n","        tt = min(self.rp_curr[ith_peak] + lwr ,self.rp_next[-1])\n","        \n","        qq = np.where((self.rp_curr>=ff) & (self.rp_curr<=tt))[0] #  these many peaks in dd sec\n","        nq = len(qq)# qq must be at least 2 peaks\n","        if nq<2:  \n","             return 0, 0\n","        else:\n","             ff = self.rp_curr[qq[0]]\n","             tt = self.rp_curr[qq[-1]]\n","             dd = (tt-ff)/BASIC_SRATE\n","        # if nq peaks in dd secs then heart rate = (nq/dd) bps =  (nq/dd)*60 bpm\n","             local_bps = (nq-1)/dd #bps\n","             return local_bps, dd\n","\n","    def get_local_hrA(self, local_window_left,local_window_right): # within local duration of all peaks\n","        lwl = local_window_left*BASIC_SRATE # in samples        \n","        lwr = local_window_right*BASIC_SRATE # in samples       \n","        #ff and tt should be within signal limits\n","        # if not in limits then take shortest : means truncate lw duration\n","        local_bps = np.zeros(self.rp_count,dtype='float')\n","        local_dd = np.zeros(self.rp_count,dtype='float')\n","        for ith_peak in range(0, self.rp_count):\n","             ff = max(self.rp_curr[ith_peak] - lwl ,self.rp_prev[0])\n","             tt = min(self.rp_curr[ith_peak] + lwr ,self.rp_next[-1])\n","             qq = np.where((self.rp_curr>=ff) & (self.rp_curr<=tt))[0] #  these many peaks in dd sec\n","             nq = len(qq) # qq must be at least 2 peaks\n","             if nq<2:  \n","                  local_bps[ith_peak] = 0 #bps\n","                  local_dd[ith_peak] = 0 #bps\n","             else:\n","                  ff = self.rp_curr[qq[0]]\n","                  tt = self.rp_curr[qq[-1]]\n","                  dd = (tt-ff)/BASIC_SRATE\n","                  local_bps[ith_peak] = (nq-1)/dd #bps\n","                  local_dd[ith_peak] = dd #bps\n","        return local_bps, local_dd\n","    \n","    def map_ants2int(self,map_dict):\n","        if len(self.rli_curr)!=self.rp_count:\n","            temp = np.zeros(self.rp_count+2,dtype='str')\n","            temp[0] =  map_dict[self.rl_prev[0]]\n","            for i in range(0, self.rp_count):\n","                temp[i+1] = map_dict[self.rl_curr[i]]\n","            temp[-1] =  map_dict[self.rl_next[-1]]\n","            self.rli_curr = temp[1:-1]\n","            self.rli_prev = temp[0:-2]\n","            self.rli_next = temp[2:]\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nwgh8qLKYnBd","colab_type":"text"},"source":["# [ BUILD STANDARD DBs ]"]},{"cell_type":"code","metadata":{"id":"fBi7pG-gYqbO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":360},"executionInfo":{"status":"ok","timestamp":1594701772124,"user_tz":-330,"elapsed":1903,"user":{"displayName":"Nelson Sharma","photoUrl":"","userId":"05205859662695765719"}},"outputId":"2210d115-f5b9-4530-ff0f-a900b3f2e59c"},"source":["print('Buidling standard databases')\n","#------------------------------------------------------------------------\n","std_mitdb = ecg_db('mitdb', [])\n","#------------------------------------------------------------------------\n","std_svdb = ecg_db('svdb', [])\n","#------------------------------------------------------------------------\n","std_incartdb= ecg_db('incartdb', [])\n","#------------------------------------------------------------------------"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Buidling standard databases\n","\n","Initailze new ecg database ... \n","DB NAME :: mitdb\n","DATA DIR :: /content/drive/My Drive/Masters/workdir/ecg_data/db_npy/mitdb_npy\n","RECORDS :: [48] {'122', '223', '118', '102', '221', '107', '202', '201', '214', '203', '222', '105', '212', '233', '121', '210', '106', '209', '215', '108', '104', '123', '231', '115', '116', '119', '234', '213', '200', '228', '114', '117', '103', '113', '232', '101', '124', '220', '208', '100', '230', '207', '205', '109', '217', '219', '112', '111'}\n","TAG RECORDS :: [0] set()\n","\n","Initailze new ecg database ... \n","DB NAME :: svdb\n","DATA DIR :: /content/drive/My Drive/Masters/workdir/ecg_data/db_npy/svdb_npy\n","RECORDS :: [78] {'864', '847', '869', '868', '854', '801', '844', '845', '802', '880', '885', '856', '841', '800', '811', '849', '884', '887', '826', '865', '823', '803', '843', '848', '883', '806', '881', '829', '820', '872', '810', '860', '859', '886', '812', '878', '871', '877', '890', '861', '891', '862', '863', '807', '824', '879', '892', '888', '850', '851', '894', '821', '827', '822', '866', '875', '873', '855', '809', '852', '876', '889', '842', '874', '808', '857', '870', '867', '805', '840', '846', '893', '858', '882', '804', '853', '828', '825'}\n","TAG RECORDS :: [0] set()\n","\n","Initailze new ecg database ... \n","DB NAME :: incartdb\n","DATA DIR :: /content/drive/My Drive/Masters/workdir/ecg_data/db_npy/incartdb_npy\n","RECORDS :: [75] {'I74', 'I38', 'I02', 'I14', 'I28', 'I24', 'I17', 'I39', 'I50', 'I27', 'I70', 'I26', 'I66', 'I42', 'I44', 'I65', 'I64', 'I59', 'I03', 'I31', 'I61', 'I04', 'I73', 'I11', 'I15', 'I45', 'I46', 'I21', 'I49', 'I16', 'I19', 'I54', 'I71', 'I32', 'I62', 'I18', 'I20', 'I30', 'I22', 'I41', 'I75', 'I35', 'I06', 'I52', 'I09', 'I53', 'I58', 'I05', 'I29', 'I12', 'I37', 'I25', 'I10', 'I36', 'I51', 'I56', 'I57', 'I55', 'I67', 'I69', 'I40', 'I08', 'I33', 'I60', 'I13', 'I47', 'I72', 'I63', 'I34', 'I68', 'I43', 'I01', 'I23', 'I48', 'I07'}\n","TAG RECORDS :: [0] set()\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_gDNs0vmbIK-","colab_type":"text"},"source":["# [ PERFORMANCE MEASURES ]"]},{"cell_type":"code","metadata":{"id":"yRoN7e-1bLvq","colab_type":"code","colab":{}},"source":["#=========================================================================================================================\n","#======================= NEURAL NETWORK PERFORMANCE MEASURES\n","#=========================================================================================================================\n","# 3.3 :: define performance evaluation functions\n","\n","def get_performance(conf_matrix):\n","    #how many classes? = len of conf_matril\n","    nos_class = len(conf_matrix[0,:]) # len of 0th row\n","    res = np.zeros((0,8),dtype ='float64')\n","    for i in range(0,nos_class):\n","        # for each class calculate 4 performance measure - ACC, PRE, SEN, SPF, \n","        # first compute TP, TN, FP, FN\n","        TP = conf_matrix[i,i]\n","        FP = np.sum(conf_matrix[:,i]) - TP\n","        FN = np.sum(conf_matrix[i,:]) - TP\n","        TN = np.sum(conf_matrix) - FN - FP - TP\n","\n","        ACC = (TP+TN)   /   (TP+FP+FN+TN)\n","        PRE = (TP)      /   (TP+FP)\n","        SEN = (TP)      /   (TP+FN)\n","        SPF = (TN)      /   (TN+FP)\n","\n","        res_i = np.array([TP, FN, FP, TN, ACC, PRE, SEN, SPF])\n","        res = np.vstack((res,res_i))\n","    return res\n","\n","\n","#------------------------------------------------------------------PRINTING\n","\n","def print_lstr(class_labels):\n","    g_LSTR=''   # HEADER ROW for printing confusing matrix\n","    for i in range(0,len(class_labels)):\n","        g_LSTR+='\\t'+str(class_labels[i])\n","    return  g_LSTR\n","\n","def print_cf_row(cf_row,nos_labels):\n","    res = ''\n","    for j in range(0,nos_labels):\n","        res += '\\t'+ str(cf_row[j])\n","    return res\n","def print_conf_matrix(conf_matrix, suffix, class_labels):\n","    res=(suffix+'A\\\\P' + print_lstr(class_labels)+'\\n')\n","    nos_l=len(class_labels)\n","    for i in range(0,nos_l):\n","        res+=(suffix+str(class_labels[i]) + print_cf_row(conf_matrix[i],nos_l )+'\\n')\n","    return res\n","def print_performance(perf_measures, class_labels):\n","    nos_class = len(perf_measures[:,0])\n","    print('Performance for '+str(nos_class)+' classes')\n","    print ('Class\\tACC\\tPRE\\tSEN\\tSPF')\n","    for i in range(0, nos_class):\n","        perf_i = np.round(perf_measures [i,:],2)\n","        #print('\\tT.P : '+str(perf_i[0])+'\\tF.N : '+str(perf_i[1]))\n","        #print('\\tF.P : '+str(perf_i[2])+'\\tT.N : '+str(perf_i[3]))\n","        print(str(class_labels[i])+'\\t'+str(perf_i[4])+'\\t'+str(perf_i[5])+'\\t'+str(perf_i[6])+'\\t'+str(perf_i[7]))\n","    return\n","#------------------------------------------------------------------\n","\n","def plot_ecg_segment(signal_info, signal_array, fsec, tsec, x_scale, y_scale, y_low, y_high, mticks_pos, show_rris, predx, predy, a_color, gain=1):\n","    # plot signal segments\n","    #<<---------------------------------------------Select ECG Segment\n","    dsec = tsec - fsec\n","    print(signal_info.rec.name)\n","    if len(signal_array)==0:\n","        print('WARNING::Signal was not loaded.')\n","        return 0\n","    else:\n","        ff = int(fsec * BASIC_SRATE)\n","        tt = int(tsec * BASIC_SRATE)\n","        dd = tt - ff\n","\n","        bps = signal_array[ff:tt] * gain  # signal data * gain\n","\n","        lim_query = np.where((signal_info.rp_sec >= fsec) & (signal_info.rp_sec < tsec))[0]\n","\n","        dticks = signal_info.rp_curr[lim_query]-ff  # tick position\n","        nos_ticks = len(dticks)\n","\n","        dlabels = signal_info.rl_curr[lim_query]    # orignal labels\n","        dilabels = signal_info.rli_curr[lim_query]  # mapped labels\n","        ditruth = predy[lim_query]\n","        dpredx = predx[lim_query]\n","        diPred = dpredx.argmax(axis=1)\n","        diPredCol = np.zeros(nos_ticks, dtype='U15') \n","        for i in range(0,nos_ticks):\n","            if diPred[i]==0:\n","                diPredCol[i]= 'tab:green'      \n","            else:\n","                diPredCol[i]= a_color  \n","        dicolors = np.zeros(nos_ticks, dtype='U15') # get color repesentation\n","        for i in range(0,nos_ticks):\n","            dicolors[i]= g_STD_LABELS[dilabels[i]]\n","\n","        print('Time Interval{'+str(dsec)+'s}:['+str(fsec)+':'+str(tsec)+']')\n","        if nos_ticks > 0:\n","            print('Beat Interval{'+str(nos_ticks)+'#}:['+str(lim_query[0])+':'+str(lim_query[-1])+']')\n","        else:\n","            print('Beat Interval{'+str(nos_ticks)+'#}')\n","\n","        # prepare figure: predictions\n","        plt.figure('ecg predictions', figsize = (dsec*x_scale ,(y_high-y_low) * y_scale) )\n","        plt.xlim(0, len(bps))\n","        plt.ylim(-0.5,1.1)\n","        plt.yticks([])\n","        plt.xticks(dticks,dlabels)\n","        plt.grid(axis='x')\n","        plt.hlines(0,0,len(bps), linewidth=0.3)\n","        plt.hlines(0.5,0,len(bps), linewidth=0.3)\n","        plt.hlines(1,0,len(bps), linewidth=0.3)\n","        plt.scatter(dticks,np.zeros(nos_ticks)-0.40,marker='s',color=dicolors)\n","        plt.scatter(dticks,np.zeros(nos_ticks)-0.20,marker='o',color=diPredCol)\n","\n","        pred_str = np.zeros(len(diPred))\n","        for i in range(0,len(diPred)):\n","            pred_str[i]=dpredx[i][diPred[i]]\n","            \n","        plt.scatter(dticks,pred_str,marker='.',color='black')\n","\n","        # where predy is 0 and predx is 1\n","        d_aN_pA = dticks[np.where((ditruth==0)&(diPred==1))[0]]\n","        plt.scatter(d_aN_pA,np.zeros(len(d_aN_pA)),marker='x',color='tab:green')\n","\n","        d_aA_pN = dticks[np.where((ditruth==1)&(diPred==0))[0]]\n","        plt.scatter(d_aA_pN,np.zeros(len(d_aA_pN)),marker='x',color='tab:red')\n","\n","        #plt.scatter(dticks,dpredx[:,0],marker='x',color='tab:green')\n","        #plt.scatter(dticks,dpredx[:,1],marker='x',color=a_color)\n","\n","        plt.tight_layout()\n","        plt.show()\n","        \n","\n","        # prepare figure: signal\n","        plt.figure('ecg signal', figsize = (dsec*x_scale ,(y_high-y_low) * y_scale) )\n","        plt.xlim(0, len(bps))\n","        plt.ylim(y_low,y_high)\n","        plt.yticks([])\n","        plt.xticks(dticks,dlabels)\n","        #x_grid = np.arange(0,tt-ff, 1*BASIC_SRATE)\n","        #plt.xticks(x_grid)\n","        plt.grid(axis='x')\n","        # plot signal and baseline\n","        plt.plot(bps, linewidth=0.5, color='black')\n","        plt.hlines(0,0,len(bps), linewidth=0.3)\n","        # plot mapped labels\n","        plt.scatter(dticks,np.zeros(nos_ticks)+mticks_pos,marker='s',color=dicolors)\n","\n","        # finalize\n","        plt.tight_layout()\n","        plt.show()\n","        \n","        if show_rris:\n","             ddur = signal_info.rri_dur[lim_query]       # duration\n","             ddel = np.absolute(signal_info.rri_delta[lim_query] )      # delta rri\n","             # prepare figure: rri,delta rri\n","             my_low, my_high = -0.1, 3.5\n","             plt.figure('ecg meta', figsize = (dsec*x_scale ,(my_high-my_low) * 1.5*y_scale) )\n","             plt.xlim(0, len(bps))\n","             plt.ylim(my_low,my_high)\n","             plt.yticks([])\n","             plt.xticks(dticks,dlabels)\n","             #x_grid = np.arange(0,tt-ff, 1*BASIC_SRATE)\n","             #plt.xticks(x_grid)\n","             plt.grid(axis='x')\n","     \n","             # plot grid and baseline\n","             plt.hlines(0,0,len(bps), linewidth=0.3,color='red')\n","             #for j in [0.5,1,1.5,2,2.5,3]:\n","             #    plt.hlines(j,0,len(bps), linewidth=0.3,color='black')\n","     \n","             # plot mapped labels\n","             plt.scatter(dticks,ddur,marker='s',color=dicolors)\n","             plt.scatter(dticks,ddel,marker='o',color='tab:purple')\n","             plt.plot(dticks,ddur,color='black',linewidth=0.5,linestyle='dotted')\n","             plt.plot(dticks,ddel,color='black',linewidth=0.5,linestyle='dotted')\n","             # finalize\n","             plt.tight_layout()\n","             plt.show()\n","\n","        return bps,dticks,dlabels\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MVhDoaFFcQIk","colab_type":"text"},"source":["\n","\n","---\n","\n","END OF SHARED SECTION\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Vx8Rz27tkxEq","colab_type":"text"},"source":["# [EXP DATA DICT]"]},{"cell_type":"code","metadata":{"id":"iH1JzYX9k2Ut","colab_type":"code","colab":{}},"source":["mitdb_ex = set([\n","            '102','104','107','217', # paced\n","            '207',   # VFlutter\n","            '212', '231',   # both N and BBB\n","            '108', # bad signal\n","            '202','203' # bad labeling\n","            ])\n","svdb_ex = set([])\n","incartdb_ex = set([])\n","\n","#<<--------------------------------------------\n","std_mitdb.recs_tag = set.difference(std_mitdb.recs, mitdb_ex)\n","std_svdb.recs_tag = set.difference(std_svdb.recs, svdb_ex)\n","std_incartdb.recs_tag = set.difference(std_incartdb.recs, incartdb_ex)\n","\n","#<<--------------------------------------------\n","std_db_msi = {}\n","std_db_msi['mitdb']=std_mitdb\n","std_db_msi['svdb']=std_svdb\n","std_db_msi['incartdb']=std_incartdb\n","\n","#<<--------------------------------------------\n","std_db_ms = {}\n","std_db_ms['mitdb']=std_mitdb\n","std_db_ms['svdb']=std_svdb\n","\n","#<<--------------------------------------------\n","std_db_mi = {}\n","std_db_mi['mitdb']=std_mitdb\n","std_db_mi['incartdb']=std_incartdb\n","\n","#<<--------------------------------------------\n","std_db_si = {}\n","std_db_si['svdb']=std_svdb\n","std_db_si['incartdb']=std_incartdb\n","\n","#<<--------------------------------------------\n","std_db_m = {}\n","std_db_m['mitdb']=std_mitdb\n","\n","#<<--------------------------------------------\n","std_db_s = {}\n","std_db_s['svdb']=std_svdb\n","\n","#<<--------------------------------------------\n","std_db_i = {}\n","std_db_i['incartdb']=std_incartdb\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W_sqax3Pf69f","colab_type":"text"},"source":["# [ --- EXP_3 : RNN/LSTM --- ]"]},{"cell_type":"markdown","metadata":{"id":"2_byWOT9nJBC","colab_type":"text"},"source":["This experiment classifies beats into Normal or Abnormal category. Annotations used are N,S,V (F beats are included in V type)"]},{"cell_type":"markdown","metadata":{"id":"u5HmtO78YW20","colab_type":"text"},"source":["# [ VIEW ANNOTATION MAPPERS ]"]},{"cell_type":"code","metadata":{"id":"kQf6tu51YcIl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"executionInfo":{"status":"ok","timestamp":1594587981676,"user_tz":-330,"elapsed":1438,"user":{"displayName":"Nelson Sharma","photoUrl":"","userId":"05205859662695765719"}},"outputId":"127dfb4d-1bef-4748-929e-83758d7e3902"},"source":["ls_ants = os.listdir(global_antdir)\n","ls_ants=np.sort(ls_ants)\n","print('Available annotation files ['+str(len(ls_ants))+']')\n","for ls_ant in ls_ants:\n","    print(ls_ant)\n","print('--------------------------')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Available annotation files [6]\n","default_labels.txt\n","default_map.txt\n","exp01_labels.txt\n","exp01_map.txt\n","nsvf_labels.txt\n","nsvf_map.txt\n","--------------------------\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GmckqB0KYfCg","colab_type":"text"},"source":["# [ MAP ANNOTATIONS ]"]},{"cell_type":"code","metadata":{"id":"sodtJ3YKXxuW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":887},"executionInfo":{"status":"ok","timestamp":1594701790614,"user_tz":-330,"elapsed":1692,"user":{"displayName":"Nelson Sharma","photoUrl":"","userId":"05205859662695765719"}},"outputId":"1c00156f-1644-4cff-feae-92e3fb8d139f"},"source":["# standard labels and mappings default_labels\n","sel_labels = os.path.join(global_antdir, 'exp01_labels.txt') \n","sel_map = os.path.join(global_antdir, 'exp01_map.txt') \n","\n","# ----------------------------------------------------------------------\n","# ------ load standard labels ------------------------------------------\n","# ----------------------------------------------------------------------\n","sel_labels_data = np.loadtxt(sel_labels, dtype='str',delimiter=\"\\t\")\n","g_STD_LABELS={}\n","print('\\nStandard Labels::')\n","for a in sel_labels_data:\n","    # a[0] =  # standard label (char)\n","    # a[1] =  # mapped color (str)\n","    # a[2]  = # description (str)\n","    g_STD_LABELS[a[0]]= a[1]\n","    print(a[0]+'\\t'+a[1]+'\\t'+a[2])\n","\n","# ----------------------------------------------------------------------\n","# ------ load mapping data ---------------------------------------------\n","# ----------------------------------------------------------------------\n","ant_map_data = np.loadtxt(sel_map, dtype='str',delimiter=\"\\t\")\n","g_STD_NO_MAP = '_'\n","g_STD_LABELS[g_STD_NO_MAP]='black'\n","g_STD_MAP={}\n","print('\\nMapping::')\n","for a in ant_map_data:\n","    # a[0] =  # orignal pysionet label (char)\n","    # a[1] =  # mapped standard label (char)\n","    # a[2]  = # description (str)\n","    g_STD_MAP[a[0]]= a[1] ##<<----------------mapping dictionary\n","    print(a[0]+'\\t'+a[1]+'\\t'+a[2])\n","print('\\n',g_STD_MAP.keys())\n","\n","\n","#<<--------------------------------------------\n","for idb in std_db_msi.keys():\n","    sel_db = std_db_msi[idb]\n","    for irec in sel_db.recs_tag:\n","        sel_rec = sel_db.get_record(irec)\n","        sel_info = sel_rec.read_binfo()\n","        sel_info.map_ants2int(g_STD_MAP)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Standard Labels::\n","N\tgreen\tNormal\n","S\tred\tSupraventricular Premature\n","V\tblue\tVentricular Premature\n","\n","Mapping::\n","N\tN\tNormal beat\n","L\tN\tLeft bundle branch block beat\n","R\tN\tRight bundle branch block beat\n","B\tN\tBundle branch block beat (unspecified)\n","A\tS\tAtrial premature beat\n","a\tS\tAberrated atrial premature beat\n","J\tS\tNodal (junctional) premature beat\n","S\tS\tSupraventricular premature or ectopic beat (atrial or nodal)\n","V\tV\tPremature ventricular contraction\n","r\tV\tR-on-T premature ventricular contraction\n","F\tV\tFusion of ventricular and normal beat\n","e\t_\tAtrial escape beat\n","j\t_\tNodal (junctional) escape beat\n","n\t_\tSupraventricular escape beat (atrial or nodal)\n","E\t_\tVentricular escape beat\n","/\t_\tPaced beat\n","f\t_\tFusion of paced and normal beat\n","Q\t_\tUnclassifiable \n","?\t_\tBeat not classified during learning\n","[\t_\tStart of ventricular flutter/fibrillation\n","!\t_\tVentricular flutter wave\n","]\t_\tEnd of ventricular flutter/fibrillation\n","x\t_\tNon-conducted P-wave (blocked APC)\n","(\t_\tWaveform onset\n",")\t_\tWaveform end\n","p\t_\tPeak of P-wave\n","t\t_\tPeak of T-wave\n","u\t_\tPeak of U-wave\n","`\t_\tPQ junction\n","'\t_\tJ-point\n","^\t_\t(Non-captured) pacemaker artifact\n","|\t_\tIsolated QRS-like artifact [1]\n","~\t_\tChange in signal quality [1]\n","+\t_\tRhythm change [2]\n","s\t_\tST segment change [2]\n","T\t_\tT-wave change [2]\n","*\t_\tSystole\n","D\t_\tDiastole\n","=\t_\tMeasurement annotation [2]\n","\"\t_\tComment annotation [2]\n","@\t_\tLink to external data [3]\n","\n"," dict_keys(['N', 'L', 'R', 'B', 'A', 'a', 'J', 'S', 'V', 'r', 'F', 'e', 'j', 'n', 'E', '/', 'f', 'Q', '?', '[', '!', ']', 'x', '(', ')', 'p', 't', 'u', '`', \"'\", '^', '|', '~', '+', 's', 'T', '*', 'D', '=', '\"', '@'])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HDM71ap2ENGX","colab_type":"text"},"source":["# [ MODEL ]"]},{"cell_type":"code","metadata":{"id":"8DUZHEB12eu7","colab_type":"code","colab":{}},"source":["# variable length input LSTM model\n","\n","cost = 'binary_crossentropy'\n","opt = 'adam'\n","\n","def get_modelLSTM_01(print_summary):\n","\n","# NR INPUT SIDE ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","\n","    iNR_0 = Input( shape=(None,1), name = \"in_NR_0\" )\n","    #bn_N =                              BatchNormalization()(iNR_0)\n","    lNR_1 =  LSTM                       (150,\n","                                        activation='tanh', \n","                                        recurrent_activation='sigmoid', \n","                                        use_bias=True, \n","                                        kernel_initializer='glorot_uniform', \n","                                        recurrent_initializer='orthogonal', \n","                                        bias_initializer='zeros', unit_forget_bias=True, \n","                                        kernel_regularizer=None, \n","                                        recurrent_regularizer=None, \n","                                        bias_regularizer=None, \n","                                        activity_regularizer=None, \n","                                        kernel_constraint=None, \n","                                        recurrent_constraint=None, \n","                                        bias_constraint=None, \n","                                        dropout=0.0, \n","                                        recurrent_dropout=0.0, \n","                                        implementation=2, \n","                                        return_sequences=True, \n","                                        return_state=False, \n","                                        go_backwards=False,\n","                                        stateful=False, \n","                                        unroll=False,\n","                                        name='LSTM_NR_1')(iNR_0) \n","    \n","    lNR_2 = LSTM                        (50,\n","                                        activation='tanh', \n","                                        recurrent_activation='sigmoid', \n","                                        use_bias=True, \n","                                        kernel_initializer='glorot_uniform', \n","                                        recurrent_initializer='orthogonal', \n","                                        bias_initializer='zeros', unit_forget_bias=True, \n","                                        kernel_regularizer=None, \n","                                        recurrent_regularizer=None, \n","                                        bias_regularizer=None, \n","                                        activity_regularizer=None, \n","                                        kernel_constraint=None, \n","                                        recurrent_constraint=None, \n","                                        bias_constraint=None, \n","                                        dropout=0.0, \n","                                        recurrent_dropout=0.0, \n","                                        implementation=2, \n","                                        return_sequences=False, \n","                                        return_state=False, \n","                                        go_backwards=False,\n","                                        stateful=False, \n","                                        unroll=False,\n","                                        name='LSTM_NR_2')(lNR_1) \n","\n","# CR INPUT SIDE ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","\n","    iCR_0 = Input( shape=(None,1), name = \"in_CR_0\" )\n","    #bn_C =                              BatchNormalization()(iCR_0)\n","    lCR_1 =  LSTM                       (150,\n","                                        activation='tanh', \n","                                        recurrent_activation='sigmoid', \n","                                        use_bias=True, \n","                                        kernel_initializer='glorot_uniform', \n","                                        recurrent_initializer='orthogonal', \n","                                        bias_initializer='zeros', unit_forget_bias=True, \n","                                        kernel_regularizer=None, \n","                                        recurrent_regularizer=None, \n","                                        bias_regularizer=None, \n","                                        activity_regularizer=None, \n","                                        kernel_constraint=None, \n","                                        recurrent_constraint=None, \n","                                        bias_constraint=None, \n","                                        dropout=0.0, \n","                                        recurrent_dropout=0.0, \n","                                        implementation=2, \n","                                        return_sequences=True, \n","                                        return_state=False, \n","                                        go_backwards=False,\n","                                        stateful=False, \n","                                        unroll=False,\n","                                        name='LSTM_CR_1')(iCR_0) \n","    \n","    lCR_2 = LSTM                        (50,\n","                                        activation='tanh', \n","                                        recurrent_activation='sigmoid', \n","                                        use_bias=True, \n","                                        kernel_initializer='glorot_uniform', \n","                                        recurrent_initializer='orthogonal', \n","                                        bias_initializer='zeros', unit_forget_bias=True, \n","                                        kernel_regularizer=None, \n","                                        recurrent_regularizer=None, \n","                                        bias_regularizer=None, \n","                                        activity_regularizer=None, \n","                                        kernel_constraint=None, \n","                                        recurrent_constraint=None, \n","                                        bias_constraint=None, \n","                                        dropout=0.0, \n","                                        recurrent_dropout=0.0, \n","                                        implementation=2, \n","                                        return_sequences=False, \n","                                        return_state=False, \n","                                        go_backwards=False,\n","                                        stateful=False, \n","                                        unroll=False,\n","                                        name='LSTM_CR_2')(lCR_1)    \n","\n","# CONCAT NR and CR ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","\n","    d_concat =  tf.concat([lNR_2, lCR_2],axis=1, name = \"dense_NC\")\n","\n","# DENSE SIDE ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","\n","    den_fc0 = Dense(20, activation=tf.nn.leaky_relu, name = \"DENSE_FC0\")(d_concat)\n","    den_fc1 = Dense(15, activation=tf.nn.leaky_relu, name = \"DENSE_FC1\")(den_fc0)\n","\n","# OUTPUT SIDE ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","    den_out = Dense(1, activation=tf.nn.sigmoid, name = \"OUTPUT_FC\")(den_fc1)\n","\n","# =========================================================================================\n","\n","    model=Model(inputs=[iNR_0,iCR_0], outputs=den_out)\n","\n","    #-------------------------------------\n","    #model.get_layer(name=\"LSTM_50\").trainable=is_trainable\n","    #-------------------------------------\n","\n","    model.compile(loss=cost, optimizer=opt, metrics=['accuracy'])\n","    if print_summary:\n","        print(model.summary())\n","    return model\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cmFjnDQ5BzKi","colab_type":"text"},"source":["# [ DATA GENERATOR ]"]},{"cell_type":"code","metadata":{"id":"68QAPnr028Pt","colab_type":"code","colab":{}},"source":["class DGen:\n","    def __init__(self, samplelist, ecgdb, shuffle_count):\n","        self.ecgdb = ecgdb\n","        self.shuffle=shuffle_count\n","        self.sample_list = samplelist\n","        self.nos_samples = len(samplelist)\n","        self.isample = -1\n","\n","\n","    def read_data_sample(self): # sel_dbA,sel_recA,sel_NR,sel_A,sel_A_label\n","        self.isample = -1\n","        while True:\n","            self.isample+=1\n","            if self.isample>=self.nos_samples:\n","                #print('Repeating...')\n","                for i in range (0,self.shuffle):\n","                    np.random.shuffle(self.sample_list)\n","                self.isample = 0\n","                \n","\n","\n","            cdata = self.sample_list[self.isample]\n","\n","            data_db = cdata[0]\n","            data_rec = cdata[1]\n","            data_NR = int(cdata[2])\n","            data_CR = int(cdata[3])\n","            data_L = np.array([int(cdata[4])])\n","\n","            #data_recO = self.ecgdb.get_record(data_rec)\n","            data_binfo = self.ecgdb[data_db].get_record(data_rec).read_binfo()\n","            NR_sig,_,_ = data_binfo.get_signal_data_var(data_NR)\n","            CR_sig,_,_ = data_binfo.get_signal_data_var(data_CR)\n","\n","\n","            \n","            NR_sig = np.expand_dims(np.expand_dims(NR_sig,axis=-1),axis=0)\n","            CR_sig = np.expand_dims(np.expand_dims(CR_sig,axis=-1),axis=0)\n","            data_L = np.expand_dims(data_L,axis=0)\n","            #print(cdata)\n","            #print(NR_sig.shape,CR_sig.shape,data_L.shape)\n","\n","            #print('\\nyield:',self.isample,self.iepoch)\n","            yield [NR_sig,CR_sig],data_L\n","\n","    def read_data_sample_predict(self): # sel_dbA,sel_recA,sel_NR,sel_A,sel_A_label\n","        self.true_labels = []\n","        self.isample = -1\n","        while True:\n","            self.isample+=1\n","            if self.isample>=self.ifilelen:\n","                #print('Repeating...')\n","                self.isample = 0\n","                \n","\n","\n","            cdata = self.sample_list[self.isample]\n","\n","            data_db = cdata[0]\n","            data_rec = cdata[1]\n","            data_NR = int(cdata[2])\n","            data_CR = int(cdata[3])\n","            data_L = np.array([int(cdata[4])])\n","\n","            #data_recO = self.ecgdb.get_record(data_rec)\n","            data_binfo = self.ecgdb[data_db].get_record(data_rec).read_binfo()\n","            NR_sig,_,_ = data_binfo.get_signal_data_var(data_NR)\n","            CR_sig,_,_ = data_binfo.get_signal_data_var(data_CR)\n","\n","\n","            \n","            NR_sig = np.expand_dims(np.expand_dims(NR_sig,axis=-1),axis=0)\n","            CR_sig = np.expand_dims(np.expand_dims(CR_sig,axis=-1),axis=0)\n","            data_L = np.expand_dims(data_L,axis=0)\n","            #print(cdata)\n","            #print(NR_sig.shape,CR_sig.shape,data_L.shape)\n","\n","            #print('\\nyield:',self.isample,self.iepoch)\n","            self.true_labels.append(data_L[0])\n","            yield [NR_sig,CR_sig]\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iPPkL-DVB7SD","colab_type":"text"},"source":["# [ TRAINING ]"]},{"cell_type":"markdown","metadata":{"id":"29UUhfNJPQTz","colab_type":"text"},"source":["## [ LOAD DATASET ]"]},{"cell_type":"code","metadata":{"id":"DUZa-7r2CBIe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1594689617051,"user_tz":-330,"elapsed":1900,"user":{"displayName":"Nelson Sharma","photoUrl":"","userId":"05205859662695765719"}},"outputId":"d7fe024d-0d4a-408f-b5fd-4dd11fea3762"},"source":["ds_list = ['train_X']\n","timestamp_start = datetime.datetime.now()\n","ds_str = np.zeros((0,5),dtype='U10')\n","for ds_name in ds_list:\n","    ds_path = os.path.join(global_dsdir,ds_name+'.npy') \n","    ds_this = np.load(ds_path)\n","    print('loaded:',ds_this.shape, ds_path)\n","    ds_str=np.vstack((ds_str,ds_this))\n","\n","\n","genD = DGen(ds_str,std_db_m,2)\n","print(genD.isample,'/',genD.nos_samples)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["loaded: (414, 5) /content/drive/My Drive/Masters/workdir/ecg_data/db_dataset/train_X.npy\n","-1 / 414\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sHGS8irgVPSk","colab_type":"text"},"source":["## [ PERFORM TRAINING ]"]},{"cell_type":"code","metadata":{"id":"dXcadsX2CmGb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":935},"executionInfo":{"status":"error","timestamp":1594689725833,"user_tz":-330,"elapsed":106482,"user":{"displayName":"Nelson Sharma","photoUrl":"","userId":"05205859662695765719"}},"outputId":"7995b3ba-9c08-437b-e190-83cd138efcfc"},"source":["timestamp_start = datetime.datetime.now()\n","model = get_modelLSTM_01(True)\n","hx = model.fit_generator(genD.read_data_sample(),epochs=30, steps_per_epoch=genD.nos_samples,verbose=1\n","                         #validation_data=unet_gen(),\n","                         #validation_steps=1\n","                         )\n","\n","timestamp_dur = datetime.datetime.now() - timestamp_start\n","print('Elapsed time = ' + str(timestamp_dur))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_11\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","in_NR_0 (InputLayer)            [(None, None, 1)]    0                                            \n","__________________________________________________________________________________________________\n","in_CR_0 (InputLayer)            [(None, None, 1)]    0                                            \n","__________________________________________________________________________________________________\n","LSTM_NR_1 (LSTM)                (None, None, 150)    91200       in_NR_0[0][0]                    \n","__________________________________________________________________________________________________\n","LSTM_CR_1 (LSTM)                (None, None, 150)    91200       in_CR_0[0][0]                    \n","__________________________________________________________________________________________________\n","LSTM_NR_2 (LSTM)                (None, 50)           40200       LSTM_NR_1[0][0]                  \n","__________________________________________________________________________________________________\n","LSTM_CR_2 (LSTM)                (None, 50)           40200       LSTM_CR_1[0][0]                  \n","__________________________________________________________________________________________________\n","tf_op_layer_dense_NC_11 (Tensor [(None, 100)]        0           LSTM_NR_2[0][0]                  \n","                                                                 LSTM_CR_2[0][0]                  \n","__________________________________________________________________________________________________\n","DENSE_FC0 (Dense)               (None, 20)           2020        tf_op_layer_dense_NC_11[0][0]    \n","__________________________________________________________________________________________________\n","DENSE_FC1 (Dense)               (None, 15)           315         DENSE_FC0[0][0]                  \n","__________________________________________________________________________________________________\n","OUTPUT_FC (Dense)               (None, 1)            16          DENSE_FC1[0][0]                  \n","==================================================================================================\n","Total params: 265,151\n","Trainable params: 265,151\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","Epoch 1/30\n","359/414 [=========================>....] - ETA: 14s - loss: 0.6935 - accuracy: 0.5070"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-69-8647f8309e8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtimestamp_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_modelLSTM_01\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m hx = model.fit_generator(genD.read_data_sample(),epochs=30, steps_per_epoch=genD.nos_samples,verbose=1\n\u001b[0m\u001b[1;32m      4\u001b[0m                          \u001b[0;31m#validation_data=unet_gen(),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                          \u001b[0;31m#validation_steps=1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1477\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m   @deprecation.deprecated(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"NOQT2povgWTe","colab_type":"text"},"source":["## [ SAVE MODEL ]"]},{"cell_type":"code","metadata":{"id":"ipPzHUHbgYNT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594682893933,"user_tz":-330,"elapsed":1678,"user":{"displayName":"Nelson Sharma","photoUrl":"","userId":"05205859662695765719"}},"outputId":"66da1ed0-2146-4be4-eb10-f8dfd15b453c"},"source":["ds_model = 'model_X'\n","# save this model\n","model_path = os.path.join(global_modeldir, ds_model+'.h5')\n","model.save_weights(model_path)\n","print('Saved Model Weights at : '+ str(model_path))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Saved Model Weights at : /content/drive/My Drive/Masters/workdir/ecg_data/db_exp/model_X.h5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Y16ZVidWPbHY","colab_type":"text"},"source":["# [ TESTING ]"]},{"cell_type":"markdown","metadata":{"id":"ql7iCwslgi7O","colab_type":"text"},"source":["## [ EVAL DATASET ]"]},{"cell_type":"code","metadata":{"id":"uHBA3U9Zglzz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"status":"ok","timestamp":1594684278809,"user_tz":-330,"elapsed":985126,"user":{"displayName":"Nelson Sharma","photoUrl":"","userId":"05205859662695765719"}},"outputId":"9d89648c-bc2b-4afe-90e1-d1f52aeb267e"},"source":["ds_path = os.path.join(global_dsdir,'lstm')\n","print(ds_path)\n","genD = DGen(ds_path,std_db_m,2)\n","genD.set_up()\n","print(genD.isample,'/',genD.iepoch)\n","print(genD.nos_epochs,genD.iepochlen)\n","A_Label = 'V'\n","g_LABELS = ['N',A_Label]\n","ds_model = 'model_X'       # SELECT MODEL WEIGHTS TO TEST UPON\n","model_path = os.path.join(global_modeldir, ds_model+'.h5')\n","model=get_modelLSTM_01(False)\n","model.load_weights(model_path)\n","print('Loaded Model weights '+ str(model_path))\n","##<----------------------------------------------\n","timestamp_start = datetime.datetime.now()\n","print('Manual Prediction on : ' , ds_path)\n","predx = model.evaluate_generator(genD.read_data_sample(),steps=genD.nos_epochs*genD.iepochlen,verbose=1\n","                         #validation_data=unet_gen(),\n","                         #validation_steps=1\n","                         )\n","\n","print(predx)\n","timestamp_dur = datetime.datetime.now() - timestamp_start\n","print('Elapsed time = ' + str(timestamp_dur))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Masters/workdir/ecg_data/db_exp/lstm\n","-1 / 0\n","30 992\n","Loaded Model weights /content/drive/My Drive/Masters/workdir/ecg_data/db_exp/model_X.h5\n","Manual Prediction on :  /content/drive/My Drive/Masters/workdir/ecg_data/db_exp/lstm\n","WARNING:tensorflow:From <ipython-input-14-28dca0f95d98>:17: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use Model.evaluate, which supports generators.\n","29760/29760 [==============================] - 977s 33ms/step - loss: 0.6777 - accuracy: 0.9698\n","[0.6777151823043823, 0.9697580933570862]\n","Elapsed time = 0:16:19.189684\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sDChkpDtj8R8","colab_type":"text"},"source":["## [ PREDICT DATASET ]"]},{"cell_type":"code","metadata":{"id":"7JD-J4GxkAUS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":360},"executionInfo":{"status":"ok","timestamp":1594685424530,"user_tz":-330,"elapsed":981436,"user":{"displayName":"Nelson Sharma","photoUrl":"","userId":"05205859662695765719"}},"outputId":"8875c6f7-4621-470d-ffe6-1bdc1f274fe8"},"source":["ds_path = os.path.join(global_dsdir,'lstm')\n","print(ds_path)\n","genD = DGen(ds_path,std_db_m,2)\n","genD.set_up()\n","print(genD.isample,'/',genD.iepoch)\n","print(genD.nos_epochs,genD.iepochlen)\n","A_Label = 'V'\n","g_LABELS = ['N',A_Label]\n","ds_model = 'model_X'       # SELECT MODEL WEIGHTS TO TEST UPON\n","model_path = os.path.join(global_modeldir, ds_model+'.h5')\n","model=get_modelLSTM_01(False)\n","model.load_weights(model_path)\n","print('Loaded Model weights '+ str(model_path))\n","##<----------------------------------------------\n","timestamp_start = datetime.datetime.now()\n","print('Manual Prediction on : ' , ds_path)\n","predx = model.predict_generator(genD.read_data_sample_predict(),steps=genD.nos_epochs*genD.iepochlen,verbose=1\n","                         #validation_data=unet_gen(),\n","                         #validation_steps=1\n","                         )\n","#------------------------------------------------------------ manual prediction\n","data_y = np.array(genD.true_labels)\n","cmx_local = np.zeros((len(g_LABELS),len(g_LABELS)),dtype='int32')\n","cmx2_local = predx.argmax(axis=1)\n","for i in range(0,len(cmx2_local)):\n","    alabel = int(data_y[i])\n","    plabel = cmx2_local[i]\n","    cmx_local[alabel,plabel]+=1\n","print('\\tConfusion Matrix')\n","print(print_conf_matrix( cmx_local,'', g_LABELS)) #logit('\\t'+str(cmx))\n","print_performance( get_performance(cmx_local) ,g_LABELS ) \n","#------------------------------------------------------------\n","timestamp_dur = datetime.datetime.now() - timestamp_start\n","print('Elapsed time = ' + str(timestamp_dur))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Masters/workdir/ecg_data/db_exp/lstm\n","-1 / 0\n","30 992\n","Loaded Model weights /content/drive/My Drive/Masters/workdir/ecg_data/db_exp/model_X.h5\n","Manual Prediction on :  /content/drive/My Drive/Masters/workdir/ecg_data/db_exp/lstm\n","WARNING:tensorflow:From <ipython-input-17-2a2eadccd901>:17: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use Model.predict, which supports generators.\n","29760/29760 [==============================] - 977s 33ms/step\n","\tConfusion Matrix\n","A\\P\tN\tV\n","N\t14871\t9\n","V\t13989\t891\n","\n","Performance for 2 classes\n","Class\tACC\tPRE\tSEN\tSPF\n","N\t0.53\t0.52\t1.0\t0.06\n","V\t0.53\t0.99\t0.06\t1.0\n","Elapsed time = 0:16:18.877093\n"],"name":"stdout"}]}]}